ReviewVenue,PublicationVenue,Title,delete,Authors,AuthorPDF,Abstract,ExplanationPage,SourceMaterials,Data,Preregistered,Video,DOI,PublicationYear,ConferenceYear,ConferenceTrack,ConferenceRoom,ConferenceDay,ConferenceSession,date,ConferenceTimeStart,ConferenceTimeEnd
VAST,TVCG,TPFlow: Progressive Partition and Multidimensional Pattern Extraction for Large-Scale Spatio-Temporal Data Analysis,J),"Dongyu Liu, Panpan Xu, Liu Ren",https://lliquid.github.io/homepage/files/draft_vis18_st.pdf,"Consider a multi-dimensional spatio-temporal (ST) dataset where each entry is a numerical measure defined by the corresponding temporal, spatial and other domain-specific dimensions. A typical approach to explore such data utilizes interactive visualizations with multiple coordinated views. Each view displays the aggregated measures along one or two dimensions. By brushing on the views, analysts can obtain detailed information. However, this approach often cannot provide sufficient guidance for analysts to identify patterns hidden within subsets of data. Without a priori hypotheses, analysts need to manually select and iterate through different slices to search for patterns, which can be a tedious and lengthy process. In this work, we model multidimensional ST data as tensors and propose a novel piecewise rank-one tensor decomposition algorithm which supports automatically slicing the data into homogeneous partitions and extracting the latent patterns in each partition for comparison and visual summarization. The algorithm optimizes a quantitative measure about how faithfully the extracted patterns visually represent the original data. Based on the algorithm we further propose a visual analytics framework that supports a top-down, progressive partitioning workflow for level-of-detail multidimensional ST data exploration. We demonstrate the general applicability and effectiveness of our technique on three datasets from different application domains: regional sales trend analysis, customer traffic analysis in department stores, and taxi trip analysis with origin-destination (OD) data. We further interview domain experts to verify the usability of the prototype.",,,,,video https://lliquid.github.io/homepage/files/video_vast18_tpflow_1920x1080_v7.mp4,10.1109/tvcg.2018.2865018,2018,2018,Other,"Convention Hall 1, Section C+D",Tuesday,VIS Awards & Best Papers,23-Oct,10:00 AM,10:20 AM
InfoVis,TVCG,Formalizing Visualization Design Knowledge as Constraints: Actionable and Extensible Models in Draco,J),"Dominik Moritz, Chenglong Wang, Greg L. Nelson, Halden Lin, Adam M. Smith, Bill Howe, Jeffrey Heer",https://osf.io/3eg9c/,"There exists a gap between visualization design guidelines and their application in visualization tools. While empirical studies can provide design guidance, we lack a formal framework for representing design knowledge, integrating results across studies, and applying this knowledge in automated design tools that promote effective encodings and facilitate visual exploration. We propose modeling visualization design knowledge as a collection of constraints, in conjunction with a method to learn weights for soft constraints from experimental data. Using constraints, we can take theoretical design knowledge and express it in a concrete, extensible, and testable form: the resulting models can recommend visualization designs and can easily be augmented with additional constraints or updated weights. We implement our approach in Draco, a constraint-based system based on Answer Set Programming (ASP). We demonstrate how to construct increasingly sophisticated automated visualization design systems, including systems based on weights learned directly from the results of graphical perception experiments.",https://medium.com/@uwdata/draco-representing-applying-learning-visualization-design-guidelines-64ce20287e9d,https://uwdata.github.io/draco/,,,vimeo 289784521,10.1109/tvcg.2018.2865240,2018,2018,Other,"Convention Hall 1, Section C+D",Tuesday,VIS Awards & Best Papers,23-Oct,10:20 AM,10:40 AM
SciVis,TVCG,Deadeye: A Novel Preattentive Visualization Technique Based on Dichoptic Presentation,J),"Andrey Krekhov, Jens Krueger",,,,,,,vimeo 290325240,10.1109/tvcg.2018.2864498,2018,2018,Other,"Convention Hall 1, Section C+D",Tuesday,VIS Awards & Best Papers,23-Oct,10:40 AM,11:00 AM
VAST,TVCG,Evaluating Multi-Dimensional Visualizations for Understanding Fuzzy Clusters,J),"Ying Zhao, Feng Luo, Minghui Chen, Yingchao Wang, Jiazhi Xia, Fangfang Zhou, Yunhai Wang, Yi Chen, Wei Chen",http://www.cad.zju.edu.cn/home/vagblog/VAG_Work/Fuzzy%20Clusters.pdf,"Fuzzy clustering assigns a probability of membership for a datum to a cluster, which veritably reflects real-world clustering scenarios but significantly increases the complexity of understanding fuzzy clusters. Many studies have demonstrated that visualization techniques for multi-dimensional data are beneficial to understand fuzzy clusters. However, no empirical evidence exists on the effectiveness and efficiency of these visualization techniques in solving analytical tasks featured by fuzzy clusters. In this paper, we conduct a controlled experiment to evaluate the ability of fuzzy clusters analysis to use four multi-dimensional visualization techniques, namely, parallel coordinate plot, scatterplot matrix, principal component analysis, and Radviz. First, we define the analytical tasks and their representative questions specific to fuzzy clusters analysis. Then, we design objective questionnaires to compare the accuracy, time, and satisfaction in using the four techniques to solve the questions. We also design subjective questionnaires to collect the experience of the volunteers with the four techniques in terms of ease of use, informativeness, and helpfulness. With a complete experiment process and a detailed result analysis, we test against four hypotheses that are formulated on the basis of our experience, and provide instructive guidance for analysts in selecting appropriate and efficient visualization techniques to analyze fuzzy clusters.",,,,,vimeo 289787891,10.1109/tvcg.2018.2865020,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Evaluation and Theory,23-Oct,2:20 PM,2:40 PM
VAST,VAST,The Effect of Proximity in Social Data Charts on Perceived Unity,C),"Marlen Promann, Sabine Brunswicker",,,,,,,vimeo 289787716,,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Evaluation and Theory,23-Oct,2:40 PM,3:00 PM
VAST,TVCG,Futzing and Moseying: Interviews with Professional Data Analysts on Exploration Practices,J),"Sara Alspaugh, Nava Zokaei, Andrea Liu, Cindy Jin, Marti Hearst",http://people.ischool.berkeley.edu/~hearst/papers/vast2018.pdf,"We report the results of interviewing thirty professional data analysts working in a range of industrial, academic, and regulatory environments. This study focuses on participants' descriptions of exploratory activities and tool usage in these activities. Highlights of the ndings include: distinctions between exploration as a precursor to more directed analysis versus truly open-ended exploration; conrmation that some analysts see ""finding something interesting"" as a valid goal of data exploration while others explicitly disavow this goal; conicting views about the role of intelligent tools in data exploration; and pervasive use of visualization for exploration, but with only a subset using direct manipulation interfaces. These findings provide guidelines for future tool development, as well as a better understanding of the meaning of the term ""data exploration"" based on the words of practitioners ""in the wild.""",,,,,vimeo 289787961,10.1109/TVCG.2018.2865040,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Evaluation and Theory,23-Oct,3:00 PM,3:20 PM
VAST,VAST,The Effect of Semantic Interaction on Foraging in Text Analysis,C),"John Wenskovitch, Lauren Bradel, Michelle Dowling, Leanna House, Chris North",https://infovis.cs.vt.edu/sites/default/files/effect-semantic-interaction.pdf,"Completing text analysis tasks is a continuous sensemaking loop of foraging for information and incrementally synthesizing it into hypotheses. Past research has shown the advantages of using spatial workspaces as a means for synthesizing information through externalizing hypotheses and creating spatial schemas. However, spatializing the entirety of datasets becomes prohibitive as the number of documents available to the analysts grows, particularly when only a small subset are relevant to the task at hand. StarSPIRE is a visual analytics tool designed to explore collections of documents, leveraging users’ semantic interactions to steer (1) a synthesis model that aids in document layout, and (2) a foraging model to automatically retrieve new relevant information. In contrast to traditional keyword search foraging (KSF), “semantic interaction foraging” (SIF) occurs as a result of the user’s synthesis actions. To quantify the value of semantic interaction foraging, we use StarSPIRE to evaluate its utility for an intelligence analysis sensemaking task. Semantic interaction foraging accounted for 26% of useful documents found, and it also resulted in increased synthesis interactions and improved sensemaking task performance by users in comparison to only using keyword search.",,,,,vimeo 289787752,,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Evaluation and Theory,23-Oct,3:20 PM,3:40 PM
VAST,TVCG,An Information-Theoretic Approach to the Cost-benefit Analysis of Visualization in Virtual Environments,J),"Min Chen, Kelly Gaither, Nigel John, Brian McCann",,,,,,,vimeo 289787910,10.1109/TVCG.2018.2865025,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Evaluation and Theory,23-Oct,3:40 PM,4:00 PM
InfoVis,TVCG,Shape-preserving Star Coordinates,J),"Vladimir Molchanov, Lars Linsen",,,,,,,vimeo 289785145,10.1109/tvcg.2018.2865118,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Multiple Dimensions,23-Oct,2:20 PM,2:40 PM
TVCG,TVCG,Using Dashboard Networks to Visualize Multiple Patient Histories: A Design Study on Post-operative Prostate Cancer,T),"Jürgen Bernard, David Sessler, Jörn Kohlhammer, Roy A. Ruddle",http://eprints.whiterose.ac.uk/128739/1/bernard-ieee-tvcg-dashboard-networks.pdf,"In this design study, we present a visualization technique that segments patients' histories instead of treating them as raw event sequences, aggregates the segments using criteria such as the whole history or treatment combinations, and then visualizes the aggregated segments as static dashboards that are arranged in a dashboard network to show longitudinal changes. The static dashboards were developed in nine iterations, to show 15 important attributes from the patients' histories. The final design was evaluated with five non-experts, five visualization experts and four medical experts, who successfully used it to gain an overview of a 2,000 patient dataset, and to make observations about longitudinal changes and differences between two cohorts. The research represents a step-change in the detail of large-scale data that may be successfully visualized using dashboards, and provides guidance about how the approach may be generalized.",,,,,vimeo 289789053,10.1109/tvcg.2018.2803829,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Multiple Dimensions,23-Oct,2:40 PM,3:00 PM
InfoVis,TVCG,SRVis: Towards Better Spatial Integration in Ranking Visualization,J),"Di Weng, Ran Chen, Zikun Deng, Feiran Wu, Jingmin Chen, Yingcai Wu",http://zjuvis.org/files/srvis.pdf,"Interactive ranking techniques have substantially promoted analysts' ability in making judicious and informed decisions effectively based on multiple criteria. However, the existing techniques cannot satisfactorily support the analysis tasks involved in ranking large-scale spatial alternatives, such as selecting optimal locations for chain stores, where the complex spatial contexts involved are essential to the decision-making process. Limitations observed in the prior attempts of integrating rankings with spatial contexts motivate us to develop a context-integrated visual ranking technique. Based on a set of generic design requirements we summarized by collaborating with domain experts, we propose SRVis, a novel spatial ranking visualization technique that supports efficient spatial multi-criteria decision-making processes by addressing three major challenges in the aforementioned context integration, namely, a) the presentation of spatial rankings and contexts, b) the scalability of rankings' visual representations, and c) the analysis of context-integrated spatial rankings. Specifically, we encode massive rankings and their cause with scalable matrix-based visualizations and stacked bar charts based on a novel two-phase optimization framework that minimizes the information loss, and the flexible spatial filtering and intuitive comparative analysis are adopted to enable the in-depth evaluation of the rankings and assist users in selecting the best spatial alternative. The effectiveness of the proposed technique has been evaluated and demonstrated with an empirical study of optimization methods, two case studies, and expert interviews.",https://srvis.zjuvis.org/,,,,vimeo 289784783,10.1109/TVCG.2018.2865126,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Multiple Dimensions,23-Oct,3:00 PM,3:20 PM
InfoVis,TVCG,A Declarative Rendering Model for Multiclass Density Maps,J),"Jaemin Jo, Frédéric Vernier, Pierre Dragicevic, Jean-Daniel Fekete",https://hal.inria.fr/hal-01848427/document,"Multiclass maps are scatterplots, multidimensional projections, or thematic geographic maps where data points have a categorical attribute in addition to two quantitative attributes. This categorical attribute is often rendered using shape or color, which does not scale when overplotting occurs. When the number of data points increases, multiclass maps must resort to data aggregation to remain readable. We present multiclass density maps: multiple 2D histograms computed for each of the category values. Multiclass density maps are meant as a building block to improve the expressiveness and scalability of multiclass map visualization. In this article, we first present a short survey of aggregated multiclass maps, mainly from cartography. We then introduce a declarative model—a simple yet expressive JSON grammar associated with visual semantics—that specifies a wide design space of visualizations for multiclass density maps. Our declarative model is expressive and can be efficiently implemented in visualization front-ends such as modern web browsers. Furthermore, it can be reconfigured dynamically to support data exploration tasks without recomputing the raw data. Finally, we demonstrate how our model can be used to reproduce examples from the past and support exploring data at scale.",https://jaeminjo.github.io/Multiclass-Density-Maps/,https://github.com/e-/Multiclass-Density-Maps,,,vimeo 289785026,10.1109/TVCG.2018.2865141,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Multiple Dimensions,23-Oct,3:20 PM,3:40 PM
InfoVis,TVCG,DimReader: Axis lines that explain non-linear projections,J),"Rebecca Faust, David Glickenstein, Carlos Scheidegger",https://arxiv.org/pdf/1710.00992.pdf,"Non-linear dimensionality reduction (NDR) methods such as LLE and t-SNE are popular with visualization researchers and experienced data analysts, but present serious problems of interpretation. In this paper, we present DimReader, a technique that recovers readable axes from such techniques. DimReader is based on analyzing infinitesimal perturbations of the dataset with respect to variables of interest. The perturbations define exactly how we want to change each point in the original dataset and we measure the effect that these changes have on the projection. The recovered axes are in direct analogy with the axis lines (grid lines) of traditional scatterplots. We also present methods for discovering perturbations on the input data that change the projection the most. The calculation of the perturbations is efficient and easily integrated into programs written in modern programming languages. We present results of DimReader on a variety of NDR methods and datasets both synthetic and real-life, and show how it can be used to compare different NDR methods. Finally, we discuss limitations of our proposal and situations where further research is needed.",,,,,vimeo 289784574,10.1109/tvcg.2018.2865194,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Multiple Dimensions,23-Oct,3:40 PM,4:00 PM
SciVis,TVCG,Recirculation Surfaces for Flow Visualization,J),"Thomas Wilde, Christian Rössl, Holger Theisel",http://vc.cs.ovgu.de/files/publications/2018/Wilde_2018_VISa.pdf,"We present a formal approach to the visual analysis of recirculation in flows by introducing recirculation surfaces for 3D unsteady flow fields. Recirculation surfaces are the loci where massless particle integration returns to its starting point after some variable, finite integration. We give a rigorous definition of recirculation surfaces as 2-manifolds embedded in 5D space and study their properties. Based on this we construct an algorithm for their extraction, which searches for intersections of a recirculation surface with lines defined in 3D. This reduces the problem to a repeated search for critical points in 3D vector fields. We provide a uniform sampling of the search space paired with a surface reconstruction and visualize results. This way, we present the first algorithm for a comprehensive feature extraction in the 5D flow map of a 3D flow. The problem of finding isolated closed orbits in steady vector fields occurs as a special case of recirculation surfaces. This includes isolated closed orbits with saddle behavior. We show recirculation surfaces for a number of artificial and real flow data sets.",,,,,video http://isgwww.cs.uni-magdeburg.de/visual/files/publications/2018/Wilde_2018_VISa.mp4,10.1109/tvcg.2018.2864813,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Flow Features,23-Oct,2:20 PM,2:40 PM
SciVis,TVCG,Objective Vortex Corelines of Finite-sized Objects in Fluid Flows,J),"Tobias Günther, Holger Theisel",https://isgwww.cs.uni-magdeburg.de/visual/files/publications/2018/Guenther_2018_VIS.pdf,"Vortices are one of the most-frequently studied phenomena in fluid flows. The center of the rotating motion is called the vortex coreline and its successful detection strongly depends on the choice of the reference frame. The optimal frame moves with the center of the vortex, which incidentally makes the observed fluid flow steady and thus standard vortex coreline extractors such as Sujudi-Haimes become applicable. Recently, an objective optimization framework was proposed that determines a near-steady reference frame for tracer particles. In this paper, we extend this technique to the detection of vortex corelines of inertial particles. An inertial particle is a finite-sized object that is carried by a fluid flow. In contrast to the usual tracer particles, they do not move tangentially with the flow, since they are subject to gravity and exhibit mass-dependent inertia. Their particle state is determined by their position and own velocity, which makes the search for the optimal frame a high-dimensional problem. We demonstrate in this paper that the objective detection of an inertial vortex coreline can be reduced in 2D to a critical point search in 2D. For 3D flows, however, the vortex coreline criterion remains a parallel vectors condition in 6D. To detect the vortex corelines we propose a recursive subdivision approach that is tailored to the underlying structure of the 6D vectors. The resulting algorithm is objective, and we demonstrate the vortex coreline extraction in a number of 2D and 3D vector fields.",,,,,video http://isgwww.cs.uni-magdeburg.de/visual/files/publications/2018/Guenther_2018_VIS.mp4,10.1109/TVCG.2018.2864828,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Flow Features,23-Oct,2:40 PM,3:00 PM
TVCG,TVCG,Towards High-quality Visualization of Superfluid Vortices,T),"Yulong Guo, Xiaopei Liu, Chi Xiong, Xuemiao Xu, Chi-Wing Fu",https://arxiv.org/pdf/1710.02630.pdf,"Superfluidity is a special state of matter exhibiting macroscopic quantum phenomena and acting like a fluid with zero viscosity. In such a state, superfluid vortices exist as phase singularities of the model equation with unique distributions. This paper presents novel techniques to aid the visual understanding of superfluid vortices based on the state-of-the-art non-linear Klein-Gordon equation, which evolves a complex scalar field, giving rise to special vortex lattice/ring structures with dynamic vortex formation, reconnection, and Kelvin waves, etc. By formulating a numerical model with theoretical physicists in superfluid research, we obtain high-quality superfluid flow data sets without noise-like waves, suitable for vortex visualization. By further exploring superfluid vortex properties, we develop a new vortex identification and visualization method: a novel mechanism with velocity circulation to overcome phase singularity and an orthogonal-plane strategy to avoid ambiguity. Hence, our visualizations can help reveal various superfluid vortex structures and enable domain experts for related visual analysis, such as the steady vortex lattice/ring structures, dynamic vortex string interactions with reconnections and energy radiations, where the famous Kelvin waves and decaying vortex tangle were clearly observed. These visualizations have assisted physicists to verify the superfluid model, and further explore its dynamic behavior more intuitively.",,,,,youtube TlEQbPSbYTQ ,10.1109/TVCG.2017.2719684,2017,2018,SciVis,Estrel Hall A+B,Tuesday,Flow Features,23-Oct,3:00 PM,3:20 PM
TVCG,TVCG,Semantic Flow Graph: A Framework for Discovering Object Relationships in Flow Fields,T),"Jun Tao, Chaoli Wang, Nitesh Chawla, Lei Shi, Seung Hyun Kim",https://www3.nd.edu/~cwang11/research/tvcg18-sfg.pdf,"Visual exploration of flow fields is important for studying dynamic systems. We introduce semantic flow graph (SFG), a novel graph representation and interaction framework that enables users to explore the relationships among key objects (i.e., field lines, features, and spatiotemporal regions) of both steady and unsteady flow fields. The objects and their relationships are organized as a heterogeneous graph. We assign each object a set of attributes, based on which a semantic abstraction of the heterogeneous graph is generated. This semantic abstraction is SFG. We design a suite of operations to explore the underlying flow fields based on this graph representation and abstraction mechanism. Users can flexibly reconfigure SFG to examine the relationships among groups of objects at different abstraction levels. Three linked views are developed to display SFG, its node split criteria and history, and the objects in the spatial volume. For simplicity, we introduce SFG construction and exploration for steady flow fields with critical points being the only features. Then we demonstrate that SFG can be naturally extended to deal with unsteady flow fields and multiple types of features. We experiment with multiple data sets and conduct an expert evaluation to demonstrate the effectiveness of our approach. ",,,,,video http://www.nd.edu/~cwang11/research/tvcg18-sfg.wmv,10.1109/tvcg.2017.2773071,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Flow Features,23-Oct,3:20 PM,3:40 PM
VAST,TVCG,Visual Abstraction of the Large Scale Geospatial Origin-Destination Movement Data,J),"Zhiguang Zhou, Linhao Meng, Cheng Tang, Ying Zhao, Zhiyong Guo, Miaoxin Hu, Wei Chen",,,,,,,vimeo 289787224,10.1109/TVCG.2018.2864503,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Spatio-Temporal Data,23-Oct,4:20 PM,4:40 PM
VAST,TVCG,Analysis of Flight Variability: a Systematic Approach,J),"Natalia Andrienko, Gennady Andrienko, Jose Manuel Cordero Garcia, David Scarlatti",http://openaccess.city.ac.uk/20334/1/analysis-flight-variability.pdf,"In movement data analysis, there exists a problem of comparing multiple trajectories of moving objects to common or distinct reference trajectories. We introduce a general conceptual framework for comparative analysis of trajectories and an analytical procedure, which consists of (1) finding corresponding points in pairs of trajectories, (2) computation of pairwise difference measures, and (3) interactive visual analysis of the distributions of the differences with respect to space, time, set of moving objects, trajectory structures, and spatio-temporal context. We propose a combination of visualisation, interaction, and data transformation techniques supporting the analysis and demonstrate the use of our approach for solving a challenging problem from the aviation domain.",,,,,vimeo 289787283,10.1109/TVCG.2018.2864811,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Spatio-Temporal Data,23-Oct,4:40 PM,5:00 PM
VAST,TVCG,ForVizor: Visualizing Spatio-Temporal Team Formations in Soccer,J),"Yingcai Wu, Xiao Xie, Jiachen Wang, Dazhen Deng, Hongye Liang, Hui Zhang, Shoubin Cheng, Wei Chen",http://zjuvis.org/files/forvizor.pdf,"Regarded as a high-level tactic in soccer, a team formation assigns players different tasks and indicates their active regions on the pitch, thereby influencing the team performance significantly. Analysis of formations in soccer has become particularly indispensable for soccer analysts. However, formations of a team are intrinsically time-varying and contain inherent spatial information. The spatio-temporal nature of formations and other characteristics of soccer data, such as multivariate features, make analysis of formations in soccer a challenging problem. In this study, we closely worked with domain experts to characterize domain problems of formation analysis in soccer and formulated several design goals. We design a novel spatio-temporal visual representation of changes in team formation, allowing analysts to visually analyze the evolution of formations and track the spatial flow of players within formations over time. Based on the new design, we further design and develop ForVizor, a visual analytics system, which empowers users to track the spatio-temporal changes in formation and understand how and why such changes occur. With ForVizor, domain experts conduct formation analysis of two games. Analysis results with insights and useful feedback are summarized in two case studies.",,,,,vimeo 289787566,10.1109/tvcg.2018.2865041,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Spatio-Temporal Data,23-Oct,5:00 PM,5:20 PM
VAST,TVCG,MotionRugs: Visualizing Collective Trends in Space and Time,J),"Juri Buchmuller, Dominik Jackle, Eren Cakmak, Ulrik Brandes, Daniel Keim",,,,https://github.com/jbuchmueller/motionrugs,,,vimeo 289787684,10.1109/tvcg.2018.2865049,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Spatio-Temporal Data,23-Oct,5:20 PM,5:40 PM
VAST,TVCG,Identification of Temporally Varying Areas of Interest in Long Duration Eye Tracking Data Sets,J),"Prithiviraj Kaliappa Gounder Muthumanickam, Katerina Vrotsou, Aida Nordman, Jimmy Johansson, Matthew Cooper",,,,,,,vimeo 289787582,10.1109/TVCG.2018.2865042,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Spatio-Temporal Data,23-Oct,5:40 PM,6:00 PM
InfoVis,TVCG,A Heuristic Approach to Value-Driven Evaluation of Visualizations,J),"Emily Wall, Meeshu Agnihotri, Laura Matzen, Kristin Divis, Michael Haass, Alex Endert, John Stasko",https://www.cc.gatech.edu/~ewall9/media/papers/ValueVIS2018.pdf,"Recently, an approach for determining the value of a visualization was proposed, one moving beyond simple measurements of task accuracy and speed. The value equation contains components for the time savings a visualization provides, the insights and insightful questions it spurs, the overall essence of the data it conveys, and the confidence about the data and its domain it inspires. This articulation of value is purely descriptive, however, providing no actionable method of assessing a visualization's value. In this work, we create a heuristic-based evaluation methodology to accompany the value equation for assessing interactive visualizations. We refer to the methodology colloquially as ICE-T, based on an anagram of the four value components. Our approach breaks the four components down into guidelines, each of which is made up of a small set of low-level heuristics. Evaluators who have knowledge of visualization design principles then assess the visualization with respect to the heuristics. We conducted an initial trial of the methodology on three interactive visualizations of the same data set, each evaluated by 15 visualization experts. We found that the methodology showed promise, obtaining consistent ratings across the three visualizations and mirroring judgments of the utility of the visualizations by instructors of the course in which they were developed.",,,,,vimeo 289784928,10.1109/tvcg.2018.2865146,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Evaluation & Applications,23-Oct,4:20 PM,4:40 PM
InfoVis,TVCG,Patterns and Pace: Quantifying Diverse Exploration Behavior with Visualizations on the Web,J),"Mi Feng, Evan Peck, Lane Harrison",https://osf.io/9wqgk/,"The diverse and vibrant ecosystem of interactive visualizations on the web presents an opportunity for researchers and practitioners to observe and analyze how everyday people interact with data visualizations. However, existing metrics of visualization interaction behavior used in research do not fully reveal the breadth of peoples' open-ended explorations with visualizations. One possible way to address this challenge is to determine high-level goals for visualization interaction metrics, and infer corresponding features from user interaction data that characterize different aspects of peoples' explorations of visualizations. In this paper, we address this challenge by identifying needs for visualization behavior analysis, and by developing corresponding candidate features that can be inferred from users' interaction data with visualization. We then propose metrics that capture novel aspects of peoples' open-ended explorations, including exploration uniqueness and exploration pacing. We evaluate these metrics along with four other metrics recently proposed in visualization literature by applying them to interaction data from prior visualization studies. The results of these evaluations suggest that these new metrics 1) reveal new characteristics of peoples' use of visualizations, 2) can be used to evaluate statistical differences between visualization designs, and 3) are statistically independent of prior metrics used in visualization research. We discuss implications of these results for future studies, including the potential for applying these metrics in visualization interaction analysis, as well as emerging challenges in developing a design space of metrics for visualization engagement.",,,https://osf.io/dx43q/wiki/home/,,vimeo 289785167,10.1109/tvcg.2018.2865117,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Evaluation & Applications,23-Oct,4:40 PM,5:00 PM
TVCG,TVCG,Lineage: Visualizing Multivariate Clinical Data in Genealogy Graphs,T),"Carolina Nobre, Nils Gehlenborg, Hilary Coon, Alexander Lex",https://www.biorxiv.org/content/early/2018/02/27/128579,"The majority of diseases that are a significant challenge for public and individual heath are caused by a combination of hereditary and environmental factors. In this paper we introduce Lineage, a novel visual analysis tool designed to support domain experts who study such multifactorial diseases in the context of genealogies. Incorporating familial relationships between cases with other data can provide insights into shared genomic variants and shared environmental exposures that may be implicated in such diseases. We introduce a data and task abstraction, and argue that the problem of analyzing such diseases based on genealogical, clinical, and genetic data can be mapped to a multivariate graph visualization problem. The main contribution of our design study is a novel visual representation for tree-like, multivariate graphs, which we apply to genealogies and clinical data about the individuals in these families. We introduce data-driven aggregation methods to scale to multiple families. By designing the genealogy graph layout to align with a tabular view, we are able to incorporate extensive, multivariate attributes in the analysis of the genealogy without cluttering the graph. We validate our designs by conducting case studies with our domain collaborators.",,https://github.com/caleydo/lineage,,,vimeo 289789223,10.1109/tvcg.2018.2811488,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Evaluation & Applications,23-Oct,5:00 PM,5:20 PM
InfoVis,TVCG,IDMVis: Temporal Event Sequence Visualization for Type 1 Diabetes Treatment Decision Support,J),"Yixuan Zhang, Kartik Chanana, Cody Dunne",https://github.com/zjanice/PHI/blob/master/IDMVis_IEEEVIS18_preprint.pdf,"Type 1 diabetes is a chronic, incurable autoimmune disease affecting millions of Americans in which the body stops producing insulin and blood glucose levels rise. The goal of intensive diabetes management is to lower average blood glucose through frequent adjustments to insulin protocol, diet, and behavior. Manual logs and medical device data are collected by patients, but these multiple sources are presented in disparate visualization designs to the clinician—making temporal inference difficult. We conducted a design study over 18 months with clinicians performing intensive diabetes management. We present a data abstraction and novel hierarchical task abstraction for this domain. We also contribute IDMVis: a visualization tool for temporal event sequences with multidimensional, interrelated data. IDMVis includes a novel technique for folding and aligning records by dual sentinel events and scaling the intermediate timeline. We validate our design decisions based on our domain abstractions, best practices, and through a qualitative evaluation with six clinicians. The results of this study indicate that IDMVis accurately reflects the workflow of clinicians. Using IDMVis, clinicians are able to identify issues of data quality such as missing or conflicting data, reconstruct patient records when data is missing, differentiate between days with different patterns, and promote educational interventions after identifying discrepancies.",,https://github.com/VisDunneRight/IDMVis,,,vimeo 289785100,10.1109/tvcg.2018.2865076,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Evaluation & Applications,23-Oct,5:20 PM,5:40 PM
TVCG,TVCG,Visualization of Cultural Heritage Collection Data: State of the Art and Future Challenges,T),"Florian Windhager, Paolo Federico, Günther Schreder, Katrin Glinka, Marian Dörk, Silvia Miksch, Eva Mayr",https://uclab.fh-potsdam.de/wp/wp-content/uploads/tvcg2018.pdf,"After decades of digitization, large cultural heritage collections have emerged on the web, which contain massive stocks of content from galleries, libraries, archives, and museums. This increase in digital cultural heritage data promises new modes of analysis and increased levels of access for academic scholars and casual users alike. Going beyond the standard representations of search-centric and grid-based interfaces, a multitude of approaches has recently started to enable visual access to cultural collections, and to explore them as complex and comprehensive information spaces by the means of interactive visualizations. In contrast to conventional web interfaces, we witness a widening spectrum of innovative visualization types specially designed for rich collections from the cultural heritage sector. This new class of information visualizations gives rise to a notable diversity of interaction and representation techniques while lending currency and urgency to a discussion about principles such as serendipity, generosity, and criticality in connection with visualization design. With this survey, we review information visualization approaches to digital cultural heritage collections and reflect on the state of the art in techniques and design choices. We contextualize our survey with humanist perspectives on the field and point out opportunities for future research.",,,,,vimeo 289789286,10.1109/tvcg.2018.2830759,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Evaluation & Applications,23-Oct,5:40 PM,6:00 PM
SciVis,TVCG,Interactive Visualization of RNA and DNA Structures,J),"Norbert Lindow, Daniel Baum, Morgan Leborgne, Hans-Christian Hege",,,,,,,vimeo 290325417,10.1109/tvcg.2018.2864507,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Biological Applications,23-Oct,4:20 PM,4:40 PM
SciVis,TVCG,Labels on Levels: Labeling of Multi-Scale Multi-Instance and Crowded 3D Biological Environments,J),"David Kouřil, Ladislav Čmolík, Barbora Kozlíková, Hsiang-Yun Wu, Graham Johnson, David S. Goodsell, Arthur Olson, Eduard Gröller, Ivan Viola",https://www.cg.tuwien.ac.at/research/publications/2019/kouril-2018-LoL/kouril-2018-LoL-paper.pdf,"Labeling is intrinsically important for exploring and understanding complex environments and models in a variety of domains. We present a method for interactive labeling of crowded 3D scenes containing very many instances of objects spanning multiple scales in size. In contrast to previous labeling methods, we target cases where many instances of dozens of types are present and where the hierarchical structure of the objects in the scene presents an opportunity to choose the most suitable level for each placed label. Our solution builds on and goes beyond labeling techniques in medical 3D visualization, cartography, and biological illustrations from books and prints. In contrast to these techniques, the main characteristics of our new technique are: 1) a novel way of labeling objects as part of a bigger structure when appropriate, 2) visual clutter reduction by labeling only representative instances for each type of an object, and a strategy of selecting those. The appropriate level of label is chosen by analyzing the scene’s depth buffer and the scene objects’ hierarchy tree. We address the topic of communicating the parent-children relationship between labels by employing visual hierarchy concepts adapted from graphic design. Selecting representative instances considers several criteria tailored to the character of the data and is combined with a greedy optimization approach. We demonstrate the usage of our method with models from mesoscale biology where these two characteristics—multi-scale and multi-instance—are abundant, along with the fact that these scenes are extraordinarily dense.",,,,,vimeo 290325281,10.1109/tvcg.2018.2864491,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Biological Applications,23-Oct,4:40 PM,5:00 PM
SciVis,TVCG,Visualization of Large Molecular Trajectories,J),"David Duran Rosich, Pedro Hermosilla Casajus, Timo Ropinski, Barbora Kozlíková, Àlvar Vinacua, Pere-Pau Vázquez",https://www.uni-ulm.de/fileadmin/website_uni_ulm/iui.inst.100/institut/Papers/viscom/2018/vazquez2018-largemol.pdf,"The analysis of protein-ligand interactions is a time-intensive task. Researchers have to analyze multiple physico-chemical properties of the protein at once and combine them to derive conclusions about the protein-ligand interplay. Typically, several charts are inspected, and 3D animations can be played side-by-side to obtain a deeper understanding of the data. With the advances in simulation techniques, larger and larger datasets are available, with up to hundreds of thousands of steps. Unfortunately, such large trajectories are very difficult to investigate with traditional approaches. Therefore, the need for special tools that facilitate inspection of these large trajectories becomes substantial. In this paper, we present a novel system for visual exploration of very large trajectories in an interactive and user-friendly way. Several visualization motifs are automatically derived from the data to give the user the information about interactions between protein and ligand. Our system offers specialized widgets to ease and accelerate data inspection and navigation to interesting parts of the simulation. The system is suitable also for simulations where multiple ligands are involved. We have tested the usefulness of our tool on a set of datasets obtained from protein engineers, and we describe the expert feedback.",,,,,vimeo 290328133,10.1109/tvcg.2018.2864851,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Biological Applications,23-Oct,5:00 PM,5:20 PM
TVCG,TVCG,Robust Tracing and Visualization of Heterogeneous Microvascular Networks,T),"Pavel Govyadinov, Tasha Womack, Jason L. Eriksen, Guoning Chen, David Mayerich",,,,,,,vimeo 289789196,10.1109/tvcg.2018.2818701,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Biological Applications,23-Oct,5:20 PM,5:40 PM
VAST,TVCG,Visual Analysis of the Temporal Evolution of Ensemble Forecast Sensitivities,J),"Alexander Kumpf, Marc Rautenhaus, Michael Riemer, Rüdiger Westermann",http://www.in.tum.de/fileadmin/w00bws/cg/Research/Publications/2018/ESAWorkflow/Preprint_Correlation_wDOI.pdf,"Ensemble sensitivity analysis (ESA) has been established in the atmospheric sciences as a correlation-based approach to determine the sensitivity of a scalar forecast quantity computed by a numerical weather prediction model to changes in another model variable at a different model state. Its applications include determining the origin of forecast errors and placing targeted observations to improve future forecasts. We—a team of visualization scientists and meteorologists—present a visual analysis framework to improve upon current practice of ESA. We support the user in selecting regions to compute a meaningful target forecast quantity by embedding correlation-based grid-point clustering to obtain statistically coherent regions. The evolution of sensitivity features computed via ESA are then traced through time, by integrating a quantitative measure of feature matching into optical-flow-based feature assignment, and displayed by means of a swipe-path showing the geo-spatial evolution of the sensitivities. Visualization of the internal correlation structure of computed features guides the user towards those features robustly predicting a certain weather event. We demonstrate the use of our method by application to real-world 2D and 3D cases that occurred during the 2016 NAWDEX field campaign, showing the interactive generation of hypothesis chains to explore how atmospheric processes sensitive to each other are interrelated.",,,,,vimeo 289787833,10.1109/tvcg.2018.2864901,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Ensemble and Provenance,24-Oct,9:00 AM,9:20 AM
VAST,TVCG,EnsembleLens: Ensemble-based Visual Exploration of Anomaly Detection Algorithms with Multidimensional Data,J),"Ke Xu, Meng Xia, Xing Mu, Yun Wang, Nan Cao",https://lukeluker.github.io/papers/EnsembleLens_VAST2018_KeXu.pdf,"The results of anomaly detection are sensitive to the choice of detection algorithms as they are specialized for different properties of data, especially for multidimensional data. Thus, it is vital to select the algorithm appropriately. To systematically select the algorithms, ensemble analysis techniques have been developed to support the assembly and comparison of heterogeneous algorithms. However, challenges remain due to the absence of the ground truth, interpretation, or evaluation of these anomaly detectors. In this paper, we present a visual analytics system named EnsembleLens that evaluates anomaly detection algorithms based on the ensemble analysis process. The system visualizes the ensemble processes and results by a set of novel visual designs and multiple coordinated contextual views to meet the requirements of correlation analysis, assessment and reasoning of anomaly detection algorithms. We also introduce an interactive analysis workflow that dynamically produces contextualized and interpretable data summaries that allow further refinements of exploration results based on user feedback. We demonstrate the effectiveness of EnsembleLens through a quantitative evaluation, three case studies with real-world data and interviews with two domain experts.",,,,,vimeo 289787339,10.1109/TVCG.2018.2864825,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Ensemble and Provenance,24-Oct,9:20 AM,9:40 AM
TVCG,TVCG,Exploring Variability within Ensembles of Decadal Climate Predictions,T),"Christopher P. Kappe, Michael Böttinger, Heike Leitte",,,,,,,vimeo 289789327,10.1109/tvcg.2018.2810919,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Ensemble and Provenance,24-Oct,9:40 AM,10:00 AM
VAST,TVCG,KnowledgePearls: Provenance-Based Visualization Retrieval,J),"Holger Stitz, Samuel Gratzl, Harald Piringer, Thomas Zichner, Marc Streit",https://www.vrvis.at/publications/pdfs/PB-VRVis-2018-031.pdf,"Storing analytical provenance generates a knowledge base with a large potential for recalling previous results and guiding users in future analyses. However, without extensive manual creation of meta information and annotations by the users, search and retrieval of analysis states can become tedious. We present KnowledgePearls, a solution for efficient retrieval of analysis states that are structured as provenance graphs containing automatically recorded user interactions and visualizations. As a core component, we describe a visual interface for querying and exploring analysis states based on their similarity to a partial definition of a requested analysis state. Depending on the use case, this definition may be provided explicitly by the user by formulating a search query or inferred from given reference states. We explain our approach using the example of efficient retrieval of demographic analyses by Hans Rosling and discuss our implementation for a fast look-up of previous states. Our approach is independent of the underlying visualization framework. We discuss the applicability for visualizations which are based on the declarative grammar Vega and we use a Vega-based implementation of Gapminder as guiding example. We additionally present a biomedical case study to illustrate how KnowledgePearls facilitates the exploration process by recalling states from earlier analyses.",,https://github.com/Caleydo/knowledge-pearls,,,vimeo 289787528,10.1109/tvcg.2018.2865024,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Ensemble and Provenance,24-Oct,10:00 AM,10:20 AM
VAST,TVCG,Enhancing Web-based Analytics Applications through Provenance,J),"Akhilesh Camisetty, Chaitanya Chandurkar, Maoyuan Sun, David Koop",http://www.cis.umassd.edu/~dkoop/pubs/simprov.pdf,"Visual analytics systems continue to integrate new technologies and leverage modern environments for exploration and collaboration, making tools and techniques available to a wide audience through web browsers. Many of these systems have been developed with rich interactions, offering users the opportunity to examine details and explore hypotheses that have not been directly encoded by a designer. Understanding is enhanced when users can replay and revisit the steps in the sensemaking process, and in collaborative settings, it is especially important to be able to review not only the current state but also what decisions were made along the way. Unfortunately, many web-based systems lack the ability to capture such reasoning, and the path to a result is transient, forgotten when a user moves to a new view. This paper explores the requirements to augment existing client-side web applications with support for capturing, reviewing, sharing, and reusing steps in the reasoning process. Furthermore, it considers situations where decisions are made with streaming data, and the insights gained from revisiting those choices when more data is available. It presents a proof of concept, the Shareable Interactive Manipulation Provenance framework (SIMProv.js), that addresses these requirements in a modern, client-side JavaScript library, and describes how it can be integrated with existing frameworks.",,,,,vimeo 289787554,10.1109/tvcg.2018.2865039,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Ensemble and Provenance,24-Oct,10:20 AM,10:40 AM
InfoVis,TVCG,Comparing Similarity Perception in Time Series Visualizations,J),"Anna Gogolou, Theophanis Tsandilas, Themis Palpanas, Anastasia Bezerianos",https://hal.inria.fr/hal-01845008/document,"A common challenge faced by many domain experts working with time series data is how to identify and compare similar patterns. This operation is fundamental in high-level tasks, such as detecting recurring phenomena or creating clusters of similar temporal sequences. While automatic measures exist to compute time series similarity, human intervention is often required to visually inspect these automatically generated results. The visualization literature has examined similarity perception and its relation to automatic similarity measures for line charts, but has not yet considered if alternative visual representations, such as horizon graphs and colorfields, alter this perception. Motivated by how neuroscientists evaluate epileptiform patterns, we conducted two experiments that study how these three visualization techniques affect similarity perception in EEG signals. We seek to understand if the time series results returned from automatic similarity measures are perceived in a similar manner, irrespective of the visualization technique; and if what people perceive as similar with each visualization aligns with different automatic measures and their similarity constraints. Our findings indicate that horizon graphs align with similarity measures that allow local variations in temporal position or speed (i.e., dynamic time warping) more than the two other techniques. On the other hand, horizon graphs do not align with measures that are insensitive to amplitude and y-offset scaling (i.e., measures based on z-normalization), but the inverse seems to be the case for line charts and colorfields. Overall, our work indicates that the choice of visualization affects what temporal patterns we consider as similar, i.e., the notion of similarity in time series is not visualization independent.",,,,,vimeo 289785077,10.1109/tvcg.2018.2865077,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Time,24-Oct,9:00 AM,9:20 AM
TVCG,TVCG,A Multiresolution Streamgraph Approach to Explore Hierarchical Time Series,T),"Erick Cuenca, Arnaud Sallaberry, Florence Ying Wang, Pascal Poncelet",http://www.lirmm.fr/~poncelet/publications/papers/Multistream2018.pdf,"Multiple time series are a set of multiple quantitative variables occurring at the same interval. They are present in many domains such as medicine, finance, and manufacturing for analytical purposes. In recent years, streamgraph visualization (evolved from ThemeRiver) has been widely used for representing temporal evolution patterns in multiple time series. However, streamgraph as well as ThemeRiver suffer from scalability problems when dealing with several time series. To solve this problem, multiple time series can be organized into a hierarchical structure where individual time series are grouped hierarchically according to their proximity. In this paper, we present a new streamgraph-based approach to convey the hierarchical structure of multiple time series to facilitate the exploration and comparisons of temporal evolution. Based on a focus+context technique, our method allows time series exploration at different granularities (e. g., from overview to details). To illustrate our approach, two usage examples are presented.",http://advanse.lirmm.fr/multistream/,https://github.com/erickedu85/multistream,,,vimeo 289789365,10.1109/TVCG.2018.2796591,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Time,24-Oct,9:20 AM,9:40 AM
TVCG,TVCG,Line Graph or Scatter Plot? Automatic Selection of Methods for Visualizing Trends in Time Series,T),"Yunhai Wang, Fubo Han, Lifeng Zhu, Oliver Deussen, Baoquan Chen",http://www.yunhaiwang.org/vis-selection/timeseries.pdf,"Line graphs are usually considered to be the best choice for visualizing time series data, whereas sometimes also scatter plots are used for showing main trends. So far there are no guidelines that indicate which of these visualization methods better display trends in time series for a given canvas. Assuming that the main information in a time series is its overall trend, we propose an algorithm that automatically picks the visualization method that reveals this trend best. This is achieved by measuring the visual consistency between the trend curve represented by a LOESS fit and the trend described by a scatter plot or a line graph. To measure the consistency between our algorithm and user choices, we performed an empirical study with a series of controlled experiments that show a large correspondence. In a factor analysis we furthermore demonstrate that various visual and data factors have effects on the preference for a certain type of visualization.",,,,,vimeo 289788836,10.1109/tvcg.2017.2653106,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Time,24-Oct,9:40 AM,10:00 AM
TVCG,TVCG,A Vector Field Design Approach to Animated Transitions,T),"Yong Wang, Daniel Archambault, Carlos E. Scheidegger, Huamin Qu",http://www.cs.swansea.ac.uk/~csdarchambault/publications/animatedTransitionFinalSubVersion.pdf,"Animated transitions can be effective in explaining and exploring a small number of visualizations where there are drastic changes in the scene over a short interval of time. This is especially true if data elements cannot be visually distinguished by other means. Current research in animated transitions has mainly focused on linear transitions (all elements follow straight line paths) or enhancing coordinated motion through bundling of linear trajectories. In this paper, we introduce animated transition design, a technique to build smooth, non-linear transitions for clustered data with either minimal or no user involvement. The technique is flexible and simple to implement, and has the additional advantage that it explicitly enhances coordinated motion and can avoid crowding, which are both important factors to support object tracking in a scene. We investigate its usability, provide preliminary evidence for the effectiveness of this technique through metric evaluations and user study and discuss limitations and future directions.",,,,,vimeo 289789555,10.1109/tvcg.2017.2750689,2017,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Time,24-Oct,10:00 AM,10:20 AM
InfoVis,TVCG,Temporal Treemaps: Static Visualization of Evolving Trees,J),"Wiebke Köpp, Tino Weinkauf",http://www.csc.kth.se/~weinkauf/publications/documents/koepp19a.pdf,"We consider temporally evolving trees with changing topology and data: tree nodes may persist for a time range, merge or split, and the associated data may change. Essentially, one can think of this as a time series of trees with a node correspondence per hierarchy level between consecutive time steps. Existing visualization approaches for such data include animated 2D treemaps, where the dynamically changing layout makes it difficult to observe the data in its entirety. We present a method to visualize this dynamic data in a static, nested, and space-filling visualization. This is based on two major contributions: First, the layout constitutes a graph drawing problem. We approach it for the entire time span at once using a combination of a heuristic and simulated annealing. Second, we propose a rendering that emphasizes the hierarchy through an adaption of the classic cushion treemaps. We showcase the wide range of applicability using data from feature tracking in time-dependent scalar fields, evolution of file system hierarchies, and world population.",http://www.csc.kth.se/~weinkauf/publications/documents/koepp19a_algorithm.mp4,,,,vimeo 289784452,10.1109/TVCG.2018.2865265,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Time,24-Oct,10:20 AM,10:40 AM
SciVis,TVCG,Visual Analysis of Aneurysm Data using Statistical Graphics,J),"Monique Meuschke, Tobias Günther, Philipp Berg, Ralph Wickenhoefer, Markus Gross, Bernhard Preim, Kai Lawonn",https://cgl.ethz.ch/Downloads/Publications/Papers/2018/Meu18b/Meu18b.pdf,"This paper presents a framework to explore multi-field data of aneurysms occurring at intracranial and cardiac arteries by using statistical graphics. The rupture of an aneurysm is often a fatal scenario, whereas during treatment serious complications for the patient can occur. Whether an aneurysm ruptures or whether a treatment is successful depends on the interaction of different morphological such as wall deformation and thickness, and hemodynamic attributes like wall shear stress and pressure. Therefore, medical researchers are very interested in better understanding these relationships. However, the required analysis is a time-consuming process, where suspicious wall regions are difficult to detect due to the time-dependent behavior of the data. Our proposed visualization framework enables medical researchers to efficiently assess aneurysm risk and treatment options. This comprises a powerful set of views including 2D and 3D depictions of the aneurysm morphology as well as statistical plots of different scalar fields. Brushing and linking aids the user to identify interesting wall regions and to understand the influence of different attributes on the aneurysm’s state. Moreover, a visual comparison of pre- and post-treatment as well as different treatment options is provided. Our analysis techniques are designed in collaboration with domain experts, e.g., physicians, and we provide details about the evaluation.",,,,,vimeo 290325604,10.1109/tvcg.2018.2864509,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Biomedical Visualization,24-Oct,9:00 AM,9:20 AM
SciVis,TVCG,Interactive Visualization of 3D Histopathology in Native Resolution,J),"Martin Falk, Anders Ynnerman, Darren Treanor, Claes Lundström",http://scivis.itn.liu.se/publications/2019/FYTL19//falk-3dhistology-preprint.pdf," We present a visualization application that enables effective interactive visual analysis of large-scale 3D histopathology, that is, high-resolution 3D microscopy data of human tissue. Clinical work flows and research based on pathology have, until now, largely been dominated by 2D imaging. As we will show in the paper, studying volumetric histology data will open up novel and useful opportunities for both research and clinical practice. Our starting point is the current lack of appropriate visualization tools in histopathology, which has been a limiting factor in the uptake of digital pathology. Visualization of 3D histology data does pose difficult challenges in several aspects. The full-color datasets are dense and large in scale, on the order of 100,000 × 100,000× 100 voxels. This entails serious demands on both rendering performance and user experience design. Despite this, our developed application supports interactive study of 3D histology datasets at native resolution. Our application is based on tailoring and tuning of existing methods, system integration work, as well as a careful study of domain specific demands emanating from a close participatory design process with domain experts as team members. Results from a user evaluation employing the tool demonstrate a strong agreement among the 14 participating pathologists that 3D histopathology will be a valuable and enabling tool for their work",,,,,vimeo 290325921,10.1109/TVCG.2018.2864816,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Biomedical Visualization,24-Oct,9:20 AM,9:40 AM
SciVis,TVCG,Visualization of Neuronal Structures in Wide-field Microscopy Brain Images,J),"Saeed Boorboor, Shreeraj Jadhav, Mala Ananth, David Talmage, Lorna W Role, Arie Kaufman",,,,,,,vimeo 290328215,10.1109/TVCG.2018.2864852,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Biomedical Visualization,24-Oct,9:40 AM,10:00 AM
TVCG,TVCG,Classification of Blood Flow Patterns in Cerebral Aneurysms,T),"Monique Meuschke, Steffen Oeltze-Jafra, Oliver Beuing, Bernhard Preim, Kai Lawonn",,,,,,,youtube jI8GxKXaoU8,10.1109/tvcg.2018.2834923,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Biomedical Visualization,24-Oct,10:00 AM,10:20 AM
TVCG,TVCG,Bridging Text Visualization and Mining: A Task-Driven Survey,T),"Shixia Liu, Xiting Wang, Christopher Collins, Wenwen Dou, Fangxin Ouyang, Mennatallah El-Assady, Liu Jiang, Daniel Keim",,,,,,,vimeo 289789579,10.1109/tvcg.2018.2834341,2018,2018,VAST,Estrel Hall C,Wednesday,Text,24-Oct,9:00 AM,9:20 AM
VAST,TVCG,Doccurate: A Curation-Based Approach for Clinical Text Visualization,J),Nicole Sultanum,,,,,,,vimeo 289787431,10.1109/TVCG.2018.2864905,2018,2018,VAST,Estrel Hall C,Wednesday,Text,24-Oct,9:20 AM,9:40 AM
VAST,TVCG,VIS Author Profiles: Interactive Descriptions of Publication Records Combining Text and Visualization,J),"Shahid Latif, Fabian Beck, Devin Singh, Michael Brudno, Fanny Chevalier",https://www.vis.wiwi.uni-due.de/uploads/tx_itochairt3/publications/vap-preprint.pdf,"Publication records and collaboration networks are important for assessing the expertise and experience of researchers. Existing digital libraries show the raw publication lists in author profiles, whereas visualization techniques focus on specific subproblems. Instead, we look at publication records from various perspectives mixing low-level publication data with high-level abstractions and background information. This work presents VIS Author Profiles, a novel approach to generate integrated textual and visual descriptions to highlight patterns in publication records. We leverage template-based natural language generation to summarize notable publication statistics, evolution of research topics, and collaboration relationships. Seamlessly integrated visualizations augment the textual description and are interactively connected with each other and the text. The underlying publication data and detailed explanations of the analysis are available on demand. We compare our approach to existing systems by taking into account information needs of users and demonstrate its usefulness in two realistic application examples.",https://vis-tools.paluno.uni-due.de/vap/,,,,vimeo 289787504,10.1109/TVCG.2018.2865022,2018,2018,VAST,Estrel Hall C,Wednesday,Text,24-Oct,9:40 AM,10:00 AM
TVCG,TVCG,A Visual Analytics Framework for Identifying Topic Drivers in Media,T),"Yafeng Lu, Hong Wang, Steven Landis, Ross Maciejewski",http://rmaciejewski.faculty.asu.edu/papers/2018/Identifying%20Topic%20Drivers.pdf,"Media data has been the subject of large scale analysis with applications of text mining being used to provide overviews of media themes and information flows. Such information extracted from media articles has also shown its contextual value of being integrated with other data, such as criminal records and stock market pricing. In this work, we explore linking textual media data with curated secondary textual data sources through user-guided semantic lexical matching for identifying relationships and data links. In this manner, critical information can be identified and used to annotate media timelines in order to provide a more detailed overview of events that may be driving media topics and frames. These linked events are further analyzed through an application of causality modeling to model temporal drivers between the data series. Such causal links are then annotated through automatic entity extraction which enables the analyst to explore persons, locations, and organizations that may be pertinent to the media topic of interest. To demonstrate the proposed framework, two media datasets and an armed conflict event dataset are explored.",,,,,vimeo 289788885,10.1109/TVCG.2017.2752166,2018,2018,VAST,Estrel Hall C,Wednesday,Text,24-Oct,10:00 AM,10:20 AM
TVCG,TVCG,Visualizing a Thinker’s Life,T),"Patrick Riehmann, Dora Kiesel, Martin Kohlhaas, Bernd Fröhlich",,,,,,,vimeo 289789544,10.1109/TVCG.2018.2824822,2018,2018,VAST,Estrel Hall C,Wednesday,Text,24-Oct,10:20 AM,10:40 AM
TVCG,TVCG,Commercial Visual Analytics Systems – Advances in the Big Data Analytics Field,T),"Michael Behrisch, Dirk Streeb, Florian Stoffel, Daniel Seebacher, Stefan Hagen Weber, Sebastian Mittelstaedt, Hanspeter Pfister, Daniel Keim",https://commercialtools.dbvis.de/assets/data/submission/CommercialTools_TVCG_Journal_FINAL.pdf,"Five years after the first state-of-the-art report on Commercial Visual Analytics Systems we present a reevaluation of the Big Data Analytics field. We build on the success of the 2012 survey, which was influential even beyond the boundaries of the InfoVis and Visual Analytics (VA) community. While the field has matured significantly since the original survey, we find that innovation and research-driven development are increasingly sacrificed to satisfy a wide range of user groups. We evaluate new product versions on established evaluation criteria, such as available features, performance, and usability, to extend on and assure comparability with the previous survey. We also investigate previously unavailable products to paint a more complete picture of the commercial VA landscape. Furthermore, we introduce novel measures, like suitability for specific user groups and the ability to handle complex data types, and undertake a new case study to highlight innovative features. We explore the achievements in the commercial sector in addressing VA challenges and propose novel developments that should be on systems’ roadmaps in the coming years.",,https://commercialtools.dbvis.de/questions,,,vimeo 289789498,10.1109/TVCG.2018.2859973,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Applications,24-Oct,11:00 AM,11:20 AM
VAST,TVCG,BitExTract: Interactive Visualization for Extracting Bitcoin Exchange Intelligence,J),"Xuanwu Yue, Xinhuan Shu, Xinyu ZHU, Xinnan Du, Zheqing Yu, Dimitrios Papadopoulos, Siyuan Liu",,,,,,,vimeo 289787312,10.1109/TVCG.2018.2864814,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Applications,24-Oct,11:20 AM,11:40 AM
TVCG,TVCG,KAVAGait: Knowledge-Assisted Visual Analytics for Clinical Gait Analysis,T),"Markus Wagner, Djordje Slijepcevic, Brian Horsak, Alexander Rind, Matthias Zeppelzauer, Wolfgang Aigner",https://arxiv.org/pdf/1707.06105.pdf,"In 2014, more than 10 million people in the US were affected by an ambulatory disability. Thus, gait rehabilitation is a crucial part of health care systems. The quantification of human locomotion enables clinicians to describe and analyze a patient’s gait performance in detail and allows them to base clinical decisions on objective data. These assessments generate a vast amount of complex data which need to be interpreted in a short time period. We conducted a design study in cooperation with gait analysis experts to develop a novel Knowledge-Assisted Visual Analytics solution for clinical Gait analysis (KAVAGait). KAVAGait allows the clinician to store and inspect complex data derived during clinical gait analysis. The system incorporates innovative and interactive visual interface concepts, which were developed based on the needs of clinicians. Additionally, an explicit knowledge store (EKS) allows externalization and storage of implicit knowledge from clinicians. It makes this information available for others, supporting the process of data inspection and clinical decision making. We validated our system by conducting expert reviews, a user study, and a case study. Results suggest that KAVAGait is able to support a clinician during clinical practice by visualizing complex gait data and providing knowledge of other clinicians.",,,,,vimeo 289788975,10.1109/tvcg.2017.2785271,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Applications,24-Oct,11:40 AM,12:00 PM
TVCG,TVCG,Precision Risk Analysis of Cancer Therapy with Interactive Nomograms and Survival Plots,T),"G.Elisabeta Marai, Chihua Ma, Andrew T. Burks, Filippo Pellolio, Guadalupe Canahuate, David M. Vock, Abdallah S.R. Mohamed, C. David Fuller",https://www.evl.uic.edu/documents/ieee_precisionriskanalysis.pdf,"We present the design and evaluation of an integrated problem solving environment for cancer therapy analysis. The environment intertwines a statistical martingale model and a K Nearest Neighbor approach with visual encodings, including novel interactive nomograms, in order to compute and explain a patient’s probability of survival as a function of similar patient results. A coordinated views paradigm enables exploration of the multivariate, heterogeneous and few-valued data from a large head and neck cancer repository. A visual scaffolding approach further enables users to build from familiar representations to unfamiliar ones. Evaluation with domain experts show how this visualization approach and set of streamlined workflows enable the systematic and precise analysis of a patient prognosis in the context of cohorts of similar patients. We describe the design lessons learned from this successful, multi-site remote collaboration.",,,,,vimeo 289789079,10.1109/tvcg.2018.2817557,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Applications,24-Oct,12:00 PM,12:20 PM
VAST,VAST,VUSphere: Visual Analysis of Video Utilization in Online Distance Education,C),"Huan He, Qinghua Zheng, Bo Dong",,,,,,,vimeo 289788052,,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Applications,24-Oct,12:20 PM,12:40 PM
InfoVis,TVCG,Juniper: A Tree+Table Approach to Multivariate Graph Visualization,J),"Carolina Nobre, Marc Streit, Alexander Lex",https://arxiv.org/pdf/1804.03261.pdf,"Analyzing large, multivariate graphs is an important problem in many domains, yet such graphs are challenging to visualize. In this paper, we introduce a novel, scalable, tree+table multivariate graph visualization technique, which makes many tasks related to multivariate graph analysis easier to achieve. The core principle we follow is to selectively query for nodes or subgraphs of interest and visualize these subgraphs as a spanning tree of the graph. The tree is laid out linearly, which enables us to juxtapose the nodes with a table visualization where diverse attributes can be shown. We also use this table as an adjacency matrix, so that the resulting technique is a hybrid node-link/adjacency matrix technique. We implement this concept in Juniper and complement it with a set of interaction techniques that enable analysts to dynamically grow, restructure, and aggregate the tree, as well as change the layout or show paths between nodes. We demonstrate the utility of our tool in usage scenarios for different multivariate networks: a bipartite network of scholars, papers, and citation metrics and a multitype network of story characters, places, books, etc.",,https://github.com/caleydo/lineage/tree/juniper,,,vimeo 289784894,10.1109/TVCG.2018.2865149,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Graphs & Trees,24-Oct,11:00 AM,11:20 AM
TVCG,TVCG,Graph Thumbnails: Identifying and Comparing Multiple Graphs at a Glance,T),"Vahan Yoghourdjian, Tim Dwyer, Karsten Klein, Kim Marriott, Michael Wybrow",http://vahany.com/docs/Graph_Thumbnails_preprint.pdf,"We propose <i>Graph Thumbnails</i>, small icon-like visualisations of the high-level structure of network data. Graph Thumbnails are designed to be legible in small multiples to support rapid browsing within large graph corpora. Compared to existing graph-visualisation techniques our representation has several advantages: (1) the visualisation can be computed in linear time; (2) it is canonical in the sense that isomorphic graphs will always have identical thumbnails; and (3) it provides precise information about the graph structure. We report the results of two user studies. The first study compares Graph Thumbnails to node-link and matrix views for identifying similar graphs. The second study investigates the comprehensibility of the different representations. We demonstrate the usefulness of this representation for summarising the evolution of protein-protein interaction networks across a range of species.",,,,,vimeo 289789353,10.1109/tvcg.2018.2790961,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Graphs & Trees,24-Oct,11:20 AM,11:40 AM
InfoVis,TVCG,Structure-Based Suggestive Exploration: A New Approach for Effective Exploration of Large Networks,J),"Fangzhou Guo, Wei Chen, Dongming Han, Jiacheng Pan, Xiaotao Nie, Jiazhi Xia, Xiaolong (Luke) Zhang",http://www.cad.zju.edu.cn/home/vagblog/VAG_Work/Structure-Based%20Suggestive%20Exploration.pdf,"When analyzing a visualized network, users need to explore different sections of the network to gain insight. However, effective exploration of large networks is often a challenge. While various tools are available for users to explore the global and local features of a network, these tools usually require significant interaction activities, such as repetitive navigation actions to follow network nodes and edges. In this paper, we propose a structure-based suggestive exploration approach to support effective exploration of large networks by suggesting appropriate structures upon user request. Encoding nodes with vectorized representations by transforming information of surrounding structures of nodes into a high dimensional space, our approach can identify similar structures within a large network, enable user interaction with multiple similar structures simultaneously, and guide the exploration of unexplored structures. We develop a web-based visual exploration system to incorporate this suggestive exploration approach and compare performances of our approach under different vectorizing methods and networks. We also present the usability and effectiveness of our approach through a controlled user study with two datasets.",,,,,vimeo 289785045,10.1109/tvcg.2018.2865139,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Graphs & Trees,24-Oct,11:40 AM,12:00 PM
InfoVis,TVCG,Structure-aware Fisheye Views for Efficient Large Graph Exploration,J),"Yunhai Wang, Yanyan Wang, Yinqi Sun, Haifeng Zhang, Chi-Wing Fu, Michael Sedlmair, Baoquan Chen, Oliver Deussen",https://homepage.univie.ac.at/michael.sedlmair/papers/wang2019fisheye.pdf,"Traditional fisheye views for exploring large graphs introduce substantial distortions that often lead to a decreased readability of paths and other interesting structures. To overcome these problems, we propose a framework for <i>structure-aware</i> fisheye views. Using edge orientations as constraints for graph layout optimization allows us not only to reduce spatial and temporal distortions during fisheye zooms, but also to improve the readability of the graph structure. Furthermore, the framework enables us to optimize fisheye lenses towards specific tasks and design a family of new lenses: polyfocal, cluster, and path lenses. A GPU implementation lets us process large graphs with up to 15,000 nodes at interactive rates. A comprehensive evaluation, a user study, and two case studies demonstrate that our structure-aware fisheye views improve layout readability and user performance.",,,,,vimeo 289785238,10.1109/tvcg.2018.2864911,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Graphs & Trees,24-Oct,12:00 PM,12:20 PM
InfoVis,TVCG,"Graphicle: Exploring Units, Networks, and Context in a Blended Visualization Approach ",J),"Timothy Major, Rahul C. Basole",http://entsci.gatech.edu/resources/basole-2019-tvcg-graphicle.pdf,"Many real-world datasets are large, multivariate, and relational in nature and relevant associated decisions frequently require a simultaneous consideration of both attributes and connections. Existing visualization systems and approaches, however, often make an explicit trade-off between either affording rich exploration of individual data units and their attributes or exploration of the underlying network structure. In doing so, important analysis opportunities and insights are potentially missed. In this study, we aim to address this gap by (1) considering visualizations and interaction techniques that blend the spectrum between unit and network visualizations, (2) discussing the nature of different forms of contexts and the challenges in implementing them, and (3) demonstrating the value of our approach for visual exploration of multivariate, relational data for a real-world use case. Specifically, we demonstrate through a system called Graphicle how network structure can be layered on top of unit visualization techniques to create new opportunities for visual exploration of physician characteristics and referral data. We report on the design, implementation, and evaluation of the system and effectiveness of our blended approach.",,,,,vimeo 262664447,10.1109/tvcg.2018.2865151,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Graphs & Trees,24-Oct,12:20 PM,12:40 PM
SciVis,TVCG,Interactive Obstruction-free Lensing for Volumetric Data Visualization,J),"Michael Traoré, Christophe Hurter, Alexandru Telea",http://recherche.enac.fr/~hurter/ObstructionFreeLens/Vis2018Traore.pdf,"Occlusion is an issue in volumetric visualization as it prevents direct visualization of the region of interest. While many techniques such as transfer functions, volume segmentation or view distortion have been developed to address this, there is still room for improvement to better support the understanding of objects’ vicinity. However, most existing Focus+Context fail to solve partial occlusion in datasets where the target and the occluder are very similar density-wise. For these reasons, we investigate a new technique which maintains the general structure of the investigated volumetric dataset while addressing occlusion issues. With our technique, the user interactively defines an area of interest where an occluded region or object is partially visible. Then our lens starts pushing at its border occluding objects, thus revealing hidden volumetric data. Next, the lens is modified with an extended field of view (fish-eye deformation) to better see the vicinity of the selected region. Finally, the user can freely explore the surroundings of the area under investigation within the lens. To provide real-time exploration, we implemented our lens using a GPU accelerated ray-casting framework to handle ray deformations, local lighting, and local viewpoint manipulation. We illustrate our technique with five application scenarios in baggage inspection, 3D fluid flow visualization, chest radiology, air traffic planning, and DTI fiber exploration.",,,,,youtube FOiCmznSOz4,10.1109/TVCG.2018.2864690,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Volume Visualization,24-Oct,11:00 AM,11:20 AM
SciVis,TVCG,Dynamic Volume Lines: Visual Comparison of 3D Volumes through Space-filling Curves,J),"Johannes Weissenböck, Bernhard Fröhler, Eduard Gröller, Johann Kastner, Christoph Heinzl",,,,,,,vimeo 290325634,10.1109/tvcg.2018.2864510,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Volume Visualization,24-Oct,11:20 AM,11:40 AM
SciVis,TVCG,A Declarative Grammar of Flexible Volume Visualization Pipelines,J),"Min Shih, Charles Rozhon, Kwan-Liu Ma",,,,,,,vimeo 290327611,10.1109/tvcg.2018.2864841,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Volume Visualization,24-Oct,11:40 AM,12:00 PM
TVCG,TVCG,Multi-Material Volume Rendering with a Physically-Based Surface Reflection Model,T),"Oleg Igouchkine, Yubo Zhang, Kwan-Liu Ma",,,,,,,vimeo 289789120,10.1109/tvcg.2017.2784830,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Volume Visualization,24-Oct,12:00 PM,12:20 PM
TVCG,TVCG,A Generative Model for Volume Rendering,T),"Matthew Berger, Jixian Li, Joshua A. Levine",https://arxiv.org/pdf/1710.09545.pdf,"We present a technique to synthesize and analyze volume-rendered images using generative models. We use the Generative Adversarial Network (GAN) framework to compute a model from a large collection of volume renderings, conditioned on (1) viewpoint and (2) transfer functions for opacity and color. Our approach facilitates tasks for volume analysis that are challenging to achieve using existing rendering techniques such as ray casting or texture-based methods. We show how to guide the user in transfer function editing by quantifying expected change in the output image. Additionally, the generative model transforms transfer functions into a view-invariant latent space specifically designed to synthesize volume-rendered images. We use this space directly for rendering, enabling the user to explore the space of volume-rendered images. As our model is independent of the choice of volume rendering process, we show how to analyze volume-rendered images produced by direct and global illumination lighting, for a variety of volume datasets.",,https://github.com/matthewberger/tfgan,,,vimeo 289789468,10.1109/tvcg.2018.2816059,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Volume Visualization,24-Oct,12:20 PM,12:40 PM
InfoVis,TVCG,Vistrates: A Component Model for Ubiquitous Analytics,J),"Sriram Karthik Badam, Andreas Mathisen, Roman Rädle, Clemens Nylandsted Klokmose, Niklas Elmqvist",http://users.umiacs.umd.edu/~elm/projects/vistrates/vistrates.pdf,"Visualization tools are often specialized for specific tasks, which turns the user's analytical workflow into a fragmented process performed across many tools. In this paper, we present a component model design for data visualization to promote modular designs of visualization tools that enhance their analytical scope. Rather than fragmenting tasks across tools, the component model supports unification, where components—the building blocks of this model—can be assembled to support a wide range of tasks. Furthermore, the model also provides additional key properties, such as support for collaboration, sharing across multiple devices, and adaptive usage depending on expertise, from creating visualizations using dropdown menus, through instantiating components, to actually modifying components or creating entirely new ones from scratch using JavaScript or Python source code. To realize our model, we introduce VISTRATES, a literate computing platform for developing, assembling, and sharing visualization components. From a visualization perspective, Vistrates features cross-cutting components for visual representations, interaction, collaboration, and device responsiveness maintained in a component repository. From a development perspective, Vistrates offers a collaborative programming environment where novices and experts alike can compose component pipelines for specific analytical activities. Finally, we present several Vistrates use cases that span the full range of the classic ""anytime"" and ""anywhere"" motto for ubiquitous analysis: from mobile and on-the-go usage, through office settings, to collaborative smart environments covering a variety of tasks and devices.",,https://github.com/karthikbadam/Vistrates,,,vimeo 289784994,10.1109/tvcg.2018.2865144,2018,2018,InfoVis,Estrel Hall C,Wednesday,Devices,24-Oct,11:00 AM,11:20 AM
InfoVis,TVCG,SmartCues: A Multitouch Query Approach for Details-on-Demand through Dynamically Computed Overlays,J),"Hariharan Subramonyam, Eytan Adar",,,,,,,vimeo 289784720,10.1109/tvcg.2018.2865231,2018,2018,InfoVis,Estrel Hall C,Wednesday,Devices,24-Oct,11:20 AM,11:40 AM
InfoVis,TVCG,"Multiple Coordinated Views at Large Displays for Multiple Users: Empirical Findings on User Behavior, Movements, and Distances ",J),"Ricardo Langner, Ulrike Kister, Raimund Dachselt",,,,,,,vimeo 289784543,10.1109/tvcg.2018.2865235,2018,2018,InfoVis,Estrel Hall C,Wednesday,Devices,24-Oct,11:40 AM,12:00 PM
InfoVis,TVCG,Visualizing Ranges over Time on Mobile Phones: A Task-Based Crowdsourced Evaluation,J),"Matthew Brehmer, Bongshin Lee, Petra Isenberg, Eun Kyoung Choe",https://hal.inria.fr/hal-01857469/document,"In the first crowdsourced visualization experiment conducted exclusively on mobile phones, we compare approaches to visualizing ranges over time on small displays. People routinely consume such data via a mobile phone, from temperatures in weather forecasting apps to sleep and blood pressure readings in personal health apps. However, we lack guidance on how to effectively visualize ranges on small displays in the context of different value retrieval and comparison tasks, or with respect to different data characteristics such as periodicity, seasonality, or the cardinality of ranges. Central to our experiment is a comparison between two ways to lay out ranges: a more conventional linear layout strikes a balance between quantitative and chronological scale resolution, while a less conventional radial layout emphasizes the cyclicality of time and may prioritize discrimination between values at its periphery. With results from 87 crowd workers, we found that while participants completed tasks more quickly with linear layouts than with radial ones, there were few differences in terms of error rate between layout conditions. We also found that participants performed similarly with both layouts in tasks that involved comparing superimposed observed and average ranges.",,https://github.com/Microsoft/RangesOnMobile/blob/master/StudyApp,https://github.com/Microsoft/RangesOnMobile/blob/master/StudyDataAnalysis,,vimeo 289784625,10.1109/tvcg.2018.2865234,2018,2018,InfoVis,Estrel Hall C,Wednesday,Devices,24-Oct,12:00 PM,12:20 PM
InfoVis,TVCG,Glanceable Visualization: Studies of Data Comparison Performance on Smartwatches,J),"Tanja Blascheck, Lonni Besançon, Anastasia Bezerianos, Bongshin Lee, Petra Isenberg",https://hal.inria.fr/hal-01851306/file/Blascheck_2018_Glanceable_Visualization.pdf,"We present the results of two perception studies to assess how quickly people can perform a simple data comparison task for small-scale visualizations on a smartwatch. The main goal of these studies is to extend our understanding of design constraints for smartwatch visualizations. Previous work has shown that a vast majority of smartwatch interactions last under 5 s. It is still unknown what people can actually perceive from visualizations during such short glances, in particular with such a limited display space of smartwatches. To shed light on this question, we conducted two perception studies that assessed the lower bounds of task time for a simple data comparison task. We tested three chart types common on smartwatches: bar charts, donut charts, and radial bar charts with three different data sizes: 7, 12, and 24 data values. In our first study, we controlled the differences of the two target bars to be compared, while the second study varied the difference randomly. For both studies, we found that participants performed the task on average in <300 ms for the bar chart, <220 ms for the donut chart, and in <1780 ms for the radial bar chart. Thresholds in the second study per chart type were on average 1.14–1.35× higher than in the first study. Our results show that bar and donut charts should be preferred on smartwatch displays when quick data comparisons are necessary.",,,,,vimeo 289785013,10.1109/tvcg.2018.2865142,2018,2018,InfoVis,Estrel Hall C,Wednesday,Devices,24-Oct,12:20 PM,12:40 PM
CG&A,CGA,Physical Visualization of Geospatial Datasets,,"Hessam Djavaherpour, Ali Mahdavi-Amiri, Faramarz F. Samavati",,,,,,,vimeo 289785692,10.1109/mcg.2017.38,2017,2018,Other,Room III,Wednesday,CG&A Session 1,24-Oct,11:00 AM,11:20 AM
CG&A,CGA,Typology of Uncertainty in Static Geolocated Graphs for Visualization,,"Tatiana von Landesberger, Sebastian Bremm, Marcel Wunderlich",,,,,,,vimeo 289785707,10.1109/mcg.2017.3621220,2017,2018,Other,Room III,Wednesday,CG&A Session 1,24-Oct,11:20 AM,11:40 AM
CG&A,CGA,Impact of Spatial Scales on the Intercomparison of Climate Scenarios,,"Wei Luo, Michael Steptoe, Zheng Chang, Robert Link, Leon Clarke, Ross Maciejewski",,,,,,,vimeo 289785725,10.1109/mcg.2017.3621222,2017,2018,Other,Room III,Wednesday,CG&A Session 1,24-Oct,11:40 AM,12:00 PM
CG&A,CGA,Urban Space Explorer: A Visual Analytics System for Urban Planning,,"Alireza Karduni, Isaac Cho, Ginette Wessel, William Ribarsky, Eric Sauda, Wenwen Dou",,,,,,,vimeo 289785751,10.1109/mcg.2017.3621223,2017,2018,Other,Room III,Wednesday,CG&A Session 1,24-Oct,12:00 PM,12:20 PM
CG&A,CGA,Name Profiler Toolkit,,"Feng Wang, Brett Hansen, Ryan Simmons, Ross Maciejewski",http://rmaciejewski.faculty.asu.edu/papers/2017/Names-CGA.pdf,"The Name Profiler Toolkit is a visual analytics system designed to enable the interactive exploration and analysis of forename and surname geographical distributions across the United States. Using demographic data from the US Census Bureau and Zillow, the toolkit lets users interactively compare distributions of names and name attributes.",,,,,vimeo 289785766,10.1109/mcg.2017.3621224,2017,2018,Other,Room III,Wednesday,CG&A Session 1,24-Oct,12:20 PM,12:40 PM
VAST,TVCG,"SIRIUS: Dual, Symmetric, Interactive Dimension Reductions ",J),"Michelle Dowling, John Wenskovitch, J.T. Fry, Leanna House, Scotland Leman, Chris North",,,,,,,vimeo 289787667,10.1109/tvcg.2018.2865047,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,High Dimensional Data,24-Oct,2:20 PM,2:40 PM
TVCG,TVCG,A Perception-Driven Approach to Supervised Dimensionality Reduction for Visualization,T),"Yunhai Wang, Kang Feng, Xiaowei Chu, Jian Zhang, Chi-Wing Fu, Michael Sedlmair, Xiaohui Yu, Baoquan Chen",,,,,,,vimeo 289788938,10.1109/tvcg.2017.2701829,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,High Dimensional Data,24-Oct,2:40 PM,3:00 PM
VAST,VAST,SMARTexplore: Simplifying High-Dimensional Data Analysis through a Table-Based Visual Analytics Approach,C),"Michael Blumenschein, Michael Behrisch, Stefanie Schmid, Simon Butscher, Deborah R. Wahl, Karoline Villinger, Britta Renner, Harald Reiterer, Daniel Keim",https://bib.dbvis.de/uploadedFiles/BlumenscheinetalVAST2018SMARTexplore.pdf,"We present SMARTEXPLORE, a novel visual analytics technique that simplifies the identification and understanding of clusters, correlations, and complex patterns in high-dimensional data. The analysis is integrated into an interactive table-based visualization that maintains a consistent and familiar representation throughout the analysis. The visualization is tightly coupled with pattern matching, subspace analysis, reordering, and layout algorithms. To increase the analyst’s trust in the revealed patterns, SMARTEXPLORE automatically selects and computes statistical measures based on dimension and data properties. While existing approaches to analyzing highdimensional data (e.g., planar projections and Parallel coordinates) have proven effective, they typically have steep learning curves for non-visualization experts. Our evaluation, based on three expert case studies, confirms that non-visualization experts successfully reveal patterns in high-dimensional data when using SMARTEXPLORE.",,,,,vimeo 289787735,,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,High Dimensional Data,24-Oct,3:00 PM,3:20 PM
TVCG,TVCG,ColorMapND: A Data-Driven Approach and Tool for Mapping Multivariate Data to Color,T),"Shenghui Cheng, Wei Xu, Klaus Mueller",https://www3.cs.stonybrook.edu/~shecheng/Paper/ColormapND.pdf,"A wide variety of color schemes have been devised for mapping scalar data to color. We address the challenge of color-mapping multivariate data. While a number of methods can map low-dimensional data to color, for example, using bilinear or barycentric interpolation for two or three variables, these methods do not scale to higher data dimensions. Likewise, schemes that take a more artistic approach through color mixing and the like also face limits when it comes to the number of variables they can encode. Our approach does not have these limitations. It is data driven in that it determines a proper and consistent color map from first embedding the data samples into a circular interactive multivariate color mapping display (ICD) and then fusing this display with a convex (CIE HCL) color space. The variables (data attributes) are arranged in terms of their similarity and mapped to the ICD’s boundary to control the embedding. Using this layout, the color of a multivariate data sample is then obtained via modified generalized barycentric coordinate interpolation of the map. The system we devised has facilities for contrast and feature enhancement, supports both regular and irregular grids, can deal with multi-field as well as multispectral data, and can produce heat maps, choropleth maps, and diagrams such as scatterplots.",,,,,vimeo 289788955,10.1109/tvcg.2018.2808489,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,High Dimensional Data,24-Oct,3:20 PM,3:40 PM
VAST,VAST,EmbeddingVis: A Visual Analytics Approach to Comparative Network Embedding Inspection,C),"Quan Li, Kristanto Sean Njotoprawiro, Hammad Haleem, Qiaoan Chen, Chris YI, Xiaojuan Ma",https://arxiv.org/pdf/1808.09074.pdf,"Constructing latent vector representation for nodes in a network through embedding models has shown its practicality in many graph analysis applications, such as node classification, clustering, and link prediction. However, despite the high efficiency and accuracy of learning an embedding model, people have little clue of what information about the original network is preserved in the embedding vectors. The abstractness of low-dimensional vector representation, stochastic nature of the construction process, and non-transparent hyper-parameters all obscure understanding of network embedding results. Visualization techniques have been introduced to facilitate embedding vector inspection, usually by projecting the embedding space to a two-dimensional display. Although the existing visualization methods allow simple examination of the structure of embedding space, they cannot support in-depth exploration of the embedding vectors. In this paper, we design an exploratory visual analytics system that supports the comparative visual interpretation of embedding vectors at the cluster, instance, and structural levels. To be more specific, it facilitates comparison of what and how node metrics are preserved across different embedding models and investigation of relationships between node metrics and selected embedding vectors. Several case studies confirm the efficacy of our system. Experts’ feedback suggests that our approach indeed helps them better embrace the understanding of network embedding models.",,,,,vimeo 289788000,,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,High Dimensional Data,24-Oct,3:40 PM,4:00 PM
InfoVis,TVCG,Evaluating 'Graphical Perception' with CNNs,,"Daniel Haehn, James Tompkin, Hanspeter Pfister",https://danielhaehn.com/papers/haehn2018evaluating.pdf,"Convolutional neural networks can successfully perform many computer vision tasks on images. For visualization, how do CNNs perform when applied to graphical perception tasks? We investigate this question by reproducing Cleveland and McGill's seminal 1984 experiments, which measured human perception efficiency of different visual encodings and defined elementary perceptual tasks for visualization. We measure the graphical perceptual capabilities of four network architectures on five different visualization tasks and compare to existing and new human performance baselines. While under limited circumstances CNNs are able to meet or outperform human task performance, we find that CNNs are not currently a good model for human graphical perception. We present the results of these experiments to foster the understanding of how CNNs succeed and fail when applied to data visualizations.",,https://github.com/rhoana/perception,,,vimeo 280506639,10.1109/TVCG.2018.2865138,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Text & Communication,24-Oct,2:20 PM,2:40 PM
InfoVis,TVCG,NLIZE: A Perturbation-Driven Visual Interrogation Tool for Analyzing and Interpreting Natural Language Inference Models,J),"Shusen Liu, Zhimin Li, Tao Li, Vivek Srikumar, Valerio Pascucci, Peer-Timo Bremer",http://www.sci.utah.edu/~shusenl/publications/paper_entailVis.pdf,"With the recent advances in deep learning, neural network models have obtained state-of-the-art performances for many linguistic tasks in natural language processing. However, this rapid progress also brings enormous challenges. The opaque nature of a neural network model leads to hard-to-debug-systems and difficult-to-interpret mechanisms. Here, we introduce a visualization system that, through a tight yet flexible integration between visualization elements and the underlying model, allows a user to interrogate the model by perturbing the input, internal state, and prediction while observing changes in other parts of the pipeline. We use the natural language inference problem as an example to illustrate how a perturbation-driven paradigm can help domain experts assess the potential limitation of a model, probe its inner states, and interpret and form hypotheses about fundamental model mechanisms such as attention.",,,,,vimeo 289784737,10.1109/tvcg.2018.2865230,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Text & Communication,24-Oct,2:40 PM,3:00 PM
InfoVis,TVCG,Elastic Documents: Coupling Text and Tables through Contextual Visualizations for Enhanced Document Reading,J),"Sriram Karthik Badam, Zhicheng Liu, Niklas Elmqvist",http://users.umiacs.umd.edu/~elm/projects/elastic-documents/elastic-documents.pdf,"Today's data-rich documents are often complex datasets in themselves, consisting of information in different formats such as text, gures, and data tables. These additional media augment the textual narrative in the document. However, the static layout of a traditional for-print document often impedes deep understanding of its content because of the need to navigate to access content scattered throughout the text. In this paper, we seek to facilitate enhanced comprehension of such documents through a contextual visualization technique that couples text content with data tables contained in the document. We parse the text content and data tables, cross-link the components using a keyword-based matching algorithm, and generate on-demand visualizations based on the reader's current focus within a document. We evaluate this technique in a user study comparing our approach to a traditional reading experience. Results from our study show that (1) participants comprehend the content better with tighter coupling of text and data, (2) the contextual visualizations enable participants to develop better summaries that capture the main data-rich insights within the document, and (3) overall, our method enables participants to develop a more detailed understanding of the document content.",,,,,vimeo 289784966,10.1109/TVCG.2018.2865119,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Text & Communication,24-Oct,3:00 PM,3:20 PM
InfoVis,TVCG,Augmenting Visualizations with Interactive Data Facts to Facilitate Interpretation and Communication,J),"Arjun Srinivasan, Steven Drucker, Alex Endert, John Stasko",https://arjun010.github.io/static/papers/voder-infovis18.pdf,"Recently, an increasing number of visualization systems have begun to incorporate natural language generation (NLG) capabilities into their interfaces. NLG-based visualization systems typically leverage a suite of statistical functions to automatically extract key facts about the underlying data and surface them as natural language sentences alongside visualizations. With current systems, users are typically required to read the system-generated sentences and mentally map them back to the accompanying visualization. However, depending on the features of the visualization (e.g., visualization type, data density) and the complexity of the data fact, mentally mapping facts to visualizations can be a challenging task. Furthermore, more than one visualization could be used to illustrate a single data fact. Unfortunately, current tools provide little or no support for users to explore such alternatives. In this paper, we explore how system-generated data facts can be treated as interactive widgets to help users interpret visualizations and communicate their findings. We present Voder, a system that lets users interact with automatically-generated data facts to explore both alternative visualizations to convey a data fact as well as a set of embellishments to highlight a fact within a visualization. Leveraging data facts as interactive widgets, Voder also facilitates data fact-based visualization search. To assess Voder's design and features, we conducted a preliminary user study with 12 participants having varying levels of experience with visualization tools. Participant feedback suggested that interactive data facts aided them in interpreting visualizations. Participants also stated that the suggestions surfaced through the facts helped them explore alternative visualizations and embellishments to communicate individual data facts.",,,,,vimeo 289784943,10.1109/tvcg.2018.2865145,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Text & Communication,24-Oct,3:20 PM,3:40 PM
InfoVis,TVCG,What Do We Talk About When We Talk About Dashboards?,J),"Alper Sarikaya, Michael Correll, Lyn Bartram, Melanie Tory, Danyel A Fisher",https://alper.datav.is/assets/publications/dashboards/dashboards-preprint.pdf,"Dashboards are one of the most common use cases for data visualization, and their design and contexts of use are considerably different from exploratory visualization tools. In this paper, we look at the broad scope of how dashboards are used in practice through an analysis of dashboard examples and documentation about their use. We systematically review the literature surrounding dashboard use, construct a design space for dashboards, and identify major dashboard types. We characterize dashboards by their design goals, levels of interaction, and the practices around them. Our framework and literature review suggest a number of fruitful research directions to better support dashboard design, implementation, and use.",,,,,vimeo 289785315,10.1109/tvcg.2018.2864903,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Text & Communication,24-Oct,3:40 PM,4:00 PM
SciVis,TVCG,Visualization of Bubble Formation in Porous Media,J),"Hui Zhang, Steffen Frey, Holger Steeb, David Uribe, Thomas Ertl, Wenping Wang",,,,,,,vimeo 290325359,10.1109/tvcg.2018.2864506,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Space and Physics,24-Oct,2:20 PM,2:40 PM
SciVis,TVCG,Gaia Sky: Navigating the Gaia Catalog,J),"Toni Sagristà Sellés, Stefan Jordan, Thomas Mueller, Filip Sadlo",https://vcg.iwr.uni-heidelberg.de/static/publications/Sagrista2019gaiaSky.pdf,"In this paper, we present Gaia Sky, a free and open-source multiplatform 3D Universe system, developed since 2014 in the Data Processing and Analysis Consortium framework of ESA’s Gaia mission. Gaia’s data release 2 represents the largest catalog of the stars of our Galaxy, comprising 1.3 billion star positions, with parallaxes, proper motions, magnitudes, and colors. In this mission, Gaia Sky is the central tool for off-the-shelf visualization of these data, and for aiding production of outreach material. With its capabilities to effectively handle these data, to enable seamless navigation along the high dynamic range of distances, and at the same time to provide advanced visualization techniques including relativistic aberration and gravitational wave effects, currently no actively maintained cross-platform, modern, and open alternative exists.",,,,,vimeo 290325474,10.1109/tvcg.2018.2864508,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Space and Physics,24-Oct,2:40 PM,3:00 PM
SciVis,TVCG,Interactive 3D Visual Analysis of Atmospheric Fronts,J),"Michael Alexander Kern, Timothy David Hewson, Andreas Schäfler, Rüdiger Westermann, Marc Rautenhaus",http://www.in.tum.de/fileadmin/w00bws/cg/Research/Publications/2018/Atmospheric_Fronts/kern_fronts_vis2018.pdf,"Atmospheric fronts play a central role in meteorology, as the boundaries between different air masses and as fundamental features of extra-tropical cyclones. They appear in numerous conceptual model depictions of extra-tropical weather systems. Conceptually, fronts are three-dimensional surfaces in space possessing an innate structural complexity, yet in meteorology, both manual and objective identification and depiction have historically focused on the structure in two dimensions. In this work, we –a team of visualization scientists and meteorologists– propose a novel visualization approach to analyze the three-dimensional structure of atmospheric fronts and related physical and dynamical processes. We build upon existing approaches to objectively identify fronts as lines in two dimensions and extend these to obtain frontal surfaces in three dimensions, using the magnitude of temperature change along the gradient of a moist potential temperature field as the primary identifying factor. We introduce the use of normal curves in the temperature gradient field to visualize a frontal zone (i.e., the transitional zone between the air masses) and the distribution of atmospheric variables in such zones. To enable for the first time a statistical analysis of frontal zones, we present a new approach to obtain the volume enclosed by a zone, by classifying grid boxes that intersect with normal curves emanating from a selected front. We introduce our method by means of an idealized numerical simulation and demonstrate its use with two real-world cases using numerical weather prediction data.",,,,,vimeo 290325737,10.1109/tvcg.2018.2864806,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Space and Physics,24-Oct,3:00 PM,3:20 PM
SciVis,TVCG,An Interactive Framework for Visualization of Weather Forecast Ensembles,J),"Bo Ma, Alireza Entezari",,,,,,,youtube 2tsXxxLsU7U,10.1109/tvcg.2018.2864815,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Space and Physics,24-Oct,3:20 PM,3:40 PM
TVCG,TVCG,Animation Plans for Before-And-After Satellite images,T),"María-Jesús Lobo, Caroline Appert, Emmanuel Pietriga",https://hal.inria.fr/hal-01773882/document,"Before-and-after image pairs show how entities in a given region have evolved over a specific period of time. Satellite images are a major source of such data, that capture how natural phenomena or human activity impact a geographical area. These images are used both for data analysis and to illustrate the resulting findings to diverse audiences. The simple techniques used to display them, including juxtaposing, swapping and monolithic blending, often fail to convey the underlying phenomenon in a meaningful manner. We introduce Baia, a framework to create advanced animated transitions, called animation plans, between before-and-after images. Baia relies on a pixel-based transition model that gives authors much expressive power, while keeping animations for common types of changes easy to create thanks to predefined animation primitives. We describe our model, the associated animation editor, and report on two user studies. In the first study, advanced transitions enabled by Baia were compared to monolithic blending, and perceived as more realistic and better at focusing viewer’s attention on a region of interest than the latter. The second study aimed at gathering feedback about the usability of Baia’s animation editor. ",,,,,vimeo 289789265,10.1109/TVCG.2018.2796557,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Space and Physics,24-Oct,3:40 PM,4:00 PM
VAST,TVCG,Vulnus: Visual Vulnerability Analysis for Network Security,J),"Marco Angelini, Graziano Blasilli, Tiziana Catarci, Simone Lenti, Giuseppe Santucci",,,,,,,vimeo 289787623,10.1109/tvcg.2018.2865028,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,"Security, Privacy, and Anomaly",25-Oct,9:00 AM,9:20 AM
VAST,TVCG,GraphProtector: a Visual Interface for Employing and Assessing Multiple Privacy Preserving Graph Algorithms,J),"Xumeng Wang, Wei Chen, Huihua Guan, Wenlong Chen, Rusheng Pan, Jia-Kai Chou, Chris Bryan, Kwan-Liu Ma",http://www.cad.zju.edu.cn/home/vagblog/VAG_Work/GraphProtector.pdf,"Analyzing social networks reveals the relationships between individuals and groups in the data. However, such analysis can also lead to privacy exposure (whether intentionally or inadvertently): leaking the real-world identity of ostensibly anonymous individuals. Most sanitization strategies modify the graph's structure based on hypothesized tactics that an adversary would employ. While combining multiple anonymization schemes provides a more comprehensive privacy protection, deciding the appropriate set of techniques—along with evaluating how applying the strategies will affect the utility of the anonymized results—remains a signicant challenge. To address this problem, we introduce GraphProtector, a visual interface that guides a user through a privacy preservation pipeline. GraphProtector enables multiple privacy protection schemes which can be simultaneously combined together as a hybrid approach. To demonstrate the effectiveness of GraphProtector, we report several case studies and feedback collected from interviews with expert users in various scenarios.",,,,,vimeo 289787471,10.1109/TVCG.2018.2865021,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,"Security, Privacy, and Anomaly",25-Oct,9:20 AM,9:40 AM
VAST,TVCG,Situ: Identifying and explaining suspicious behavior in networks,J),"John Goodall, Eric Ragan, Chad Steed, Joel Reed, Gregory Richardson, Kelly Huffer, Robert Bridges, Jason Laska",https://www.cise.ufl.edu/~eragan/papers/Goodall_Situ_2018.pdf,"Despite the best efforts of cyber security analysts, networked computing assets are routinely compromised, resulting in the loss of intellectual property, the disclosure of state secrets, and major nancial damages. Anomaly detection methods are benecial for detecting new types of attacks and abnormal network activity, but such algorithms can be difcult to understand and trust. Network operators and cyber analysts need fast and scalable tools to help identify suspicious behavior that bypasses automated security systems, but operators do not want another automated tool with algorithms they do not trust. Experts need tools to augment their own domain expertise and to provide a contextual understanding of suspicious behavior to help them make decisions. In this paper we present Situ, a visual analytics system for discovering suspicious behavior in streaming network data. Situ provides a scalable solution that combines anomaly detection with information visualization. The system's visualizations enable operators to identify and investigate the most anomalous events and IP addresses, and the tool provides context to help operators understand why they are anomalous. Finally, operators need tools that can be integrated into their workow and with their existing tools. This paper describes the Situ platform and its deployment in an operational network setting. We discuss how operators are currently using the tool in a large organization's security operations center and present the results of expert reviews with professionals.",,,,,vimeo 289787635,10.1109/TVCG.2018.2865029,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,"Security, Privacy, and Anomaly",25-Oct,9:40 AM,10:00 AM
VAST,TVCG,A Visual Analytics Framework for the Detection of Anomalous Call Stack Trees in High Performance Computing Applications,J),"Cong Xie, Wei Xu, Klaus Mueller",,,,,,,vimeo 289787924,10.1109/tvcg.2018.2865026,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,"Security, Privacy, and Anomaly",25-Oct,10:00 AM,10:20 AM
VAST,TVCG,Lessons Learned Developing a Visual Analytics Solution for Investigative Analysis of Scamming Activities,J),"Jay Koven, Cristian Felix, Hossein Siadati, Enrico Bertini, Markus Jakobsson",,,,,,,vimeo 289787515,10.1109/tvcg.2018.2865023,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,"Security, Privacy, and Anomaly",25-Oct,10:20 AM,10:40 AM
InfoVis,TVCG,Origin-Destination Flow Maps in Immersive Environments,J),"Yalong Yang, Tim Dwyer, Bernhard Jenny, Kim Marriott, Maxime Cordeil, Haohui Chen",https://ialab.it.monash.edu/~dwyer/papers/flow-maps-ia.pdf,"Immersive virtual- and augmented-reality headsets can overlay a flat image against any surface or hang virtual objects in the space around the user. The technology is rapidly improving and may, in the long term, replace traditional flat panel displays in many situations. When displays are no longer intrinsically flat, how should we use the space around the user for abstract data visualisation? In this paper, we ask this question with respect to origin-destination flow data in a global geographic context. We report on the findings of three studies exploring different spatial encodings for flow maps. The first experiment focuses on different 2D and 3D encodings for flows on flat maps. We find that participants are significantly more accurate with raised flow paths whose height is proportional to flow distance but fastest with traditional straight line 2D flows. In our second and third experiment we compared flat maps, 3D globes and a novel interactive design we call <i>MapsLink</i>, involving a pair of linked flat maps. We find that participants took significantly more time with MapsLink than other flow maps while the 3D globe with raised flows was the fastest, most accurate, and most preferred method. Our work suggests that <i>careful</i> use of the third spatial dimension can resolve visual clutter in complex flow maps.",,,,,vimeo 279605506,10.1109/tvcg.2018.2865192,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Immersive Analytics,25-Oct,9:00 AM,9:20 AM
InfoVis,TVCG,FiberClay: Sculpting Three Dimensional Trajectories to Reveal Structural Insights,J),"Christophe Hurter, Nathalie Henry Riche, Steven Drucker, Maxime Cordeil, Richard Alligier, Romain Vuillemot",https://recherche.enac.fr/~hurter/FiberClay/FiberClay2018.pdf,"Visualizing 3D trajectories to extract insights about their similarities and spatial configuration is a critical task in several domains. Air traffic controllers for example deal with large quantities of aircrafts routes to optimize safety in airspace and neuroscientists attempt to understand neuronal pathways in the human brain by visualizing bundles of fibers from DTI images. Extracting insights from masses of 3D trajectories is challenging as the multiple three dimensional lines have complex geometries, may overlap, cross or even merge with each other, making it impossible to follow individual ones in dense areas. As trajectories are inherently spatial and three dimensional, we propose FiberClay: a system to display and interact with 3D trajectories in immersive environments. FiberClay renders a large quantity of trajectories in real time using GP-GPU techniques. FiberClay also introduces a new set of interactive techniques for composing complex queries in 3D space leveraging immersive environment controllers and user position. These techniques enable an analyst to select and compare sets of trajectories with specific geometries and data properties. We conclude by discussing insights found using FiberClay with domain experts in air traffic control and neurology.",,,,,vimeo 289784766,10.1109/tvcg.2018.2865191,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Immersive Analytics,25-Oct,9:20 AM,9:40 AM
InfoVis,TVCG,DXR: A Toolkit for Building Immersive Data Visualizations,J),"Ronell Sicat, Jiabao Li, JunYoung Choi, Maxime Cordeil, Won-Ki Jeong, Benjamin Bach, Hanspeter Pfister",https://vcg.seas.harvard.edu/publications/dxr-a-toolkit-for-building-immersive-data-visualizations/paper,"This paper presents DXR, a toolkit for building immersive data visualizations based on the Unity development platform. Over the past years, immersive data visualizations in augmented and virtual reality (AR, VR) have been emerging as a promising medium for data sense-making beyond the desktop. However, creating immersive visualizations remains challenging, and often require complex low-level programming and tedious manual encoding of data attributes to geometric and visual properties. These can hinder the iterative idea-to-prototype process, especially for developers without experience in 3D graphics, AR, and VR programming. With DXR, developers can efficiently specify visualization designs using a concise declarative visualization grammar inspired by Vega-Lite. DXR further provides a GUI for easy and quick edits and previews of visualization designs in-situ, i.e., while immersed in the virtual world. DXR also provides reusable templates and customizable graphical marks, enabling unique and engaging visualizations. We demonstrate the flexibility of DXR through several examples spanning a wide range of applications.",,https://sites.google.com/view/dxr-vis/,,,youtube p4fB_OfoaZA,10.1109/tvcg.2018.2865152,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Immersive Analytics,25-Oct,9:40 AM,10:00 AM
InfoVis,TVCG,Information Olfactation: Harnessing Scent to Convey Data,J),"Biswaksen Patnaik, Andrea Batch, Niklas Elmqvist",http://users.umiacs.umd.edu/~elm/projects/info-olfac/info-olfac.pdf,"Olfactory feedback for analytical tasks is a virtually unexplored area in spite of the advantages it offers for information recall, feature identification, and location detection. Here we introduce the concept of information olfactation as the fragrant sibling of information visualization, and discuss how scent can be used to convey data. Building on a review of the human olfactory system and mirroring common visualization practice, we propose olfactory marks, the substrate in which they exist, and their olfactory channels that are available to designers. To exemplify this idea, we present VISCENT: A six-scent stereo olfactory display capable of conveying olfactory glyphs of varying temperature and direction, as well as a corresponding software system that integrates the display with a traditional visualization display. Finally, we present three applications that make use of the viScent system: A 2D graph visualization, a 2D line and point chart, and an immersive analytics graph visualization in 3D virtual reality. We close the paper with a review of possible extensions of viScent and applications of information olfactation for general visualization beyond the examples in this paper.",,,,,vimeo 289784509,10.1109/tvcg.2018.2865237,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Immersive Analytics,25-Oct,10:00 AM,10:20 AM
InfoVis,TVCG,Dynamic Composite Data Physicalization Using Wheeled Micro-Robots,J),"Mathieu Le Goc, Charles Perin, Sean Follmer, Jean-Daniel Fekete, Pierre Dragicevic",https://hal.inria.fr/hal-01848436/document,"This paper introduces dynamic composite physicalizations, a new class of physical visualizations that use collections of self-propelled objects to represent data. Dynamic composite physicalizations can be used both to give physical form to well-known interactive visualization techniques, and to explore new visualizations and interaction paradigms. We first propose a design space characterizing composite physicalizations based on previous work in the fields of Information Visualization and Human Computer Interaction. We illustrate dynamic composite physicalizations in two scenarios demonstrating potential benefits for collaboration and decision making, as well as new opportunities for physical interaction. We then describe our implementation using wheeled micro-robots capable of locating themselves and sensing user input, before discussing limitations and opportunities for future work.",,,,,vimeo 289784806,10.1109/tvcg.2018.2865159,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Immersive Analytics,25-Oct,10:20 AM,10:40 AM
SciVis,TVCG,Robust and Fast Extraction of 3D Symmetric Tensor Field Topology,J),"Lawrence Roy, Prashant Kumar, Yue Zhang, Eugene Zhang",http://web.engr.oregonstate.edu/~zhange/images/3DTensorTopology_Detection.pdf,"3D symmetric tensor fields appear in many science and engineering domains, and topology-driven analysis is important in many of these application domains, such as solid mechanics and fluid dynamics. Degenerate curves and neutral surfaces are important topological features in 3D symmetric tensor fields. Existing methods to extract degenerate curves and neutral surfaces often miss parts of the curves and surfaces, respectively. Moreover, they are relatively expensive to extract. These issues are due to the lack of knowledge of their overall structures. In this paper, we provide theoretical analysis on the geometric and topological structures of degenerate curves and neutral surfaces of 3D linear tensor fields. These structures lead to parameterizations for degenerate curves and neutral surfaces that can not only provide more robust extraction of these features but also incur less computational cost. We demonstrate the benefits of our approach by applying our degenerate curve and neutral surface detection to solid mechanics simulation data sets.",,,,,vimeo 290325698,10.1109/tvcg.2018.2864768,2018,2018,SciVis,Estrel Hall A+B,Thursday,Tensors,25-Oct,9:00 AM,9:20 AM
SciVis,TVCG,DT-MRI Streamsurfaces Revisited,J),"Michael Ankele, Thomas Schultz",http://cg.cs.uni-bonn.de/aigaion2root/attachments/ankele-vis18.pdf,"DT-MRI streamsurfaces, defined as surfaces that are everywhere tangential to the major and medium eigenvector fields, have been proposed as a tool for visualizing regions of predominantly planar behavior in diffusion tensor MRI. Even though it has long been known that their construction assumes that the involved eigenvector fields satisfy an integrability condition, it has never been tested systematically whether this condition is met in real-world data. We introduce a suitable and efficiently computable test to the visualization literature, demonstrate that it can be used to distinguish integrable from nonintegrable configurations in simulations, and apply it to whole-brain datasets of 15 healthy subjects. We conclude that streamsurface integrability is approximately satisfied in a substantial part of the brain, but not everywhere, including some regions of planarity. As a consequence, algorithms for streamsurface extraction should explicitly test local integrability. Finally, we propose a novel patch-based approch to streamsurface visualization that reduces visual artifacts, and is shown to more fully sample the extent of streamsurfaces.",,,,,vimeo 290327825,10.1109/tvcg.2018.2864845,2018,2018,SciVis,Estrel Hall A+B,Thursday,Tensors,25-Oct,9:20 AM,9:40 AM
SciVis,TVCG,Tensor Field Visualization using Fiber Surfaces of Invariant Space,J),"Felix Raith, Christian Blecha, Thomas Nagel, Francesco Parisio, Olaf Kolditz, Fabian Günther, Markus Stommel, Gerik Scheuermann",,,,,,,vimeo 290327914,10.1109/tvcg.2018.2864846,2018,2018,SciVis,Estrel Hall A+B,Thursday,Tensors,25-Oct,9:40 AM,10:00 AM
TVCG,TVCG,Tensor Decompositions for Integral Histogram Compression and Look-Up,T),"Rafael Ballester-Ripoll, Renato Pajarola",,,,https://github.com/rballester/tthistograms,,,vimeo 289788992,10.1109/tvcg.2018.2802521,2018,2018,SciVis,Estrel Hall A+B,Thursday,Tensors,25-Oct,10:00 AM,10:20 AM
VAST,TVCG,An Interactive Method to Improve Crowdsourced Annotations,J),"Shixia Liu, Changjian Chen, Yafeng Lu, Fangxin Ouyang, Bin Wang",http://www.shixialiu.com/publications/LabelInspect/paper.pdf,"In order to effectively infer correct labels from noisy crowdsourced annotations, learning-from-crowds models have introduced expert validation. However, little research has been done on facilitating the validation procedure. In this paper, we propose an interactive method to assist experts in verifying uncertain instance labels and unreliable workers. Given the instance labels and worker reliability inferred from a learning-from-crowds model, candidate instances and workers are selected for expert validation. The influence of verified results is propagated to relevant instances and workers through the learning-from-crowds model. To facilitate the validation of annotations, we have developed a confusion visualization to indicate the confusing classes for further exploration, a constrained projection method to show the uncertain labels in context, and a scatter-plot-based visualization to illustrate worker reliability. The three visualizations are tightly integrated with the learning-from-crowds model to provide an iterative and progressive environment for data validation. Two case studies were conducted that demonstrate our approach offers an efficient method for validating and improving crowdsourced annotations.",,,,,vimeo 289787374,10.1109/TVCG.2018.2864843,2018,2018,VAST,Estrel Hall C,Thursday,Interactive Analytics and Design,25-Oct,9:00 AM,9:20 AM
VAST,TVCG,RegressionExplorer: Interactive Exploration of Logistic Regression Models with Subgroup Analysis,J),"Dennis Dingen, Marcel van 't Veer, Patrick Houthuizen, Eveline H. J. Mestrom, Erik H.H.M. Korsten, Arthur R.A. Bouwman, Jarke van Wijk",,,,,,,vimeo 289787606,10.1109/tvcg.2018.2865043,2018,2018,VAST,Estrel Hall C,Thursday,Interactive Analytics and Design,25-Oct,9:20 AM,9:40 AM
VAST,TVCG,Drag and Track:  A Direct Manipulation Interface for Contextualizing Data Instances within a Continuous Parameter Space,J),"Daniel Orban, Daniel Keefe, Ayan Biswas, James Ahrens, David Rogers",,,,,,,vimeo 289787986,10.1109/TVCG.2018.2865051,2018,2018,VAST,Estrel Hall C,Thursday,Interactive Analytics and Design,25-Oct,9:40 AM,10:00 AM
VAST,TVCG,Clustrophile 2: Guided Visual Clustering Analysis,J),"Marco Cavallo, Çagatay Demiralp",https://arxiv.org/pdf/1804.03048.pdf,"Data clustering is a common unsupervised learning method frequently used in exploratory data analysis. However, identifying relevant structures in unlabeled, high-dimensional data is nontrivial, requiring iterative experimentation with clustering parameters as well as data features and instances. The number of possible clusterings for a typical dataset is vast, and navigating in this vast space is also challenging. The absence of ground-truth labels makes it impossible to define an optimal solution, thus requiring user judgment to establish what can be considered a satisfiable clustering result. Data scientists need adequate interactive tools to effectively explore and navigate the large clustering space so as to improve the effectiveness of exploratory clustering analysis. We introduce Clustrophile 2, a new interactive tool for guided clustering analysis. Clustrophile 2 guides users in clustering-based exploratory analysis, adapts user feedback to improve user guidance, facilitates the interpretation of clusters, and helps quickly reason about differences between clusterings. To this end, Clustrophile 2 contributes a novel feature, the Clustering Tour, to help users choose clustering parameters and assess the quality of different clustering results in relation to current analysis goals and user expectations. We evaluate Clustrophile 2 through a user study with 12 data scientists, who used our tool to explore and interpret sub-cohorts in a dataset of Parkinson’s disease patients. Results suggest that Clustrophile 2 improves the speed and effectiveness of exploratory clustering analysis for both experts and non-experts.",,,,,vimeo 289787185,10.1109/TVCG.2018.2864477,2018,2018,VAST,Estrel Hall C,Thursday,Interactive Analytics and Design,25-Oct,10:00 AM,10:20 AM
VAST,TVCG,InkPlanner: Supporting Prewriting via Intelligent Visual Diagramming,J),"Zhicong Lu, Mingming Fan, Yun Wang, Jian Zhao, Michelle Annett, Daniel Wigdor",http://mingmingfan.com/papers/InkPlanner_TVCG.pdf,"Prewriting is the process of generating and organizing ideas before drafting a document. Although often overlooked by novice writers and writing tool developers, prewriting is a critical process that improves the quality of a final document. To better understand current prewriting practices, we first conducted interviews with writing learners and experts. Based on the learners’ needs and experts’ recommendations, we then designed and developed InkPlanner, a novel pen and touch visualization tool that allows writers to utilize visual diagramming for ideation during prewriting. InkPlanner further allows writers to sort their ideas into a logical and sequential narrative by using a novel widget— NarrativeLine. Using a NarrativeLine, InkPlanner can automatically generate a document outline to guide later drafting exercises. Inkplanner is powered by machine-generated semantic and structural suggestions that are curated from various texts. To qualitatively review the tool and understand how writers use InkPlanner for prewriting, two writing experts were interviewed and a user study was conducted with university students. The results demonstrated that InkPlanner encouraged writers to generate more diverse ideas and also enabled them to think more strategically about how to organize their ideas for later drafting.",,,,,vimeo 289787883,10.1109/tvcg.2018.2864887,2018,2018,VAST,Estrel Hall C,Thursday,Interactive Analytics and Design,25-Oct,10:20 AM,10:40 AM
TVCG,TVCG,Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers,T),"Fred Hohman, Minsuk Kahng, Robert Pienta, Duen Horng Chau",https://arxiv.org/pdf/1801.06889.pdf,"Deep learning has recently seen rapid development and received significant attention due to its state-of-the-art performance on previously-thought hard problems. However, because of the internal complexity and nonlinear structure of deep neural networks, the underlying decision making processes for why these models are achieving such performance are challenging and sometimes mystifying to interpret. As deep learning spreads across domains, it is of paramount importance that we equip users of deep learning with tools for understanding when a model works correctly, when it fails, and ultimately how to improve its performance. Standardized toolkits for building neural networks have helped democratize deep learning; visual analytics systems have now been developed to support model explanation, interpretation, debugging, and improvement. We present a survey of the role of visual analytics in deep learning research, which highlights its short yet impactful history and thoroughly summarizes the state-of-the-art using a human-centered interrogative framework, focusing on the Five W's and How (Why, Who, What, How, When, and Where). We conclude by highlighting research directions and open research problems. This survey helps researchers and practitioners in both visual analytics and deep learning to quickly learn key aspects of this young and rapidly growing body of research, whose impact spans a diverse range of domains.",,,,,vimeo 289789596,10.1109/tvcg.2018.2843369,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Deep Learning,25-Oct,11:00 AM,11:20 AM
VAST,VAST,Analyzing the Noise Robustness of Deep Neural Networks,C),"Mengchen Liu, Shixia Liu, Hang Su, Kelei Cao, Jun Zhu",http://www.shixialiu.com/publications/aevis/paper.pdf,"Deep neural networks (DNNs) are vulnerable to maliciously generated adversarial examples. These examples are intentionally designed by making imperceptible perturbations and often mislead a DNN into making an incorrect prediction. This phenomenon means that there is significant risk in applying DNNs to safety-critical applications, such as driverless cars. To address this issue, we present a visual analytics approach to explain the primary cause of the wrong predictions introduced by adversarial examples. The key is to analyze the datapaths of the adversarial examples and compare them with those of the normal examples. A datapath is a group of critical neurons and their connections. To this end, we formulate the datapath extraction as a subset selection problem and approximately solve it based on back-propagation. A multi-level visualization consisting of a segmented DAG (layer level), an Euler diagram (feature map level), and a heat map (neuron level), has been designed to help experts investigate datapaths from the high-level layers to the detailed neuron activations. Two case studies are conducted that demonstrate the promise of our approach in support of explaining the working mechanism of adversarial examples.",,,,,vimeo 289787703,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Deep Learning,25-Oct,11:20 AM,11:40 AM
VAST,TVCG,DQNViz: A Visual Analytics Approach to Understand Deep Q-Networks,J),"Junpeng Wang, Liang Gou, Han-Wei Shen, Hao Yang",http://edda-project.github.io/files/2018-08-13/dqnvis.pdf,"Deep Q-Network (DQN), as one type of deep reinforcement learning model, targets to train an intelligent agent that acquires optimal actions while interacting with an environment. The model is well known for its ability to surpass professional human players across many Atari 2600 games. Despite the superhuman performance, in-depth understanding of the model and interpreting the sophisticated behaviors of the DQN agent remain to be challenging tasks, due to the long-time model training process and the large number of experiences dynamically generated by the agent. In this work, we propose DQNViz, a visual analytics system to expose details of the blind training process in four levels, and enable users to dive into the large experience space of the agent for comprehensive analysis. As an initial attempt in visualizing DQN models, our work focuses more on Atari games with a simple action space, most notably the Breakout game. From our visual analytics of the agent’s experiences, we extract useful action/reward patterns that help to interpret the model and control the training. Through multiple case studies conducted together with deep learning experts, we demonstrate that DQNViz can effectively help domain experts to understand, diagnose, and potentially improve DQN models.",,,,,vimeo 289787246,10.1109/tvcg.2018.2864504,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Deep Learning,25-Oct,11:40 AM,12:00 PM
VAST,TVCG,RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Network on Electronic Medical Records,J),"Bum Chul Kwon, Min-Je Choi, Joanne Kim, Edward Choi, Young Bin Kim, Soonwook Kwon, Jimeng Sun, Jaegul Choo",https://arxiv.org/pdf/1805.10724.pdf,"We have recently seen many successful applications of recurrent neural networks (RNNs) on electronic medical records (EMRs), which contain histories of patients’ diagnoses, medications, and other various events, in order to predict the current and future states of patients. Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no established methods to interactively leverage users’ domain expertise and prior knowledge as inputs for steering the model. Therefore, our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable, and interactive RNN-based model called RetainEX and visualizations for users’ exploration of EMR data in the context of prediction tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk predictions, using EMRs of patients with heart failure and cataract symptoms. Our study also demonstrates how we made substantial changes to the state-of-the-art RNN model called RETAIN in order to make use of temporal information and increase interactivity. This study will provide a useful guideline for researchers that aim to design an interpretable and interactive visual analytics tool for RNNs",,,,,vimeo 289787946,10.1109/TVCG.2018.2865027,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Deep Learning,25-Oct,12:00 PM,12:20 PM
VAST,TVCG,GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation,J),"Minsuk Kahng, Nikhil Thorat, Duen Horng Chau, Fernanda Viegas, Martin Wattenberg",https://arxiv.org/pdf/1809.01587.pdf,"Recent success in deep learning has generated immense interest among practitioners and students, inspiring many to learn about this new technology. While visual and interactive approaches have been successfully developed to help people more easily learn deep learning, most existing tools focus on simpler models. In this work, we present GAN Lab, the first interactive visualization tool designed for non-experts to learn and experiment with Generative Adversarial Networks (GANs), a popular class of complex deep learning models. With GAN Lab, users can interactively train generative models and visualize the dynamic training process’s intermediate results. GAN Lab tightly integrates an model overview graph that summarizes GAN’s structure, and a layered distributions view that helps users interpret the interplay between submodels. GAN Lab introduces new interactive experimentation features for learning complex deep learning models, such as step-by-step training at multiple levels of abstraction for understanding intricate training dynamics. Implemented using TensorFlow.js, GAN Lab is accessible to anyone via modern web browsers, without the need for installation or specialized hardware, overcoming a major practical challenge in deploying interactive tools for deep learning.",,,,,vimeo 289787794,10.1109/tvcg.2018.2864500,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Deep Learning,25-Oct,12:20 PM,12:40 PM
InfoVis,TVCG,A Framework for Creative Visualization-Opportunities Workshops,J),"Ethan Kerzner, Sarah Goodwin, Jason Dykes, Sara V Jones, Miriah Meyer",http://sci.utah.edu/~vdl/papers/2018_infovis_creative-workshops.pdf,"Applied visualization researchers often work closely with domain collaborators to explore new and useful applications of visualization. The early stages of collaborations are typically time consuming for all stakeholders as researchers piece together an understanding of domain challenges from disparate discussions and meetings. A number of recent projects, however, report on the use of creative visualization-opportunities (CVO) workshops to accelerate the early stages of applied work, eliciting a wealth of requirements in a few days of focused work. Yet, there is no established guidance for how to use such workshops effectively. In this paper, we present the results of a 2-year collaboration in which we analyzed the use of 17 workshops in 10 visualization contexts. Its primary contribution is a framework for CVO workshops that: 1) identifies a process model for using workshops; 2) describes a structure of what happens within effective workshops; 3) recommends 25 actionable guidelines for future workshops; and 4) presents an example workshop and workshop methods. The creation of this framework exemplifies the use of critical reflection to learn about visualization in practice from diverse studies and experience.",,,,,vimeo 289784415,10.1109/tvcg.2018.2865241,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Design & Storytelling,25-Oct,11:00 AM,11:20 AM
TVCG,TVCG,ATOM: A Grammar for Unit Visualizations,T),"Deokgun Park, Steven M. Drucker, Roland Fernandez, Niklas Elmqvist",http://users.umiacs.umd.edu/~elm/projects/atom/atom.pdf,"Unit visualizations are a family of visualizations where every data item is represented by a unique visual mark—a visual unit—during visual encoding. For certain datasets and tasks, unit visualizations can provide more information, better match the user’s mental model, and enable novel interactions compared to traditional aggregated visualizations. Current visualization grammars cannot fully describe the unit visualization family. In this paper, we characterize the design space of unit visualizations to derive a grammar that can express them. The resulting grammar is called <span style=""font-variant: small-caps;"">ATOM<span>, and is based on passing data through a series of layout operations that divide the output of previous operations recursively until the size and position of every data point can be determined. We evaluate the expressive power of the grammar by both using it to describe existing unit visualizations, as well as to suggest new unit visualizations.",https://intuinno.github.io/unit/#/live,,,,vimeo 289789243,10.1109/tvcg.2017.2785807,2017,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Design & Storytelling,25-Oct,11:20 AM,11:40 AM
InfoVis,TVCG,Design Exposition with Literate Visualization,J),"Jo Wood, Alexander Kachkaev, Jason Dykes",http://openaccess.city.ac.uk/20081/1/wood_literate_2018.pdf,"We propose a new approach to the visualization design and communication process, literate visualization, based upon and extending, Donald Knuth's idea of literate programming. It integrates the process of writing data visualization code with description of the design choices that led to the implementation (design exposition). We develop a model of design exposition characterised by four visualization designer architypes: the evaluator, the autonomist, the didacticist and the rationalist. The model is used to justify the key characteristics of literate visualization: 'notebook' documents that integrate live coding input, rendered output and textual narrative; low cost of authoring textual narrative; guidelines to encourage structured visualization design and its documentation. We propose narrative schemas for structuring and validating a wide range of visualization design approaches and models, and branching narratives for capturing alternative designs and design views. We describe a new open source literate visualization environment, litvis, based on a declarative interface to Vega and Vega-Lite through the functional programming language Elm combined with markdown for formatted narrative. We informally assess the approach, its implementation and potential by considering three examples spanning a range of design abstractions: new visualization idioms; validation though visualization algebra; and feminist data visualization. We argue that the rich documentation of the design process provided by literate visualization offers the potential to improve the validity of visualization design and so benefit both academic visualization and visualization practice.",,https://github.com/gicentre/litvis,,,vimeo 289785349,10.1109/tvcg.2018.2864836,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Design & Storytelling,25-Oct,11:40 AM,12:00 PM
InfoVis,TVCG,iStoryline: Effective Convergence to Hand-drawn Storylines,J),"Tan Tang, Sadia Rubab, Jiewen Lai, Weiwei Cui, Lingyun Yu, Yingcai Wu",http://zjuvis.org/files/istoryline.pdf,"Storyline visualization techniques have progressed significantly to generate illustrations of complex stories automatically. However, the visual layouts of storylines are not enhanced accordingly despite the improvement in the performance and extension of its application area. Existing methods attempt to achieve several shared optimization goals, such as reducing empty space and minimizing line crossings and wiggles. However, these goals do not always produce optimal results when compared to hand-drawn storylines. We conducted a preliminary study to learn how users translate a narrative into a hand-drawn storyline and check whether the visual elements in hand-drawn illustrations can be mapped back to appropriate narrative contexts. We also compared the hand-drawn storylines with storylines generated by the state-of-the-art methods and found they have significant differences. Our findings led to a design space that summarizes 1) how artists utilize narrative elements and 2) the sequence of actions artists follow to portray expressive and attractive storylines. We developed iStoryline, an authoring tool for integrating high-level user interactions into optimization algorithms and achieving a balance between hand-drawn storylines and automatic layouts. iStoryline allows users to create novel storyline visualizations easily according to their preferences by modifying the automatically generated layouts. The effectiveness and usability of iStoryline are studied with qualitative evaluations",https://istoryline.github.io/,,https://istoryline.github.io/interview/interview.html,,video https://istoryline.github.io/img/iStoryline.mp4,10.1109/tvcg.2018.2864899,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Design & Storytelling,25-Oct,12:00 PM,12:20 PM
InfoVis,TVCG,Narvis: Authoring Narrative Slideshows for Introducing Data Visualization Designs,J),"Qianwen Wang, Zhen Li, Siwei Fu, Weiwei Cui, Huamin Qu",https://wangqianwen0418.github.io/assets/pdf/Narvis.pdf,"Visual designs can be complex in modern data visualization systems, which poses special challenges for explaining them to the non-experts. However, few if any presentation tools are tailored for this purpose. In this study, we present Narvis, a slideshow authoring tool designed for introducing data visualizations to non-experts. Narvis targets two types of end users: teachers, experts in data visualization who produce tutorials for explaining a data visualization, and students, non-experts who try to understand visualization designs through tutorials. We present an analysis of requirements through close discussions with the two types of end users. The resulting considerations guide the design and implementation of Narvis. Additionally, to help teachers better organize their introduction slideshows, we specify a data visualization as a hierarchical combination of components, which are automatically detected and extracted by Narvis. The teachers craft an introduction slideshow through first organizing these components, and then explaining them sequentially. A series of templates are provided for adding annotations and animations to improve efficiency during the authoring process. We evaluate Narvis through a qualitative analysis of the authoring experience, and a preliminary evaluation of the generated slideshows.",,,,,vimeo 289784711,10.1109/tvcg.2018.2865232,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Design & Storytelling,25-Oct,12:20 PM,12:40 PM
SciVis,TVCG,Culling for Extreme-Scale Segmentation Volumes: A Hybrid Deterministic and Probabilistic Approach,J),"Johanna Beyer, Haneen Mohammed, Marco Agus, Ali K. Al-Awami, Hanspeter Pfister, Markus Hadwiger",http://vccvisualization.org/publications/2018_beyer_hybridculling.pdf,"With the rapid increase in raw volume data sizes, such as terabyte-sized microscopy volumes, the corresponding segmentation label volumes have become extremely large as well. We focus on integer label data, whose efficient representation in memory, as well as fast random data access, pose an even greater challenge than the raw image data. Often, it is crucial to be able to rapidly identify which segments are located where, whether for empty space skipping for fast rendering, or for spatial proximity queries. We refer to this process as culling. In order to enable efficient culling of millions of labeled segments, we present a novel hybrid approach that combines deterministic and probabilistic representations of label data in a data-adaptive hierarchical data structure that we call the label list tree. In each node, we adaptively encode label data using either a probabilistic constant-time access representation for fast conservative culling, or a deterministic logarithmic-time access representation for exact queries. We choose the best data structures for representing the labels of each spatial region while building the label list tree. At run time, we further employ a novel query-adaptive culling strategy. While filtering a query down the tree, we prune it successively, and in each node adaptively select the representation that is best suited for evaluating the pruned query, depending on its size. We show an analysis of the efficiency of our approach with several large data sets from connectomics, including a brain scan with more than 13 million labeled segments, and compare our method to conventional culling approaches. Our approach achieves significant reductions in storage size as well as faster query times.",,,,,youtube ABf0jw1jLUY,10.1109/tvcg.2018.2864847,2018,2018,SciVis,Estrel Hall A+B,Thursday,Scalable Techniques,25-Oct,11:00 AM,11:20 AM
SciVis,TVCG,CPU Iso-surface Ray Tracing of Adaptive Mesh Refinement Data,J),"Feng Wang, Ingo Wald, Qi Wu, Will Usher, Chris R. Johnson",http://sci.utah.edu/~will/papers/amr-isosurface.pdf,"Adaptive mesh refinement (AMR) is a key technology for large-scale simulations that allows for adaptively changing the simulation mesh resolution, resulting in significant computational and storage savings. However, visualizing such AMR data poses a significant challenge due to the difficulties introduced by the hierarchical representation when reconstructing continuous field values. In this paper, we detail a comprehensive solution for interactive isosurface rendering of block-structured AMR data. We contribute a novel reconstruction strategy—the octant method—which is continuous, adaptive and simple to implement. Furthermore, we present a generally applicable hybrid implicit isosurface ray-tracing method, which provides better rendering quality and performance than the built-in sampling-based approach in OSPRay. Finally, we integrate our octant method and hybrid isosurface geometry into OSPRay as a module, providing the ability to create high-quality interactive visualizations combining volume and isosurface representations of BS-AMR data. We evaluate the rendering performance, memory consumption and quality of our method on two gigascale block-structured AMR datasets.",,,,,vimeo 290328099,10.1109/TVCG.2018.2864850,2018,2018,SciVis,Estrel Hall A+B,Thursday,Scalable Techniques,25-Oct,11:20 AM,11:40 AM
TVCG,TVCG,Efficient Local Statistical Analysis via Point-Wise Histograms in Tetrahedral Meshes and Curvilinear Grids,T),"Bo Zhou, Yi-Jen Chiang, Cong Wang",http://cse.poly.edu/chiang/TVCG18-Final-Paper.pdf,"Local histograms (i.e., point-wise histograms computed from local regions of mesh vertices) have been used in many data analysis and visualization applications. Previous methods for computing local histograms mainly work for regular or rectilinear grids only. In this paper, we develop theory and novel algorithms for computing local histograms in tetrahedral meshes and curvilinear grids. Our algorithms are theoretically sound and efficient, and work effectively and fast in practice. Our main focus is on scalar fields, but the algorithms also work for vector fields as a by-product with small, easy modifications. Our methods can benefit information theoretic and other distribution-driven analysis. The experiments demonstrate the efficacy of our new techniques, including a utility case study on tetrahedral vector field visualization.",,,,,vimeo 289789310,10.1109/tvcg.2018.2796555,2018,2018,SciVis,Estrel Hall A+B,Thursday,Scalable Techniques,25-Oct,11:40 AM,12:00 PM
TVCG,TVCG,Shadow Accrual Maps: Efficient Accumulation of City-Scale Shadows over Time,T),"Fabio Miranda, Harish Doraiswamy, Marcos Lage, Luc Wilson, Mondrian Hsieh, Claudio T. Silva",http://www.harishd.com/home/assets/papers/shadows.pdf,"Large scale shadows from buildings in a city play an important role in determining the environmental quality of public spaces. They can be both beneficial, such as for pedestrians during summer, and detrimental, by impacting vegetation and by blocking direct sunlight. Determining the effects of shadows requires the accumulation of shadows over time across different periods in a year. In this paper, we propose a simple yet efficient class of approach that uses the properties of sun movement to track the changing position of shadows within a fixed time interval. We use this approach to extend two commonly used shadow techniques, shadow maps and ray tracing, and demonstrate the efficiency of our approach. Our technique is used to develop an interactive visual analysis system, Shadow Profiler, targeted at city planners and architects that allows them to test the impact of shadows for different development scenarios. We validate the usefulness of this system through case studies set in Manhattan, a dense borough of New York City",,,,,vimeo 289789412,10.1109/tvcg.2018.2802945,2018,2018,SciVis,Estrel Hall A+B,Thursday,Scalable Techniques,25-Oct,12:00 PM,12:20 PM
TVCG,TVCG,A Scalable Hybrid Scheme for Ray-Casting of Unstructured Volume Data,T),"Roba Binyahib, Tom Peterka, Matthew Larsen, Kwan-Liu Ma, Hank Childs",https://www.mcs.anl.gov/~tpeterka/papers/2018/binyahib-tvcg18-paper.pdf,"We present an algorithm for parallel volume rendering that is a hybrid between classical object order and image order techniques. The algorithm operates on unstructured grids (and structured ones), and thus can deal with block boundaries interleaving in complex ways. It also deals effectively with cases that are prone to load imbalance, i.e., cases where cell sizes differ dramatically, either because of the nature of the input data, or because of the effects of the camera transformation. The algorithm divides work over resources such that each phase of its processing is bounded in the amount of computation it can perform. We demonstrate its efficacy through a series of studies, varying over camera position, data set size, transfer function, image size, and processor count. At its biggest, our experiments scaled up to 8,192 processors and operated on data sets with more than one billion cells. In total, we find that our hybrid algorithm performs well in all cases. This is because our algorithm naturally adapts its computation based on workload, and can operate like either an object order technique or an image order technique in scenarios where those techniques are efficient.",,,,,vimeo 289789339,10.1109/tvcg.2018.2833113,2018,2018,SciVis,Estrel Hall A+B,Thursday,Scalable Techniques,25-Oct,12:20 PM,12:40 PM
InfoVis,TVCG,Charticulator: Interactive Construction of Bespoke Chart Layouts,J),"Donghao Ren, Bongshin Lee, Matthew Brehmer",https://donghaoren.org/publications/infovis18-charticulator.pdf,"We present Charticulator, an interactive authoring tool that enables the creation of bespoke and reusable chart layouts. Charticulator is our response to most existing chart construction interfaces that require authors to choose from predefined chart layouts, thereby precluding the construction of novel charts. In contrast, Charticulator transforms a chart specification into mathematical layout constraints and automatically computes a set of layout attributes using a constraint-solving algorithm to realize the chart. It allows for the articulation of compound marks or glyphs as well as links between these glyphs, all without requiring any coding or knowledge of constraint satisfaction. Furthermore, thanks to the constraint-based layout approach, Charticulator can export chart designs into reusable templates that can be imported into other visualization tools. In addition to describing Charticulator's conceptual framework and design, we present three forms of evaluation: a gallery to illustrate its expressiveness, a user study to verify its usability, and a click-count comparison between Charticulator and three existing tools. Finally, we discuss the limitations and potentials of Charticulator as well as directions for future research. Charticulator is available with its source code at https://charticulator.com.",https://charticulator.com/app/index.html,https://github.com/Microsoft/charticulator,,,video https://charticulator.azureedge.net/videos/charticulator-supplemental.mp4,10.1109/tvcg.2018.2865158,2018,2018,InfoVis,Estrel Hall C,Thursday,Interaction,25-Oct,11:00 AM,11:20 AM
InfoVis,TVCG,Embedded Merge & Split: Visual Adjustment of Data Grouping,J),"Ali Sarvghad, Bahador Saket, Alex Endert, Nadir Weibel",http://bahadorsaket.com/publication/EMS.pdf,"Data grouping is among the most frequently used operations in data visualization. It is the process through which relevant information is gathered, simplified, and expressed in summary form. Many popular visualization tools support automatic grouping of data (e.g., dividing up a numerical variable into bins). Although grouping plays a pivotal role in supporting data exploration, further adjustment and customization of auto-generated grouping criteria is non-trivial. Such adjustments are currently performed either programmatically or through menus and dialogues which require specific parameter adjustments over several steps. In response, we introduce Embedded Merge & Split (EMS), a new interaction technique for direct adjustment of data grouping criteria. We demonstrate how the EMS technique can be designed to directly manipulate width and position in bar charts and histograms, as a means for adjustment of data grouping criteria. We also offer a set of design guidelines for supporting EMS. Finally, we present the results of two user studies, providing initial evidence that EMS can significantly reduce interaction time compared to WIMP-based technique and was subjectively preferred by participants.",,,,,youtube Z2rL6WF6TLY,10.1109/tvcg.2018.2865075,2018,2018,InfoVis,Estrel Hall C,Thursday,Interaction,25-Oct,11:20 AM,11:40 AM
TVCG,TVCG,Smart Brushing for Parallel Coordinates,T),"Richard Roberts, Robert S Laramee, Gary A Smith, Paul Brookes, Tony D'Cruze",http://cs.swan.ac.uk/~csbob/research/callCenter/brushing/roberts18smart.pdf,"The Parallel Coordinates plot is a popular tool for the visualization of high-dimensional data. One of the main challenges when using parallel coordinates is occlusion and overplotting resulting from large data sets. Brushing is a popular approach to address these challenges. Since its conception, limited improvements have been made to brushing both in the form of visual design and functional interaction. We present a set of novel, smart brushing techniques that enhance the standard interactive brushing of a parallel coordinates plot. We introduce two new interaction concepts: Higher-order, sketch-based brushing, and smart, data-driven brushing. Higher-order brushes support interactive, flexible, n-dimensional pattern searches involving an arbitrary number of dimensions. Smart, data-driven brushing provides interactive, real-time guidance to the user during the brushing process based on derived meta-data. In addition, we implement a selection of novel enhancements and user options that complement the two techniques as well as enhance the exploration and analytical ability of the user. We demonstrate the utility and evaluate the results using a case study with a large, high-dimensional, real-world telecommunication data set and we report domain expert feedback from the data suppliers.",,,,,vimeo 289789480,10.1109/tvcg.2018.2808969,2018,2018,InfoVis,Estrel Hall C,Thursday,Interaction,25-Oct,11:40 AM,12:00 PM
TVCG,TVCG,"Multidimensional Projection for Visual Analytics: Linking Techniques with Distortions, Tasks, and Layout Enrichment ",T),"Luis Gustavo Nonato, Michael Aupetit",http://www.lcad.icmc.usp.br/~nonato/pubs/mdp-survey.pdf,"Visual analysis of multidimensional data requires expressive and effective ways to reduce data dimensionality to encode them visually. Multidimensional projections (MDP) figure among the most important visualization techniques in this context, transforming multidimensional data into scatter plots whose visual patterns reflect some notion of similarity in the original data. However, MDP come with distortions that make these visual patterns not trustworthy, hindering users to infer actual data characteristics. Moreover, the patterns present in the scatter plots might not be enough to allow a clear understanding of multidimensional data, motivating the development of layout enrichment methodologies to operate together with MDP. This survey attempts to cover the main aspects of MDP as a visualization and visual analytic tool. It provides detailed analysis and taxonomies as to the organization of MDP techniques according to their main properties and traits, discussing the impact of such properties for visual perception and other human factors. The survey also approaches the different types of distortions that can result from MDP mappings and it overviews existing mechanisms to quantitatively evaluate such distortions. A qualitative analysis of the impact of distortions on the different analytic tasks performed by users when exploring multidimensional data through MDP is also presented. Guidelines for choosing the best MDP for an intended task are also provided as a result of this analysis. Finally, layout enrichment schemes to debunk MDP distortions and/or reveal relevant information not directly inferable from the scatter plot are reviewed and discussed in the light of new taxonomies. We conclude the survey providing future research axes to fill discovered gaps in this domain.",,,,,vimeo 289789153,10.1109/tvcg.2018.2846735,2018,2018,InfoVis,Estrel Hall C,Thursday,Interaction,25-Oct,12:00 PM,12:20 PM
TVCG,TVCG,Exploration Strategies for Discovery of Interactivity in Visualizations,T),"Tanja Blascheck, Lindsay MacDonald Vermeulen, Jo Vermeulen, Charles Perin, Wesley Willett, Thomas Ertl, Sheelagh Carpendale",https://hal.archives-ouvertes.fr/hal-01705792/document,"We investigate how people discover the functionality of an interactive visualization that was designed for the general public. While interactive visualizations are increasingly available for public use, we still know little about how the general public discovers what they can do with these visualizations and what interactions are available. Developing a better understanding of this discovery process can help inform the design of visualizations for the general public, which in turn can help make data more accessible. To unpack this problem, we conducted a lab study in which participants were free to use their own methods to discover the functionality of a connected set of interactive visualizations of public energy data. We collected eye movement data and interaction logs as well as video and audio recordings. By analyzing this combined data, we extract exploration strategies that the participants employed to discover the functionality in these interactive visualizations. These exploration strategies illuminate possible design directions for improving the discoverability of a visualization's functionality.",,,http://innovis.cpsc.ucalgary.ca/supplemental/Exploration-Strategies/#data,,vimeo 289789025,10.1109/tvcg.2018.2802520,2018,2018,InfoVis,Estrel Hall C,Thursday,Interaction,25-Oct,12:20 PM,12:40 PM
CG&A,CGA,OpenSpace: Changing the Narrative of Public Dissemination in Astronomical Visualization from What to How,,"Alexander Bock, Emil Axelsson, Carter Emmart, Masha Kuznetsova, Charles Hansen, Anders Ynnerman",http://www.sci.utah.edu/publications/Boc2018a/08370192.pdf,"This article presents the development of open-source software called OpenSpace that bridges the gap between scientific discoveries and public dissemination and thus paves the way for the next generation of science communication and data exploration. The article describes how the platform enables interactive presentations of dynamic and timevarying processes by domain experts to the general public. The concepts are demonstrated through four cases: Image acquisitions of the New Horizons and Rosetta spacecraft, the dissemination of space weather phenomena, and the display of highresolution planetary images. Each case has been presented at public events with great success. These cases highlight the details of data acquisition, rather than presenting the final results, showing the audience the value of supporting the efforts of the scientific discovery. ",,,,,vimeo 289785793,10.1109/mcg.2018.032421653,2018,2018,Other,Room III,Thursday,CG&A Session 2,25-Oct,11:00 AM,11:20 AM
CG&A,CGA,Belle2VR: A Virtual-Reality Visualization of Subatomic Particle Physics in the Belle II Experiment,,"Zach Duer, Leo Piilonen, and George Glasson",,,,,,,vimeo 289785809,10.1109/mcg.2018.032421652,2018,2018,Other,Room III,Thursday,CG&A Session 2,25-Oct,11:20 AM,11:40 AM
CG&A,CGA,Application-Driven Design: Help Students Understand Employment and See the “Big Picture”,,"Li Liu, Deborah Silver, Karen Bemis",,,,,,,vimeo 289785826,10.1109/mcg.2018.032421656,2018,2018,Other,Room III,Thursday,CG&A Session 2,25-Oct,11:40 AM,12:00 PM
CG&A,CGA,Management of Cerebral Aneurysm Descriptors based on an Automatic Ostium Extraction,,"Monique Meuschke, Tobias Günther, Ralph Wickenhöfer, Markus Gross, Bernhard Preim, Kai Lawonn",https://cgl.ethz.ch/Downloads/Publications/Papers/2018/Meu18a/Meu18a.pdf,"We present a framework to manage cerebral aneurysms. Rupture risk evaluation is based on manually extracted descriptors, which is timeconsuming. Thus, we provide an automatic solution by considering several questions: How can expert knowledge be integrated? How should metadata be defined? Which interaction techniques are needed for data exploration?",,,,,vimeo 289785840,10.1109/mcg.2018.032421654,2018,2018,Other,Room III,Thursday,CG&A Session 2,25-Oct,12:00 PM,12:20 PM
CG&A,CGA,Toward a Multimodal Diagnostic Exploratory Visualization of Focal Cortical Dysplasia,,"Shin-Ting Wu, Raphael Voltoline, Wallace S. Loos, J.A. Iván Rubianes, Lionis S. Watanabe, Bárbara J. Amorim, A. Carolina Coan, Fernando Cendes, Clarissa L. Yasuda",http://www.dca.fee.unicamp.br/projects/prosim/publications/journals/wu-loos-voltoline-rubianes-2017-3dmediv-draft.pdf,"Focal cortical dysplasia (FCD) is a malformation of cortical development and a common cause of pharmacoresistant epilepsy. Resective surgery of clear-cut lesions may be curative. However, the localization of the seizure focus and the evaluation of its spatial extent can be challenging in many situations. For concordance assessment, medical studies show the relevance of accurate correlation of multi-source imaging sequences. to improve the sensitivity and specificity of the evaluation. In this paper, we share the process we went through to reach our simple, but effective, solution for integrating multi-volume rendering into an exploratory visualization environment for the diagnosis of FCD. We focus on fetching of multiple data assigned to a sample when they are rendered. Knowing that the major diagnostic role of multiple volumes is to complement information, we demonstrate that appropriate geometric transformations in the texture space are sufficient for accomplishing this task. This allows us to fully implement our proposal in the OpenGL rendering pipeline and to easily integrate it into the existing visual diagnostic application. Both time performance and the visual quality of our proposal were evaluated with a set of clinical data volumes for assessing the potential practical impact of our solution in routine diagnostic use. ",,,,,vimeo 289785856,10.1109/mcg.2018.032421655,2018,2018,Other,Room III,Thursday,CG&A Session 2,25-Oct,12:20 PM,12:40 PM
VAST,TVCG,ViBr: Visualizing Bipartite Relations at Scale with the Minimum Description Length Principle,J),"Gromit Yeuk-Yin Chan, Panpan Xu, Zeng Dai, Liu Ren",https://vgc.poly.edu/~yychan/papers/chan-vast2018.pdf,"Bipartite graphs model the key relations in many large scale real-world data: customers purchasing items, legislators voting for bills, people’s affiliation with different social groups, faults occurring in vehicles, etc. However, it is challenging to visualize large scale bipartite graphs with tens of thousands or even more nodes or edges. In this paper, we propose a novel visual summarization technique for bipartite graphs based on the minimum description length (MDL) principle. The method simultaneously groups the two different set of nodes and constructs aggregated bipartite relations with balanced granularity and precision. It addresses the key trade-off that often occurs for visualizing large scale and noisy data: acquiring a clear and uncluttered overview while maximizing the information content in it. We formulate the visual summarization task as a co-clustering problem and propose an efficient algorithm based on locality sensitive hashing (LSH) that can easily scale to large graphs under reasonable interactive time constraints that previous related methods cannot satisfy. The method leads to the opportunity of introducing a visual analytics framework with multiple levels-of-detail to facilitate interactive data exploration. In the framework, we also introduce a compact visual design inspired by adjacency list representation of graphs as the building block for a small multiples display to compare the bipartite relations for different subsets of data. We showcase the applicability and effectiveness of our approach by applying it on synthetic data with ground truth and performing case studies on real-world datasets from two application domains including roll-call vote record analysis and vehicle fault pattern analysis. Interviews with experts in the political science community and the automotive industry further highlight the benefits of our approach.",,,,,vimeo 289787354,10.1109/TVCG.2018.2864826,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Graph and Image,25-Oct,2:20 PM,2:40 PM
VAST,VAST,Segue: Overviewing Evolution Patterns of Egocentric Networks by Interactive Construction of Spatial Layouts,C),"Po-Ming Law, Yanhong Wu, Rahul Basole",https://terrancelaw.github.io/publications/segue_vast18.pdf,"Getting the overall picture of how a large number of ego-networks evolve is a common yet challenging task. Existing techniques often require analysts to inspect the evolution patterns of ego-networks one after another. In this study, we explore an approach that allows analysts to interactively create spatial layouts in which each dot is a dynamic ego-network. These spatial layouts provide overviews of the evolution patterns of ego-networks, thereby revealing different global patterns such as trends, clusters and outliers in evolution patterns. To let analysts interactively construct interpretable spatial layouts, we propose a data transformation pipeline, with which analysts can adjust the spatial layouts and convert dynamic egonetworks into event sequences to aid interpretations of the spatial positions. Based on this transformation pipeline, we develop Segue, a visual analysis system that supports thorough exploration of the evolution patterns of ego-networks. Through two usage scenarios, we demonstrate how analysts can gain insights into the overall evolution patterns of a large collection of ego-networks by interactively creating different spatial layouts.",,,,,vimeo 289788023,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Graph and Image,25-Oct,2:40 PM,3:00 PM
VAST,TVCG,A Visual Analytics Framework for Spatiotemporal Trade Network Analysis,J),"Hong Wang, Yafeng Lu, Shade Shutters, Michael Steptoe, Feng Wang, Steven Landis, Ross Maciejewski",http://www.public.asu.edu/~hxwang/trade.pdf,"Economic globalization is increasing connectedness among regions of the world, creating complex interdependencies within various supply chains. Recent studies have indicated that changes and disruptions within such networks can serve as indicators for increased risks of violence and armed conflicts. This is especially true of countries that may not be able to compete for scarce commodities during supply shocks. Thus, network-induced vulnerability to supply disruption is typically exported from wealthier populations to disadvantaged populations. As such, researchers and stakeholders concerned with supply chains, political science, environmental studies, etc. need tools to explore the complex dynamics within global trade networks and how the structure of these networks relates to regional instability. However, the multivariate, spatiotemporal nature of the network structure creates a bottleneck in the extraction and analysis of correlations and anomalies for exploratory data analysis and hypothesis generation. Working closely with experts in political science and sustainability, we have developed a highly coordinated, multi-view framework that utilizes anomaly detection, network analytics, and spatiotemporal visualization methods for exploring the relationship between global trade networks and regional instability. Requirements for analysis and initial research questions to be investigated are elicited from domain experts, and a variety of visual encoding techniques for rapid assessment of analysis and correlations between trade goods, network patterns, and time series signatures are explored. We demonstrate the application of our framework through case studies focusing on armed conflicts in Africa, regional instability measures, and their relationship to international global trade.",,,,,vimeo 289787400,10.1109/TVCG.2018.2864844,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Graph and Image,25-Oct,3:00 PM,3:20 PM
TVCG,TVCG,A Semantic-based Method for Visualizing Large Image Collections,T),"Xiao Xie, Xiwen Cai, Junpei Zhou, Nan Cao, Yingcai Wu",http://zjuvis.org/files/imgvis.pdf,"Interactive visualization of large image collections is important and useful in many applications, such as personal album management and user profiling on images. However, most prior studies focus on using low-level visual features of images, such as texture and color histogram, to create visualizations without considering the more important semantic information embedded in images. This paper proposes a novel visual analytic system to analyze images in a semantic-aware manner. The system mainly comprises two components: a semantic information extractor and a visual layout generator. The semantic information extractor employs an image captioning technique based on convolutional neural network (CNN) to produce descriptive captions for images, which can be transformed into semantic keywords. The layout generator employs a novel co-embedding model to project images and the associated semantic keywords to the same 2D space. Inspired by the galaxy metaphor, we further turn the projected 2D space to a galaxy visualization of images, in which semantic keywords and images are visually encoded as stars and planets. Our system naturally supports multi-scale visualization and navigation, in which users can immediately see a semantic overview of an image collection and drill down for detailed inspection of a certain group of images. Users can iteratively refine the visual layout by integrating their domain knowledge into the co-embedding process. Two task-based evaluations are conducted to demonstrate the effectiveness of our system.",,,,,vimeo 289789441,10.1109/tvcg.2018.2835485,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Graph and Image,25-Oct,3:20 PM,3:40 PM
TVCG,TVCG,PhotoRecomposer: Interactive Photo Recomposition by Cropping,T),"Yuan Liang, Xiting Wang, Song-Hai Zhang, Shi-Min Hu, Shixia Liu",http://shixialiu.com/publications/photorecomposer/paper.pdf,"We present a visual analysis method for interactively recomposing a large number of photos based on example photos with high-quality composition. The recomposition method is formulated as a matching problem between photos. The key to this formulation is a new metric for accurately measuring the composition distance between photos. We have also developed an earth-mover-distancebased online metric learning algorithm to support the interactive adjustment of the composition distance based on user preferences. To better convey the compositions of a large number of example photos, we have developed a multi-level, example photo layout method to balance multiple factors such as compactness, aspect ratio, composition distance, stability, and overlaps. By introducing an EulerSmooth-based straightening method, the composition of each photos is clearly displayed. The effectiveness and usefulness of the method has been demonstrated by the experimental results, user study, and case studies.",,,,,vimeo 289788924,10.1109/tvcg.2017.2764895,2017,2018,VAST,"Convention Hall 1, Section C",Thursday,Graph and Image,25-Oct,3:40 PM,4:00 PM
InfoVis,TVCG,Mapping Color to Meaning in Colormap Data Visualizations,J),"Karen B. Schloss, Connor C. Gramazio, Allison T. Silverman, Madeline L. Parker, Audrey S. Wang",https://schlosslab.discovery.wisc.edu/wp-content/uploads/2018/09/SchlossGramazioSilvermanParkerWanginPress.pdf,"To interpret data visualizations, people must determine how visual features map onto concepts. For example, to interpret colormaps, people must determine how dimensions of color (e.g., lightness, hue) map onto quantities of a given measure (e.g., brain activity, correlation magnitude). This process is easier when the encoded mappings in the visualization match people's predictions of how visual features will map onto concepts, their inferred mappings. To harness this principle in visualization design, it is necessary to understand what factors determine people's <i>inferred mappings</i>. In this study, we investigated how inferred color-quantity mappings for colormap data visualizations were influenced by the background color. Prior literature presents seemingly conflicting accounts of how the background color affects inferred color-quantity mappings. The present results help resolve those conflicts, demonstrating that sometimes the background has an effect and sometimes it does not, depending on whether the colormap appears to vary in opacity. When there is no apparent variation in opacity, participants infer that darker colors map to larger quantities (<i>dark-is-more bias</i>). As apparent variation in opacity increases, participants become biased toward inferring that more opaque colors map to larger quantities (<i>opaque-is-more bias</i>). These biases work together on light backgrounds and conflict on dark backgrounds. Under such conflicts, the opaque-is-more bias can negate, or even supersede the dark-is-more bias. The results suggest that if a design goal is to produce colormaps that match people's inferred mappings and are robust to changes in background color, it is beneficial to use colormaps that will not appear to vary in opacity on any background color, and to encode larger quantities in darker colors.",,,https://schlosslab.discovery.wisc.edu/resources/,,vimeo 289784916,10.1109/tvcg.2018.2865147,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 1,25-Oct,2:20 PM,2:40 PM
InfoVis,TVCG,Optimizing Color Assignment for Perception of Class Separability in Multiclass Scatterplots,J),"Yunhai Wang, Xin Chen, Tong Ge, Chen Bao, Michael Sedlmair, Chi-Wing Fu, Oliver Deussen, Baoquan Chen",http://www.yunhaiwang.org/infovis18/color/vis-color.pdf,"Appropriate choice of colors significantly aids viewers in understanding the structures in multiclass scatterplots and becomes more important with a growing number of data points and groups. An appropriate color mapping is also an important parameter for the creation of an aesthetically pleasing scatterplot. Currently, users of visualization software routinely rely on color mappings that have been pre-defined by the software. A default color mapping, however, cannot ensure an optimal perceptual separability between groups, and sometimes may even lead to a misinterpretation of the data. In this paper, we present an effective approach for color assignment based on a set of given colors that is designed to optimize the perception of scatterplots. Our approach takes into account the spatial relationships, density, degree of overlap between point clusters, and also the background color. For this purpose, we use a genetic algorithm that is able to efficiently find good color assignments. We implemented an interactive color assignment system with three extensions of the basic method that incorporates top K suggestions, user-defined color subsets, and classes of interest for the optimization. To demonstrate the effectiveness of our assignment technique, we conducted a numerical study and a controlled user study to compare our approach with default color assignments; our findings were verified by two expert studies. The results show that our approach is able to support users in distinguishing cluster numbers faster and more precisely than default assignment methods.",http://www.color-assignment.net/,,,,vimeo 289785222,10.1109/tvcg.2018.2864912,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 1,25-Oct,2:40 PM,3:00 PM
InfoVis,TVCG,Looks Good To Me: Visualizations As Sanity Checks,J),"Michael Correll, Mingwei Li, Gordon L Kindlmann, Carlos Scheidegger",https://github.com/AlgebraicVis/SanityCheck/blob/master/InfoVis/preprint.pdf,"Famous examples such as Anscombe's Quartet highlight that one of the core benefits of visualizations is allowing people to discover visual patterns that might otherwise be hidden by summary statistics. This visual inspection is particularly important in exploratory data analysis, where analysts can use visualizations such as histograms and dot plots to identify data quality issues. Yet, these visualizations are driven by parameters such as histogram bin size or mark opacity that have a great deal of impact on the final visual appearance of the chart, but are rarely optimized to make important features visible. In this paper, we show that data flaws have varying impact on the visual features of visualizations, and that the adversarial or merely uncritical setting of design parameters of visualizations can obscure the visual signatures of these flaws. Drawing on the framework of Algebraic Visualization Design, we present the results of a crowdsourced study showing that common visualization types can appear to reasonably summarize distributional data while hiding large and important flaws such as missing data and extraneous modes. We make use of these results to propose additional best practices for visualizations of distributions for data quality tasks.",https://medium.com/@mcorrell/looks-good-to-me-visualizations-as-sanity-checks-6fd1ffa37ab9,https://github.com/AlgebraicVis/SanityCheck/tree/master/study,https://github.com/AlgebraicVis/SanityCheck/tree/master/study/data,,vimeo 289785290,10.1109/tvcg.2018.2864907,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 1,25-Oct,3:00 PM,3:20 PM
TVCG,TVCG,Is There a Robust Technique for Selecting Aspect Ratios in Line Charts?,T),"Yunhai Wang, Zeyu Wang, Lifeng Zhu, Jian Zhang, Chi-Wing Fu, Changhe Tu, Baoquan Chen, Zhanglin Cheng",http://www.yunhaiwang.org/bankto45/as-tvcg.pdf,"The aspect ratio of a line chart heavily influences the perception of the underlying data. Different methods explore different criteria in choosing aspect ratios, but so far, it was still unclear how to select aspect ratios appropriately for any given data. This paper provides a guideline for the user to choose aspect ratios for any input 1D curves by conducting an in-depth analysis of aspect ratio selection methods both theoretically and experimentally. By formulating several existing methods as line integrals, we explain their parameterization invariance. Moreover, we derive a new and improved aspect ratio selection method, namely the L1-LOR (local orientation resolution), with a certain degree of parameterization invariance. Furthermore, we connect different methods, including AL (arc length based method), the banking to 45° principle, RV (resultant vector) and AS (average absolute slope), as well as L1-LOR and AO (average absolute orientation). We verify these connections by a comparative evaluation involving various data sets, and show that the selections by RV and L1-LOR are complementary to each other for most data. Accordingly, we propose the dual-scale banking technique that combines the strengths of RV and L1-LOR, and demonstrate its practicability using multiple real-world data sets.",,,,,vimeo 289789006,10.1109/tvcg.2017.2787113,2017,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 1,25-Oct,3:20 PM,3:40 PM
InfoVis,TVCG,Image-based Aspect Ratio Selection,J),"Yunhai Wang, Zeyu Wang, Chi-Wing Fu, Hansjörg Schmauder, Oliver Deussen, Daniel Weiskopf",http://www.yunhaiwang.org/infovis18/dbar/paper.pdf,"Selecting a good aspect ratio is crucial for effective 2D diagrams. There are several aspect ratio selection methods for function plots and line charts, but only few can handle general, discrete diagrams such as 2D scatter plots. However, these methods either lack a perceptual foundation or heavily rely on intermediate isoline representations, which depend on choosing the right isovalues and are time-consuming to compute. This paper introduces a general image-based approach for selecting aspect ratios for a wide variety of 2D diagrams, ranging from scatter plots and density function plots to line charts. Our approach is derived from Federer's co-area formula and a line integral representation that enable us to directly construct image-based versions of existing selection methods using density fields. In contrast to previous methods, our approach bypasses isoline computation, so it is faster to compute, while following the perceptual foundation to select aspect ratios. Furthermore, this approach is complemented by an anisotropic kernel density estimation to construct density fields, allowing us to more faithfully characterize data patterns, such as the subgroups in scatterplots or dense regions in time series. We demonstrate the effectiveness of our approach by quantitatively comparing to previous methods and revisiting a prior user study. Finally, we present extensions for ROI banking, multi-scale banking, and the application to image data.",,,,,vimeo 289784435,10.1109/TVCG.2018.2865266,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 1,25-Oct,3:40 PM,4:00 PM
SciVis,TVCG,Persistence Atlas for Critical Point Variability in Ensembles,J),"Guillaume Favelier, Noura Faraj, Brian Summa, Julien Tierny",https://arxiv.org/pdf/1807.11212.pdf,"This paper presents a new approach for the visualization and analysis of the spatial variability of features of interest represented by critical points in ensemble data. Our framework, called Persistence Atlas, enables the visualization of the dominant spatial patterns of critical points, along with statistics regarding their occurrence in the ensemble. The persistence atlas represents in the geometrical domain each dominant pattern in the form of a confidence map for the appearance of critical points. As a by-product, our method also provides 2-dimensional layouts of the entire ensemble, highlighting the main trends at a global level. Our approach is based on the new notion of Persistence Map, a measure of the geometrical density in critical points which leverages the robustness to noise of topological persistence to better emphasize salient features. We show how to leverage spectral embedding to represent the ensemble members as points in a low-dimensional Euclidean space, where distances between points measure the dissimilarities between critical point layouts and where statistical tasks, such as clustering, can be easily carried out. Further, we show how the notion of mandatory critical point can be leveraged to evaluate for each cluster confidence regions for the appearance of critical points. Most of the steps of this framework can be trivially parallelized and we show how to efficiently implement them. Extensive experiments demonstrate the relevance of our approach. The accuracy of the confidence regions provided by the persistence atlas is quantitatively evaluated and compared to a baseline strategy using an off-the-shelf clustering approach. We illustrate the importance of the persistence atlas in a variety of real-life datasets, where clear trends in feature layouts are identified and analyzed. We provide a lightweight VTK-based C++ implementation of our approach that can be used for reproduction purposes.",,,,,vimeo 290325207,10.1109/tvcg.2018.2864432,2018,2018,SciVis,Estrel A+B,Thursday,"Topology, Geometry, and Precision",25-Oct,2:20 PM,2:40 PM
SciVis,TVCG,Probabilistic Asymptotic Decider for Topological Ambiguity Resolution in Level-Set Extraction for Uncertain 2D Data,J),"Tushar Athawale, Chris R. Johnson",http://tusharathawale.info/wp-content/uploads/2018/09/vis18ProbabilisticAsympDecider.pdf,"We present a framework for the analysis of uncertainty in isocontour extraction. The marching squares (MS) algorithm for isocontour reconstruction generates a linear topology that is consistent with hyperbolic curves of a piecewise bilinear interpolation. The saddle points of the bilinear interpolant cause topological ambiguity in isocontour extraction. The midpoint decider and the asymptotic decider are well-known mathematical techniques for resolving topological ambiguities. The latter technique investigates the data values at the cell saddle points for ambiguity resolution. The uncertainty in data, however, leads to uncertainty in underlying bilinear interpolation functions for the MS algorithm, and hence, their saddle points. In our work, we study the behavior of the asymptotic decider when data at grid vertices is uncertain. First, we derive closed-form distributions characterizing variations in the saddle point values for uncertain bilinear interpolants. The derivation assumes uniform and nonparametric noise models, and it exploits the concept of ratio distribution for analytic formulations. Next, the probabilistic asymptotic decider is devised for ambiguity resolution in uncertain data using distributions of the saddle point values derived in the first step. Finally, the confidence in probabilistic topological decisions is visualized using a colormapping technique. We demonstrate the higher accuracy and stability of the probabilistic asymptotic decider in uncertain data with regard to existing decision frameworks, such as deciders in the mean field and the probabilistic midpoint decider, through the isocontour visualization of synthetic and real datasets.",,,,,vimeo 290325318,10.1109/TVCG.2018.2864505,2018,2018,SciVis,Estrel A+B,Thursday,"Topology, Geometry, and Precision",25-Oct,2:40 PM,3:00 PM
SciVis,TVCG,Hexahedral Mesh Structure Visualization and Evaluation,J),"Kaoji Cotrik Xu, Guoning Chen",http://www2.cs.uh.edu/~chengu/Publications/HexMesh/Vis2018_BaseComplexVis.pdf,"Understanding hexahedral (hex-) mesh structures is important for a number of hex-mesh generation and optimization tasks. However, due to various configurations of the singularities in a valid pure hex-mesh, the structure (or base complex) of the mesh can be arbitrarily complex. In this work, we present a first and effective method to help meshing practitioners understand the possible configurations in a valid 3D base complex for the characterization of their complexity. In particular, we propose a strategy to decompose the complex hex-mesh structure into multi-level sub-structures so that they can be studied separately, from which we identify a small set of the sub-structures that can most efficiently represent the whole mesh structure. Furthermore, from this set of sub-structures, we attempt to define the first metric for the quantification of the complexity of hex-mesh structure. To aid the exploration of the extracted multi-level structure information, we devise a visual exploration system coupled with a matrix view to help alleviate the common challenge of 3D data exploration (e.g., clutter and occlusion). We have applied our tool and metric to a large number of hex-meshes generated with different approaches to reveal different characteristics of these methods in terms of the mesh structures they can produce. We also use our metric to assess the existing structure simplification techniques in terms of their effectiveness.",,,,,vimeo 290327525,10.1109/tvcg.2018.2864827,2018,2018,SciVis,Estrel A+B,Thursday,"Topology, Geometry, and Precision",25-Oct,3:00 PM,3:20 PM
SciVis,TVCG,Shared-Memory Parallel Computation of Morse-Smale Complexes with Improved Accuracy,J),"Attila Gyulassy, Peer-Timo Bremer, Valerio Pascucci",,,,,,,vimeo 290328033,10.1109/TVCG.2018.2864848,2018,2018,SciVis,Estrel A+B,Thursday,"Topology, Geometry, and Precision",25-Oct,3:20 PM,3:40 PM
SciVis,TVCG,A Study of the Trade-off between Reduced Precision and Resolution for Scientific Data Analysis and Visualization,J),"Duong Hoang, Pavol Klacansky, Harsh Bhatia, Peer-Timo Bremer, Peter Lindstrom, Valerio Pascucci",,,,,,,vimeo 290328254,10.1109/TVCG.2018.2864853,2018,2018,SciVis,Estrel A+B,Thursday,"Topology, Geometry, and Precision",25-Oct,3:40 PM,4:00 PM
SciVis,SciVis,An Organic Visual Metaphor for Public Understanding of Conditional Co-occurrences,,"Keshav Dasu, Takanori Fujiwara, Kwan-Liu Ma",,,,https://github.com/takanori-fujiwara/organic-visual-metaphor,,,vimeo 290328908,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,2:20 PM,2:32 PM
SciVis,SciVis,VAPLI: Novel Visual Abstraction for Protein-Lipid Interactions,,"Naif Alharbi, Matthieu Chavent, Michael Krone, Robert S. Laramee",http://cs.swan.ac.uk/~csbob/research/mdv/interaction/alharbi18vapli.pdf,"Molecular visualization of molecular dynamics data commonly uses representative surfaces of varying resolution to depict protein molecules while a variety of geometric shapes, from lines to spheres, are often used to represent atoms and inter-atomic bonds. In general, the aim of molecular visualization is focused on efficiently rendering atoms or molecules themselves, while the interaction space between them is less explored. Furthermore, with naive approaches rendering every molecule, the particles overlap so that significant interaction details are obscured due to clutter. Contrary to common approaches, our work focuses on the interaction between lipids and proteins and the area in which this occurs, the - lipid - membrane. To do so, we introduce a novel abstract interaction space for Protein-Lipid Interaction (PLI). The cylindrical abstraction simplifies perception and computation of PLI. It does so by using a local projection of PLI onto a cylindrical geometry. This also addresses the challenge of visualizing complex, time-dependent interactions between these molecules. We propose a fast GPU-based implementation that maps lipid-constituents involved in the interaction onto the abstract protein interaction space. The tool provides interactive rendering of PLI for 336,260 particles over almost 2,000 time-steps. The result is a great simplification of this complex Protein-Lipid Interaction leading to both better perception and new insight for computational biologists",,,,,vimeo 290328550,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,2:32 PM,2:44 PM
SciVis,SciVis,Color Interpolation for non-Euclidean Color Spaces,,"Max Zeyen, Tobias Post, Hans Hagen, James Ahrens, David Rogers, Roxana Bujack",,,,,,,vimeo 290328621,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,2:45 PM,2:57 PM
SciVis,SciVis,VRGE: An Immersive Visualization Application for the Geosciences,,"David A. B. Hyde, Tyler R. Hall, Jef Caers",,,,,,,vimeo 290328472,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,2:57 PM,3:09 PM
SciVis,SciVis,3De Interactive Lenses for Visualization in Virtual Environments,,"Roberta C. R. Mota, Allan Rocha, Julio D. Silva, Usman R. Alim, Ehud Sharlin",,,,,,,vimeo 290328419,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,3:10 PM,3:22 PM
SciVis,SciVis,Toward A Deep Understanding of What Makes a Scientific Visualization Memorable,,"Rui Li, Jian Chen",https://arxiv.org/pdf/1808.00607.pdf,"We report results from a preliminary study exploring the memorability of spatial scientific visualizations, the goal of which is to understand the visual features that contribute to memorability. The evaluation metrics include three objective measures (entropy, feature congestion, the number of edges), four subjective ratings (clutter, the number of distinct colors, familiarity, and realism), and two sentiment ratings (interestingness and happiness). We curate 1142 scientific visualization (SciVis) images from the original 2231 images in published IEEE SciVis papers from 2008 to 2017 and compute memorability scores of 228 SciVis images from data collected on Amazon Mechanical Turk (MTurk). Results showed that the memorability of SciVis images is mostly correlated with clutter and the number of distinct colors. We further investigate the differences between scientific visualization and infographics as a means to understand memorability differences by data attributes.",,https://ivclexp.github.io/scivismemorability/#download,,,vimeo 290328799,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,3:22 PM,3:34 PM
SciVis,SciVis,Ordering Perceptions about Perceptual Order,,"Roxana Bujack, Terece L Turton, David Rogers, James Ahrens",,,,,,,vimeo 290328692,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,3:35 PM,3:47 PM
SciVis,SciVis,QuFlow: Visualizing Parameter Flow in Quantum Circuits for Understanding Quantum Computation,,"Siyuan Lin, Hao Jiang, Lingyun Sun",,,,,,,vimeo 290328716,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,3:47 PM,3:59 PM
VAST,TVCG,RuleMatrix: Visualizing and Understanding Classifiers with Rules,J),"Yao Ming, Huamin Qu, Enrico Bertini",https://arxiv.org/pdf/1807.06228.pdf,"With the growing adoption of machine learning techniques, there is a surge of research interest towards making machine learning systems more transparent and interpretable. Various visualizations have been developed to help model developers understand, diagnose, and refine machine learning models. However, a large number of potential but neglected users are the domain experts with little knowledge of machine learning but are expected to work with machine learning systems. In this paper, we present an interactive visualization technique to help users with little expertise in machine learning to understand, explore and validate predictive models. By viewing the model as a black box, we extract a standardized rule-based knowledge representation from its input-output behavior. We design RuleMatrix, a matrix-based visualization of rules to help users navigate and verify the rules and the black-box model. We evaluate the effectiveness of RuleMatrix via two use cases and a usability study.",http://myaooo.com/projects/rule-matrix/,https://github.com/rulematrix/rule-matrix-py,,,vimeo 289787299,10.1109/TVCG.2018.2864812,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Explainable ML,25-Oct,4:20 PM,4:40 PM
VAST,TVCG,Seq2Seq-Vis: A Visual Debugging Tool for Sequence to Sequence Models,J),"Hendrik Strobelt, Sebastian Gehrmann, Michael Behrisch, Adam Perer, Hanspeter Pfister, Alexander M. Rush",https://arxiv.org/pdf/1804.09299.pdf,"Neural sequence-to-sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work with a five-stage blackbox pipeline that begins with encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction and ”what if”-style exploration of trained sequence-to-sequence models through each stage of the translation process. The aim is to identify which patterns have been learned, to detect model errors, and to probe the model with counterfactual scenario. We demonstrate the utility of our tool through several real-world sequence-to-sequence use cases on large-scale models.",,https://github.com/HendrikStrobelt/Seq2Seq-Vis,,,vimeo 289787650,10.1109/TVCG.2018.2865044,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Explainable ML,25-Oct,4:40 PM,5:00 PM
VAST,TVCG,Manifold: A Model-Agnostic Framework for Interpretation and Diagnosis of Machine Learning Models,J),"Jiawei Zhang, Yang Wang, Piero Molino, Lezhi Li, David Ebert",https://arxiv.org/pdf/1808.00196.pdf,"Interpretation and diagnosis of machine learning models have gained renewed interest in recent years with breakthroughs in new approaches. We present Manifold, a framework that utilizes visual analysis techniques to support interpretation, debugging, and comparison of machine learning models in a more transparent and interactive manner. Conventional techniques usually focus on visualizing the internal logic of a specific model type (i.e., deep neural networks), lacking the ability to extend to a more complex scenario where different model types are integrated. To this end, Manifold is designed as a generic framework that does not rely on or access the internal logic of the model and solely observes the input (i.e., instances or features) and the output (i.e., the predicted result and probability distribution). We describe the workflow of Manifold as an iterative process consisting of three major phases that are commonly involved in the model development and diagnosis process: inspection (hypothesis), explanation (reasoning), and refinement (verification). The visual components supporting these tasks include a scatterplot-based visual summary that overviews the models’ outcome and a customizable tabular view that reveals feature discrimination. We demonstrate current applications of the framework on the classification and regression tasks and discuss other potential machine learning use scenarios where Manifold can be applied.",,,,,vimeo 289787203,10.1109/tvcg.2018.2864499,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Explainable ML,25-Oct,5:00 PM,5:20 PM
VAST,TVCG,Visual Analytics for Topic Model Optimization based on User-Steerable Speculative Execution,J),"Mennatallah El-Assady, Fabian Sperrle, Oliver Deussen, Daniel Keim, Christopher Collins",http://graphics.uni-konstanz.de/publikationen/ElAssady2018VisualAnalytic/visualanalyticstopic.pdf,"To effectively assess the potential consequences of human interventions in model-driven analytics systems, we establish the concept of speculative execution as a visual analytics paradigm for creating user-steerable preview mechanisms. This paper presents an explainable, mixed-initiative topic modeling framework that integrates speculative execution into the algorithmic decisionmaking process. Our approach visualizes the model-space of our novel incremental hierarchical topic modeling algorithm, unveiling its inner-workings. We support the active incorporation of the user’s domain knowledge in every step through explicit model manipulation interactions. In addition, users can initialize the model with expected topic seeds, the backbone priors. For a more targeted optimization, the modeling process automatically triggers a speculative execution of various optimization strategies, and requests feedback whenever the measured model quality deteriorates. Users compare the proposed optimizations to the current model state and preview their effect on the next model iterations, before applying one of them. This supervised human-in-the-loop process targets maximum improvement for minimum feedback and has proven to be effective in three independent studies that confirm topic model quality improvements.",,,,,vimeo 289787264,10.1109/tvcg.2018.2864769,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Explainable ML,25-Oct,5:20 PM,5:40 PM
VAST,TVCG,VIS4ML: An Ontology for Visual Analytics Assisted Machine Learning,J),"Dominik Sacha, Matthias Kraus, Daniel Keim, Min Chen",https://bib.dbvis.de/uploadedFiles/TVCG2864838.pdf,"While many VA workflows make use of machine-learned models to support analytical tasks, VA workflows have become increasingly important in understanding and improving Machine Learning (ML) processes. In this paper, we propose an ontology (VIS4ML) for a subarea of VA, namely “VA-assisted ML”. The purpose of VIS4ML is to describe and understand existing VA workflows used in ML as well as to detect gaps in ML processes and the potential of introducing advanced VA techniques to such processes. Ontologies have been widely used to map out the scope of a topic in biology, medicine, and many other disciplines. We adopt the scholarly methodologies for constructing VIS4ML, including the specification, conceptualization, formalization, implementation, and validation of ontologies. In particular, we reinterpret the traditional VA pipeline to encompass model-development workflows. We introduce necessary definitions, rules, syntaxes, and visual notations for formulating VIS4ML and make use of semantic web technologies for implementing it in the Web Ontology Language (OWL). VIS4ML captures the high-level knowledge about previous workflows where VA is used to assist in ML. It is consistent with the established VA concepts and will continue to evolve along with the future developments in VA and ML. While this ontology is an effort for building the theoretical foundation of VA, it can be used by practitioners in real-world applications to optimize model-development workflows by systematically examining the potential benefits that can be brought about by either machine or human capabilities. Meanwhile, VIS4ML is intended to be extensible and will continue to be updated to reflect future advancements in using VA for building high-quality data-analytical models or for building such models rapidly",,,,,vimeo 289787814,10.1109/TVCG.2018.2864838,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Explainable ML,25-Oct,5:40 PM,6:00 PM
InfoVis,TVCG,Mitigating the Attraction Effect with Visualizations,J),"Evanthia Dimara, Gilles Bailly, Anastasia Bezerianos, Steven Franconeri",https://hal.inria.fr/hal-01845004v2/document,"Human decisions are prone to biases, and this is no less true for decisions made within data visualizations. Bias mitigation strategies often focus on the person, by educating people about their biases, typically with little success. We focus instead on the system, presenting the first evidence that altering the design of an interactive visualization tool can mitigate a strong bias – the attraction effect. Participants viewed 2D scatterplots where choices between superior alternatives were affected by the placement of other suboptimal points. We found that highlighting the superior alternatives weakened the bias, but did not eliminate it. We then tested an interactive approach where participants completely removed locally dominated points from the view, inspired by the elimination by aspects strategy in the decision-making literature. This approach strongly decreased the bias, leading to a counterintuitive suggestion: tools that allow removing inappropriately salient or distracting data from a view may help lead users to make more rational decisions.",,https://aviz.fr/deletion,https://aviz.fr/deletion,,vimeo 289784657,10.1109/TVCG.2018.2865233,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 2,25-Oct,4:20 PM,4:40 PM
InfoVis,TVCG,Face to Face: Evaluating Visual Comparison,J),"Brian David Ondov, Nicole Jardine, Niklas Elmqvist, Steven Franconeri",http://users.umiacs.umd.edu/~elm/projects/face2face/face2face.pdf,"Data are often viewed as a single set of values, but those values frequently must be compared with another set. The existing evaluations of designs that facilitate these comparisons tend to be based on intuitive reasoning, rather than quantifiable measures. We build on this work with a series of crowdsourced experiments that use low-level perceptual comparison tasks that arise frequently in comparisons within data visualizations (e.g., which value changes the most between the two sets of data?). Participants completed these tasks across a variety of layouts: overlaid, two arrangements of juxtaposed small multiples, mirror-symmetric small multiples, and animated transitions. A staircase procedure sought the difficulty level (e.g., value change delta) that led to equivalent accuracy for each layout. Confirming prior intuition, we observe high levels of performance for overlaid versus standard small multiples. However, we also find performance improvements for both mirror symmetric small multiples and animated transitions. While some results are incongruent with common wisdom in data visualization, they align with previous work in perceptual psychology, and thus have potentially strong implications for visual comparison designs.",,,,,vimeo 289785372,10.1109/tvcg.2018.2864884,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 2,25-Oct,4:40 PM,5:00 PM
TVCG,TVCG,Task-Based Effectiveness of Basic Visualizations,T),"Bahador Saket, Alex Endert, Çagatay Demiralp",https://arxiv.org/pdf/1709.08546.pdf,"Visualizations of tabular data are widely used; understanding their effectiveness in different task and data contexts is fundamental to scaling their impact. However, little is known about how basic tabular data visualizations perform across varying data analysis tasks. In this paper, we report results from a crowdsourced experiment to evaluate the effectiveness of five small scale (5-34 data points) two-dimensional visualization types—Table, Line Chart, Bar Chart, Scatterplot, and Pie Chart—across ten common data analysis tasks using two datasets. We find the effectiveness of these visualization types significantly varies across task, suggesting that visualization design would benefit from considering context-dependent effectiveness. Based on our findings, we derive recommendations on which visualizations to choose based on different tasks. We finally train a decision tree on the data we collected to drive a recommender, showcasing how to effectively engineer experimental user data into practical visualization systems.",,,https://github.com/gtvalab/ChartsEffectiveness/tree/master/Raw-Data,,vimeo 289789506,10.1109/tvcg.2018.2829750,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 2,25-Oct,5:00 PM,5:20 PM
InfoVis,TVCG,At a Glance: Approximate Entropy as a Measure of Line Chart Visualization Complexity,J),"Eugene Wu, Remco Chang, Abigail Mosca, Gabriel Ryan",http://arxiv.org/abs/1811.03180,"When inspecting information visualizations under time critical settings, such as emergency response or monitoring the heart rate in a surgery room, the user only has a small amount of time to view the visualization ""at a glance"". In these settings, it is important to provide a quantitative measure of the visualization to understand whether or not the visualization is too ""complex"" toaccurately judge at a glance. This paper proposes Pixel Approximate Entropy (PAE), which adapts the approximate entropy statistical measure commonly used to quantify regularity and unpredictability in time-series data, as a measure of visual complexity for linecharts. We show that PAE is correlated with user-perceived chart complexity, and that increased chart PAE correlates with reduced judgement accuracy. ‘We also find that the correlation between PAE values and participants’ judgment increases when the user has less time to examine the line charts.",,https://github.com/cudbg/pae,,,vimeo 289784475,10.1109/TVCG.2018.2865264,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 2,25-Oct,5:20 PM,5:40 PM
TVCG,TVCG,Correlation Judgment and Visualization Features: A Comparative Study,T),"Fumeng Yang, Lane Harrison, Ronald A. Rensink, Steven Franconeri, Remco Chang",https://github.com/Fumeng-Yang/VisualFeature_TVCG/blob/master/paper/VF_preprint.pdf,"Recent visualization research efforts have incorporated experimental techniques and perceptual models from the vision science community. Perceptual laws such as Weber's law, for example, have been used to model the perception of correlation in scatterplots. While this thread of research has progressively refined the modeling of the perception of correlation in scatterplots, it remains unclear as to why such perception can be modeled using relatively simple functions, e.g., linear and log-linear. In this paper, we investigate a longstanding hypothesis that people use visual features in a chart as a proxy for statistical measures like correlation. For a given scatterplot, we extract 49 candidate visual features and evaluate which best align with existing models and participant judgments. The results support the hypothesis that people attend to a small number of visual features when discriminating correlation in scatterplots. We discuss how this result may account for prior conflicting findings, and how visual features provide a baseline for future model-based approaches in visualization evaluation and design.",,,,,vimeo 289789613,10.1109/tvcg.2018.2810918,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 2,25-Oct,5:40 PM,6:00 PM
SciVis,TVCG,Firefly: Illumination Drones for Interactive Visualization,J),"Sergej Stoppel, Magnus Paulson Erga, Stefan Bruckner",https://vis.uib.no/wp-content/papercite-data/pdfs/VIS2018-Firefly.pdf,"Light specification in three dimensional scenes is a complex problem and several approaches have been presented that aim to automate this process. However, there are many scenarios where a static light setup is insufficient, as the scene content and camera position may change. Simultaneous manual control over the camera and light position imposes a high cognitive load on the user. To address this challenge, we introduce a novel approach for automatic scene illumination with Fireflies. Fireflies are intelligent virtual light drones that illuminate the scene by traveling on a closed path. The Firefly path automatically adapts to changes in the scene based on an outcome-oriented energy function. To achieve interactive performance, we employ a parallel rendering pipeline for the light path evaluations. We provide a catalog of energy functions for various application scenarios and discuss the applicability of our method on several examples.",,,,,video https://vis.uib.no/wp-content/papercite-data/vids/FinalVideo.mp4,10.1109/TVCG.2018.2864656,2018,2018,SciVis,Estrel Hall A+B,Thursday,Interaction and Multivariate Data,25-Oct,4:20 PM,4:40 PM
SciVis,TVCG,CoDDA: A Flexible Copula-based Distribution Driven Analysis Framework for Large-Scale Multivariate Data,J),"Subhashis Hazarika, Soumya Dutta, Han-Wei Shen, Jen-Ping Chen",,,,,,,vimeo 290325658,10.1109/tvcg.2018.2864801,2018,2018,SciVis,Estrel Hall A+B,Thursday,Interaction and Multivariate Data,25-Oct,4:40 PM,5:00 PM
SciVis,TVCG,"Details-First, Show Context, Overview Last: Supporting Exploration of Viscous Fingers in Large-Scale Ensemble Simulations ",J),"Timothy Basil Luciani, Andrew T Burks, Cassiano Sugiyama, Jonathan Komperda, Liz G.Elisabeta Marai",https://www.evl.uic.edu/documents/detailsfirst_ieee2018.pdf,"Visualization research often seeks designs that first establish an overview of the data, in accordance to the information seeking mantra: “Overview first, zoom and filter, then details on demand ”. However, in computational fluid dynamics (CFD), as well as in other domains, there are many situations where such a spatial overview is not relevant or practical for users, for example when the experts already have a good mental overview of the data, or when an analysis of a large overall structure may not be related to the specific, information-driven tasks of users. Using scientific workflow theory and, as a vehicle, the problem of viscous finger evolution, we advocate an alternative model that allows domain experts to explore features of interest first, then explore the context around those features, and finally move to a potentially unfamiliar summarization overview. In a model instantiation, we show how a computational back-end can identify and track over time low-level, small features, then be used to filter the context of those features while controlling the complexity of the visualization, and finally to summarize and compare simulations. We demonstrate the effectiveness of this approach with an online web-based exploration of a total volume of data approaching half a billion seven-dimensional data points, and report supportive feedback provided by domain experts with respect to both the instantiation and the theoretical model.",,,,,vimeo 290328058,10.1109/TVCG.2018.2864849,2018,2018,SciVis,Estrel Hall A+B,Thursday,Interaction and Multivariate Data,25-Oct,5:00 PM,5:20 PM
TVCG,TVCG,A Model of Spatial Directness in Interactive Visualization,T),"Stefan Bruckner, Tobias Isenberg, Timo Ropinski, Alexander Wiebel",https://hal.inria.fr/hal-01813889/document,"We discuss the concept of directness in the context of spatial interaction with visualization. In particular, we propose a model that allows practitioners to analyze and describe the spatial directness of interaction techniques, ultimately to be able to better understand interaction issues that may affect usability. To reach these goals, we distinguish between different types of directness. Each type of directness depends on a particular mapping between different spaces, for which we consider the data space, the visualization space, the output space, the user space, the manipulation space, and the interaction space. In addition to the introduction of the model itself, we also show how to apply it to several real-world interaction scenarios in visualization, and thus discuss the resulting types of spatial directness, without recommending either more direct or more indirect interaction techniques. In particular, we will demonstrate descriptive and evaluative usage of the proposed model, and also briefly discuss its generative usage.",,,,,vimeo 289789140,10.1109/tvcg.2018.2848906,2018,2018,SciVis,Estrel Hall A+B,Thursday,Interaction and Multivariate Data,25-Oct,5:20 PM,5:40 PM
TVCG,TVCG,Decal-Lenses: Interactive Lenses on Surfaces for Multivariate Visualization,T),"Allan Rocha, Julio Daniel Silva, Usman R. Alim, Sheelagh Carpendale, Mario Costa Sousa",http://pages.cpsc.ucalgary.ca/~acarocha/projects/decal_lenses/files/camera_ready.pdf,"We present decal-lenses, a new interaction technique that extends the concept of magic lenses to augment and manage multivariate visualizations on arbitrary surfaces. Our object-space lenses follow the surface geometry and allow the user to change the point of view during data exploration while maintaining a spatial reference to positions where one or more lenses were placed. Each lens delimits specific regions of the surface where one or more attributes can be selected or combined. Similar to 2D lenses, the user interacts with our lenses in real-time, switching between different attributes within the lens context. The user can also visualize the surface data representations from the point of view of each lens by using local cameras. To place lenses on surfaces of intricate geometry, such as the human brain, we introduce the concept of support surfaces for designing interaction techniques. Support surfaces provide a way to place and interact with the lenses while avoiding holes and occluded regions during data exploration. We further extend decal-lenses to arbitrary regions using brushing and lassoing operations. We discuss the applicability of our technique and present several examples where our lenses can be useful to create a customized exploration of multivariate data on surfaces. ",,,,,vimeo 295735599,10.1109/tvcg.2018.2850781,2018,2018,SciVis,Estrel Hall A+B,Thursday,Interaction and Multivariate Data,25-Oct,5:40 PM,6:00 PM
SciVis,SciVis,Cluster-Based Visualization for Merger Tree Data: The Challenge of Missing Expectations,,"Annie Preston, Kwan-Liu Ma",,,,,,,vimeo 290328886,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,4:20 PM,4:32 PM
SciVis,SciVis,Visualization of Uncertainty for Computationally Intensive Simulations Using High Fidelity Emulators,,"Ayan Biswas, Earl Lawrence, James Ahrens",http://ayanbiswas.net/vis18m-sub1022-cam-i7.pdf,"Visualization of high-fidelity scientific simulations with high-dimensional inputs and outputs is an important task. Existing high-dimensional data visualization approaches generally assume a substantial amount of data are available or can be generated as needed. However, many of these simulations can be very computationally intensive, taking minutes or hours to run. Analysis and visualization of such expensive simulations poses a challenge. Statistical emulators are frequently used to approximate simulations for statistical analyses. In this work, we propose a visualization tool for an emulator of the simulator and describe how emulators can be used to create effective visualization systems. We choose Gaussian process emulators for this purpose as they enable fast and accurate prediction with uncertainty information. Using these predictions, we design a system that enables visualization of high-dimensional input and output spaces of complex physics simulations. Users of our system can get a detailed understanding of the uncertainties associated with the emulator predictions in both input and output space for a high-dimensional simulation.",,,,,vimeo 290328642,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,4:32 PM,4:44 PM
SciVis,SciVis,A Lagrangian Method for Extracting Eddy Boundaries in the Red Sea and the Gulf of Aden,,"Anke Friederici, Habib Toye, Ibrahim Hoteit, Tino Weinkauf, Holger Theisel, Markus Hadwiger",http://www.medvis-award.de/visual/files/publications/2018/Friederici_2018_VIS_paper.pdf,"Mesoscale ocean eddies play a major role for both the intermixing of water and the transport of biological mass. This makes the identification and tracking of their shape, location and deformation over time highly important for a number of applications. While eddies maintain a roughly circular shape in the free ocean, the narrow basins of the Red Sea and Gulf of Aden lead to the formation of irregular eddy shapes that existing methods struggle to identify. We propose the following model: Inside an eddy, particles rotate around a common core and thereby remain at a constant distance under a certain parametrization. The transition to the more unpredictable flow on the outside can thus be identified as the eddy boundary. We apply this algorithm on a realistic simulation of the Red Sea circulation, where we are able to identify the shape of irregular eddies robustly and more coherently than previous methods. We visualize the eddies as tubes in space-time to enable the analysis of their movement and deformation over several weeks.",,,,,video http://vccvisualization.org/publications/2018_friederici_redseaeddies.mp4,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,4:45 PM,4:57 PM
SciVis,SciVis,FTLE Ridge Lines for Long Integration Times,,"Thomas Wilde, Christian Rössl, Holger Theisel",http://www.medvis-award.de/visual/files/publications/2018/Wilde_2018_VISb.pdf,"We present an approach to the extraction of FTLE ridges for 2D unsteady vector fields under long integration times. This is a hard problem because such FTLE ridges tend to be sharp and close to each other. The main feature of our approach is that it does not only use an FTLE sampling at the desired final integration time but incorporates samples from prior integration times as well. With this additional information, the new method produces more and finer ridge lines than previous approaches. Based on this output, we can consider FTLE ridge statistics. We test the approach on synthetic benchmarks and real-world data sets.",,,,,vimeo 290328753,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,4:57 PM,5:09 PM
SciVis,SciVis,Ocean Current Segmentation at Different Depths and Correlation with Temperature in a MPAS-Ocean Simulation,,"Petra Gospodnetic, Divya Banesh, Philip Wolfram, Mark Petersen, Hans Hagen, James Ahrens, Markus Rauhut",,,,,,,vimeo 290328665,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,5:10 PM,5:22 PM
SciVis,SciVis,"TimeTubes: Automatic Extraction of Observable Blazar Features from Long-Term, Multi-Dimensional Datasets",,"Naoko Sawada, Masanori Nakayama, Makoto Uemura, Issei Fujishiro",,,,,,,vimeo 290328934,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,5:22 PM,5:34 PM
SciVis,SciVis,aflak: Pluggable Visual Programming Environment with Quick Feedback Loop Tuned for Astrophysical Observations,,"Malik Olivier Boussejra, Kazuya Matsubayashi, Yuriko Takeshima, Shunya Takekawa, Rikuo Uchiki, Makoto Uemura, Issei Fujishiro",,,,,,,vimeo 290328343,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,5:35 PM,5:47 PM
SciVis,SciVis,Biclusters based Visual Exploration of Multivariate Scientific Data,,"Xiangyang He, Yubo Tao, Qirui Wang, Hai Lin",http://www.cad.zju.edu.cn/home/ybtao/papers/SciVis18_Biclusters.pdf,"This paper proposes a co-analysis framework based on biclusters, i.e., two subsets of variables and voxels with close scalar-value relationships, to guide the visual exploration process of multivariate data. We first automatically extract all meaningful biclusters, each of which only contains voxels with a similar scalar-value pattern over a subset of variables. These biclusters are organized according to their variable sets, and further grouped by a similarity metric to reduce redundancy and encourage diversity during visual exploration. Biclusters are visually represented in coordinated views to facilitate interactive exploration of multivariate data from the similarity between biclusters and the correlation of scalar values with different variables. Experiments demonstrate the effectiveness of our framework in exploring local relationships among variables, biclusters and scalar values in the data.",,,,,vimeo 290328582,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,5:47 PM,6:00 PM
VAST,TVCG,MAQUI: Interweaving Queries and Pattern Mining for Recursive Event Sequence Exploration,J),"Po-Ming Law, Zhicheng Liu, Sana Malik, Rahul Basole",http://www.zcliu.org/maqui/MAQUI_vast18.pdf,"Exploring event sequences by defining queries alone or by using mining algorithms alone is often not sufficient to support analysis. Analysts often interweave querying and mining in a recursive manner during event sequence analysis: sequences extracted as query results are used for mining patterns, patterns generated are incorporated into a new query for segmenting the sequences, and the resulting segments are mined or queried again. To support flexible analysis, we propose a framework that describes the process of interwoven querying and mining. Based on this framework, we developed MAQUI, a Mining And Querying User Interface that enables recursive event sequence exploration. To understand the efficacy of MAQUI, we conducted two case studies with domain experts. The findings suggest that the capability of interweaving querying and mining helps the participants articulate their questions and gain novel insights from their data.",,https://github.com/terrancelaw/MAQUI,,,vimeo 289787863,10.1109/TVCG.2018.2864886,2018,2018,VAST,"Convention Hall 1, Section C",Friday,"Event, Sequence, and ML",26-Oct,9:00 AM,9:20 AM
VAST,TVCG,iForest: Interpreting Random Forests via Visual Analytics,J),"Xun Zhao, Yanhong Wu, Dik Lun Lee, Weiwei Cui",http://zhaoxun.me/publication/iForest.pdf,"As an ensemble model that consists of many independent decision trees, random forests generate predictions by feeding the input to internal trees and summarizing their outputs. The ensemble nature of the model helps random forests outperform any individual decision tree. However, it also leads to a poor model interpretability, which significantly hinders the model from being used in fields that require transparent and explainable predictions, such as medical diagnosis and financial fraud detection. The interpretation challenges stem from the variety and complexity of the contained decision trees. Each decision tree has its unique structure and properties, such as the features used in the tree and the feature threshold in each tree node. Thus, a data input may lead to a variety of decision paths. To understand how a final prediction is achieved, it is desired to understand and compare all decision paths in the context of all tree structures, which is a huge challenge for any users. In this paper, we propose a visual analytic system aiming at interpreting random forest models and predictions. In addition to providing users with all the tree information, we summarize the decision paths in random forests, which eventually reflects the working mechanism of the model and reduces users’ mental burden of interpretation. To demonstrate the effectiveness of our system, two usage scenarios and a qualitative user study are conducted.",,,,,vimeo 289787165,10.1109/tvcg.2018.2864475,2018,2018,VAST,"Convention Hall 1, Section C",Friday,"Event, Sequence, and ML",26-Oct,9:20 AM,9:40 AM
VAST,TVCG,Visual Progression Analysis of Event Sequence Data,J),"Shunan Guo, Zhuochen Jin, David Gotz, Fan Du, Hongyuan Zha, Nan Cao",http://gotz.web.unc.edu/files/2018/08/2018_VAST_EventThread_V2_Preprint.pdf,"Event sequence data is common to a broad range of application domains, from security to health care to scholarly communication. This form of data captures information about the progression of events for an individual entity (e.g., a computer network device; a patient; an author) in the form of a series of time-stamped observations. Moreover, each event is associated with an event type (e.g., a computer login attempt, or a hospital discharge). Analyses of event sequence data have been shown to help reveal important temporal patterns, such as clinical paths resulting in improved outcomes, or an understanding of common career trajectories for scholars. Moreover, recent research has demonstrated a variety of techniques designed to overcome methodological challenges such as large volumes of data and high dimensionality. However, the effective identication and analysis of latent stages of progression, which can allow for variation within different but similarly evolving event sequences, remain a signicant challenge with important real-world motivations. In this paper, we propose an unsupervised stage analysis algorithm to identify semantically meaningful progression stages as well as the critical events which help dene those stages. The algorithm follows three key steps: (1) event representation estimation, (2) event sequence warping and alignment, and (3) sequence segmentation. We also present a novel visualization system, ET2 , which interactively illustrates the results of the stage analysis algorithm to help reveal evolution patterns across stages. Finally, we report three forms of evaluation for ET2 : (1) case studies with two real-world datasets, (2) interviews with domain expert users, and (3) a performance evaluation on the progression analysis algorithm and the visualization design",,,,,vimeo 289787414,10.1109/TVCG.2018.2864885,2018,2018,VAST,"Convention Hall 1, Section C",Friday,"Event, Sequence, and ML",26-Oct,9:40 AM,10:00 AM
TVCG,TVCG,StreamExplorer: A Multi-Stage System for Visually Exploring Events in Social Streams,T),"Yingcai Wu, Zhutian Chen, Guodao Sun, Xiao Xie, Nan Cao, Shixia Liu, Weiwei Cui",http://zjuvis.org/files/streamexplorer.pdf,"Analyzing social streams is important for many applications, such as crisis management. However, the considerable diversity, increasing volume, and high dynamics of social streams of large events continue to be significant challenges that must be overcome to ensure effective exploration. We propose a novel framework by which to handle complex social streams on a budget PC. This framework features two components: 1) an online method to detect important time periods (i.e., subevents), and 2) a tailored GPU-assisted Self-Organizing Map (SOM) method, which clusters the tweets of subevents stably and efficiently. Based on the framework, we present StreamExplorer to facilitate the visual analysis, tracking, and comparison of a social stream at three levels. At a macroscopic level, StreamExplorer uses a new glyph-based timeline visualization, which presents a quick multi-faceted overview of the ebb and flow of a social stream. At a mesoscopic level, a map visualization is employed to visually summarize the social stream from either a topical or geographical aspect. At a microscopic level, users can employ interactive lenses to visually examine and explore the social stream from different perspectives. Two case studies and a task-based evaluation are used to demonstrate the effectiveness and usefulness of StreamExplorer.",,,,,vimeo 289788908,10.1109/tvcg.2017.2764459,2017,2018,VAST,"Convention Hall 1, Section C",Friday,"Event, Sequence, and ML",26-Oct,10:00 AM,10:20 AM
VAST,TVCG,Duet: Helping Data Analysis Novices Conduct Pairwise Comparisons by Minimal Specification,J),"Po-Ming Law, Rahul Basole, Yanhong Wu",https://terrancelaw.github.io/publications/duet_vast18.pdf,"Data analysis novices often encounter barriers in executing low-level operations for pairwise comparisons. They may also run into barriers in interpreting the artifacts (e.g., visualizations) created as a result of the operations. We developed Duet, a visual analysis system designed to help data analysis novices conduct pairwise comparisons by addressing execution and interpretation barriers. To reduce the barriers in executing low-level operations during pairwise comparison, Duet employs minimal specication: when one object group (i.e. a group of records in a data table) is specied, Duet recommends object groups that are similar to or different from the specied one; when two object groups are specied, Duet recommends similar and different attributes between them. To lower the barriers in interpreting its recommendations, Duet explains the recommended groups and attributes using both visualizations and textual descriptions. We conducted a qualitative evaluation with eight participants to understand the effectiveness of Duet. The results suggest that minimal specication is easy to use and Duet's explanations are helpful for interpreting the recommendations despite some usability issues.",,,,,vimeo 289787850,10.1109/TVCG.2018.2864526,2018,2018,VAST,"Convention Hall 1, Section C",Friday,"Event, Sequence, and ML",26-Oct,10:20 AM,10:40 AM
InfoVis,TVCG,Visualizing Uncertain Tropical Cyclone Predictions using Representative Samples from Ensembles of Forecast Tracks,J),"Le Liu, Lace M. K. Padilla, Sarah Creem-Regehr, Donald House",http://lacepadilla.com/Downloads/publications/Liuetal_2018.pdf,"A common approach to sampling the space of a prediction is the generation of an ensemble of potential outcomes, where the ensemble's distribution reveals the statistical structure of the prediction space. For example, the US National Hurricane Center generates multiple day predictions for a storm's path, size, and wind speed, and then uses a Monte Carlo approach to sample this prediction into a large ensemble of potential storm outcomes. Various forms of summary visualizations are generated from such an ensemble, often using spatial spread to indicate its statistical characteristics. However, studies have shown that changes in the size of such summary glyphs, representing changes in the uncertainty of the prediction, are frequently confounded with other attributes of the phenomenon, such as its size or strength. In addition, simulation ensembles typically encode multivariate information, which can be difficult or confusing to include in a summary display. This problem can be overcome by directly displaying the ensemble as a set of annotated trajectories, however this solution will not be effective if ensembles are densely overdrawn or structurally disorganized. We propose to overcome these difficulties by selectively sampling the original ensemble, constructing a smaller representative and spatially well organized ensemble. This can be drawn directly as a set of paths that implicitly reveals the underlying spatial uncertainty distribution of the prediction. Since this approach does not use a visual channel to encode uncertainty, additional information can more easily be encoded in the display without leading to visual confusion. To demonstrate our argument, we describe the development of a visualization for ensembles of tropical cyclone forecast tracks, explaining how their spatial and temporal predictions, as well as other crucial storm characteristics such as size and intensity, can be clearly revealed. We verify the effectiveness of this visualization approach through a cognitive study exploring how storm damage estimates are affected by the density of tracks drawn, and by the presence or absence of annotating information on storm size and intensity.",,https://osf.io/hy3ba/,https://osf.io/hy3ba/,,vimeo 289784601,10.1109/TVCG.2018.2865193,2018,2018,InfoVis,"Convention Hall 1, Section D",Friday,Uncertainty & Error,26-Oct,9:00 AM,9:20 AM
InfoVis,TVCG,Hypothetical Outcome Plots Help Untrained Observers Judge Trends in Ambiguous Data,J),"Alex Kale, Francis Nguyen, Matthew Kay, Jessica Hullman",http://users.eecs.northwestern.edu/~jhullman/hops_jobs_pfs.pdf,"Animated representations of outcomes drawn from distributions (hypothetical outcome plots, or HOPs) are used in the media and other public venues to communicate uncertainty. HOPs greatly improve multivariate probability estimation over conventional static uncertainty visualizations and leverage the ability of the visual system to quickly, accurately, and automatically process the summary statistical properties of ensembles. However, it is unclear how well HOPs support applied tasks resembling real world judgments posed in uncertainty communication. We identify and motivate an appropriate task to investigate realistic judgments of uncertainty in the public domain through a qualitative analysis of uncertainty visualizations in the news. We contribute two crowdsourced experiments comparing the effectiveness of HOPs, error bars, and line ensembles for supporting perceptual decision-making from visualized uncertainty. Participants infer which of two possible underlying trends is more likely to have produced a sample of time series data by referencing uncertainty visualizations which depict the two trends with variability due to sampling error. By modeling each participant's accuracy as a function of the level of evidence presented over many repeated judgments, we find that observers are able to correctly infer the underlying trend in samples conveying a lower level of evidence when using HOPs rather than static aggregate uncertainty visualizations as a decision aid. Modeling approaches like ours contribute theoretically grounded and richly descriptive accounts of user perceptions to visualization evaluation.",https://medium.com/@uwdata/hypothetical-outcome-plots-hops-help-users-separate-signal-from-noise-870d4e2b75d7,,https://github.com/kalealex/jobs-report-hops,https://osf.io/8cte3/registrations/,vimeo 289785258,10.1109/tvcg.2018.2864909,2018,2018,InfoVis,"Convention Hall 1, Section D",Friday,Uncertainty & Error,26-Oct,9:20 AM,9:40 AM
InfoVis,TVCG,In Pursuit of Error: A Survey of Uncertainty Visualization Evaluation,J),"Jessica Hullman, Xiaoli Qiao, Michael Correll, Alex Kale, Matthew Kay",https://github.com/jhullman/uncertaintyVisEval/blob/master/uncertainty_vis_eval.pdf,"Understanding and accounting for uncertainty is critical to effectively reasoning about visualized data. However, evaluating the impact of an uncertainty visualization is complex due to the difficulties that people have interpreting uncertainty and the challenge of defining correct behavior with uncertainty information. Currently, evaluators of uncertainty visualization must rely on general purpose visualization evaluation frameworks which can be ill-equipped to provide guidance with the unique difficulties of assessing judgments under uncertainty. To help evaluators navigate these complexities, we present a taxonomy for characterizing decisions made in designing an evaluation of an uncertainty visualization. Our taxonomy differentiates six levels of decisions that comprise an uncertainty visualization evaluation: the behavioral targets of the study, expected effects from an uncertainty visualization, evaluation goals, measures, elicitation techniques, and analysis approaches. Applying our taxonomy to 86 user studies of uncertainty visualizations, we find that existing evaluation practice, particularly in visualization research, focuses on Performance and Satisfaction-based measures that assume more predictable and statistically-driven judgment behavior than is suggested by research on human judgment and decision making. We reflect on common themes in evaluation practice concerning the interpretation and semantics of uncertainty, the use of confidence reporting, and a bias toward evaluating performance as accuracy rather than decision quality. We conclude with a concrete set of recommendations for evaluators designed to reduce the mismatch between the conceptualization of uncertainty in visualization versus other fields.",,https://github.com/jhullman/uncertaintyVisEval,,,vimeo 289785271,10.1109/tvcg.2018.2864889,2018,2018,InfoVis,"Convention Hall 1, Section D",Friday,Uncertainty & Error,26-Oct,9:40 AM,10:00 AM
InfoVis,TVCG,Where's my data? Evaluating Visualizations with Missing Data,J),"Hayeong Song, Danielle Albers Szafir",http://cmci.colorado.edu/visualab/papers/song_VIS_2018.pdf,Many real-world datasets are incomplete due to factors such as data collection failures or misalignments between fused datasets. Visualizations of incomplete datasets should allow analysts to draw conclusions from their data while effectively reasoning about the quality of the data and resulting conclusions. We conducted a pair of crowdsourced studies to measure how the methods used to impute and visualize missing data may influence analysts' perceptions of data quality and their confidence in their conclusions. Our experiments used different design choices for line graphs and bar charts to estimate averages and trends in incomplete time series datasets. Our results provide preliminary guidance for visualization designers to consider when working with incomplete data in different domains and scenarios.,,,http://cmci.colorado.edu/visualab/MissingData/,,vimeo 289785184,10.1109/TVCG.2018.2864914,2018,2018,InfoVis,"Convention Hall 1, Section D",Friday,Uncertainty & Error,26-Oct,10:00 AM,10:20 AM
InfoVis,TVCG,A Framework for Externalizing Implicit Error Using Visualization,J),"Nina McCurdy, Julie Gerdes, Miriah Meyer",http://sci.utah.edu/~vdl/papers/2018_infovis_IE-Framework.pdf,"This paper presents a framework for externalizing and analyzing expert knowledge about discrepancies in data through the use of visualization. Grounded in an 18-month design study with global health experts, the framework formalizes the notion of data discrepancies as implicit error, both in global health data and more broadly. We use the term implicit error to describe measurement error that is inherent to and pervasive throughout a dataset, but that isn't explicitly accounted for or defined. Instead, implicit error exists in the minds of experts, is mainly qualitative, and is accounted for subjectively during expert interpretation of the data. Externalizing knowledge surrounding implicit error can assist in synchronizing, validating, and enhancing interpretation, and can inform error analysis and mitigation. The framework consists of a description of implicit error components that are important for downstream analysis, along with a process model for externalizing and analyzing implicit error using visualization. As a second contribution, we provide a rich, reflective, and verifiable description of our research process as an exemplar summary toward the ongoing inquiry into ways of increasing the validity and transferability of design study research.",,https://github.com/visdesignlab/IEFramework,,,vimeo 289785202,10.1109/tvcg.2018.2864913,2018,2018,InfoVis,"Convention Hall 1, Section D",Friday,Uncertainty & Error,26-Oct,10:20 AM,10:40 AM
SciVis,TVCG,Exploring Time-Varying Multivariate Volume Data Using Matrix of Isosurface Similarity Maps,J),"Jun Tao, Martin Imre, Chaoli Wang, Nitesh V Chawla, Hanqi Guo, Gökhan Sever, Seung Hyun Kim",https://www3.nd.edu/~cwang11/research/vis18-mism.pdf,"We present a novel visual representation and interface named the matrix of isosurface similarity maps (MISM) for effective exploration of large time-varying multivariate volumetric data sets. MISM synthesizes three types of similarity maps (i.e., self, temporal, and variable similarity maps) to capture the essential relationships among isosurfaces of different variables and time steps. Additionally, it serves as the main visual mapping and navigation tool for examining the vast number of isosurfaces and exploring the underlying time-varying multivariate data set. We present temporal clustering, variable grouping, and interactive filtering to reduce the huge exploration space of MISM. In conjunction with the isovalue and isosurface views, MISM allows users to identify important isosurfaces or isosurface pairs and compare them over space, time, and value range. More importantly, we introduce path recommendation that suggests, animates, and compares traversal paths for effectively exploring MISM under varied criteria and at different levels-of-detail. A silhouette-based method is applied to render multiple surfaces of interest in a visually succinct manner. We demonstrate the effectiveness of our approach with case studies of several time-varying multivariate data sets and an ensemble data set, and evaluate our work with two domain experts.",,,,,vimeo 290325769,10.1109/tvcg.2018.2864808,2018,2018,SciVis,Estrel Hall C,Friday,Time-varying Data,26-Oct,9:00 AM,9:20 AM
SciVis,TVCG,Visual Analysis of Spatio-temporal Relations of Pairwise Attributes in Unsteady Flow,J),"Marzieh Berenjkoub, Rodolfo Ostilla Monico, Robert S. Laramee, Guoning Chen",,,,,,,vimeo 290325964,10.1109/tvcg.2018.2864817,2018,2018,SciVis,Estrel Hall C,Friday,Time-varying Data,26-Oct,9:20 AM,9:40 AM
SciVis,TVCG,Time-Dependent Flow seen through Approximate Observer Killing Fields,J),"Markus Hadwiger, Matej Mlejnek, Thomas Theussl, Peter Rautek",http://vccvisualization.org/publications/2018_hadwiger_killingobservers.pdf,"Flow fields are usually visualized relative to a global observer, i.e., a single frame of reference. However, often no global frame can depict all flow features equally well. Likewise, objective criteria for detecting features such as vortices often use either a global reference frame, or compute a separate frame for each point in space and time. We propose the first general framework that enables choosing a smooth trade-off between these two extremes. Using global optimization to minimize specific differential geometric properties, we compute a time-dependent observer velocity field that describes the motion of a continuous field of observers adapted to the input flow. This requires developing the novel notion of an observed time derivative. While individual observers are restricted to rigid motions, overall we compute an approximate Killing field, corresponding to almost-rigid motion. This enables continuous transitions between different observers. Instead of focusing only on flow features, we furthermore develop a novel general notion of visualizing how all observers jointly perceive the input field. This in fact requires introducing the concept of an observation time, with respect to which a visualization is computed. We develop the corresponding notions of observed stream, path, streak, and time lines. For efficiency, these characteristic curves can be computed using standard approaches, by first transforming the input field accordingly. Finally, we prove that the input flow perceived by the observer field is objective. This makes derived flow features, such as vortices, objective as well.",,https://github.com/vccvisualization/killingobservers,,,vimeo 290327432,10.1109/tvcg.2018.2864839,2018,2018,SciVis,Estrel Hall C,Friday,Time-varying Data,26-Oct,9:40 AM,10:00 AM
TVCG,TVCG,An Exploratory Framework for Cyclone Identification and Tracking,T),"Akash Anil Valsangkar, Joy Merwin Monteiro, Vidya Narayanan, Ingrid Hotz, Vijay Natarajan",https://vgl.csa.iisc.ac.in/pdf/pub/CycloneTrackingTVCG_Akash.pdf,"Analyzing depressions plays an important role in meteorology, especially in the study of cyclones. In particular, the study of the temporal evolution of cyclones requires a robust depression tracking framework. To cope with this demand we propose a pipeline for the exploration of cyclones and their temporal evolution. This entails a generic framework for their identification and tracking. The fact that depressions and cyclones are not well-defined objects and their shape and size characteristics change over time makes this task especially challenging. Our method combines the robustness of topological approaches and the detailed tracking information from optical flow analysis. At first cyclones are identified within each time step based on well-established topological concepts. Then candidate tracks are computed from an optical flow field. These tracks are clustered within a moving time window to distill dominant coherent cyclone movements, which are then forwarded to a final tracking step. In contrast to previous methods our method requires only a few intuitive parameters. An integration into an exploratory framework helps in the study of cyclone movement by identifying smooth, representative tracks. Multiple case studies demonstrate the effectiveness of the method in tracking cyclones, both in the northern and southern hemisphere",,,,,youtube DLv-EKwZjSI,10.1109/tvcg.2018.2810068,2018,2018,SciVis,Estrel Hall C,Friday,Time-varying Data,26-Oct,10:00 AM,10:20 AM
TVCG,TVCG,Popup-Plots: Warping Temporal Data Visualization,T),"Johanna Schmidt, Dominik Fleischmann, Bernhard Preim, Norbert Brandle, Gabriel Mistelbauer",,,,,,,vimeo 289789393,10.1109/tvcg.2018.2841385,2018,2018,SciVis,Estrel Hall C,Friday,Time-varying Data,26-Oct,10:20 AM,10:40 AM